{"id":"s-7ujm","uuid":"1771dedd-68b4-4ec8-98e8-fe8a77df8a9d","title":"Payment Token Service","file_path":"specs/payment_token_service.md","content":"## Overview\n\nMicroservice responsible for tokenizing payment data from POS hardware. This service handles device-based decryption, re-encryption with rotating keys, token storage, and secure token retrieval. **PCI compliance boundary** - isolated from other services.\n\n## Service Boundaries\n\n- **Owns**: Payment data encryption/decryption, BDK management, token generation, token-to-payment-data mapping, internal decryption for workers\n- **Does NOT own**: Authorization logic, payment processing, merchant configuration\n- **Isolation**: Separate database, separate deployment, minimal API surface\n\n## Encryption Architecture\n\n### Key Management\n\n- **BDK (Base Derivation Key)**: Master key stored in AWS KMS, never leaves the service\n- **Device Tokens**: Per-device identifiers provided by POS hardware\n- **Derived Keys**: Generated per-request using KDF(BDK, device\\_token)\n- **Service Rotating Keys**: Used to re-encrypt tokens, rotated regularly (e.g., every 90 days)\n\n### Encryption Flow\n\n**Token Creation:**\n\n```\nPOS Device:\n  1. Generates device_token (unique per device)\n  2. Derives encryption key: device_key = KDF(BDK, device_token)\n  3. Encrypts payment data: encrypted = AES-GCM(payment_data, device_key)\n  4. Sends: encrypted_payment_data + device_token\n\nPayment Token Service:\n  1. Retrieves BDK from AWS KMS\n  2. Derives same key: device_key = KDF(BDK, device_token)\n  3. Decrypts: payment_data = decrypt(encrypted_payment_data, device_key)\n  4. Re-encrypts with service key: service_encrypted = AES-GCM(payment_data, rotating_key)\n  5. Stores: payment_token → service_encrypted\n  6. Returns: payment_token\n```\n\n**Token Decryption (Internal):**\n\n```\nAuth Worker Request:\n  1. Calls POST /internal/decrypt with payment_token\n  \nPayment Token Service:\n  1. Retrieves service_encrypted from database\n  2. Decrypts with current rotating_key: payment_data = decrypt(service_encrypted, rotating_key)\n  3. Returns: payment_data (in memory only, never persisted)\n```\n\n## API Specification\n\n### POST /payment-tokens\n\nCreates a payment token from device-encrypted payment data.\n\n**Request:**\n\n```protobuf\nmessage CreatePaymentTokenRequest {\n  string restaurant_id = 1;  // UUID of the restaurant/merchant\n  bytes encrypted_payment_data = 2;  // Encrypted by POS device with derived key\n  string device_token = 3;  // Device identifier for key derivation\n  string idempotency_key = 4;  // Client-provided idempotency key\n  map<string, string> metadata = 5;  // Optional metadata (card brand, last4, etc.)\n}\n\nmessage CreatePaymentTokenResponse {\n  string payment_token = 1;  // Generated token (UUID format: pt_...)\n  string restaurant_id = 2;\n  int64 expires_at = 3;  // Unix timestamp\n  map<string, string> metadata = 4;  // Echoed metadata\n}\n```\n\n**HTTP:**\n\n```\nPOST /v1/payment-tokens\nContent-Type: application/x-protobuf\nX-Idempotency-Key: <uuid>\nAuthorization: Bearer <api_key>\n\nResponse:\n201 Created - Token created successfully\n200 OK - Idempotent request, returning existing token\n400 Bad Request - Invalid request or decryption failed\n401 Unauthorized - Invalid API key\n500 Internal Server Error\n```\n\n### GET /payment-tokens/{token\\_id}\n\nRetrieves payment token metadata (NOT the actual payment data).\n\n**Request:**\n\n```protobuf\nmessage GetPaymentTokenRequest {\n  string payment_token = 1;\n  string restaurant_id = 2;  // Must match token owner\n}\n\nmessage GetPaymentTokenResponse {\n  string payment_token = 1;\n  string restaurant_id = 2;\n  int64 created_at = 3;\n  int64 expires_at = 4;\n  bool is_expired = 5;\n  map<string, string> metadata = 6;\n}\n```\n\n**HTTP:**\n\n```\nGET /v1/payment-tokens/{token_id}?restaurant_id={restaurant_id}\nAuthorization: Bearer <api_key>\n\nResponse:\n200 OK - Token found\n404 Not Found - Token doesn't exist or doesn't belong to restaurant\n410 Gone - Token expired\n```\n\n### POST /internal/decrypt (Internal Only)\n\nDecrypts a payment token and returns raw payment data. **Only accessible by Auth Processor Workers and Void Workers** within VPC.\n\n**Request:**\n\n```protobuf\nmessage DecryptPaymentTokenRequest {\n  string payment_token = 1;\n  string restaurant_id = 2;  // For authorization check\n  string requesting_service = 3;  // \"auth-processor-worker\", \"void-processor-worker\"\n}\n\nmessage DecryptPaymentTokenResponse {\n  PaymentData payment_data = 1;\n  map<string, string> metadata = 2;  // card_brand, last4, etc.\n}\n\nmessage PaymentData {\n  string card_number = 1;  // Full PAN\n  string exp_month = 2;  // MM\n  string exp_year = 3;  // YYYY\n  string cvv = 4;\n  string cardholder_name = 5;\n  \n  // Billing address (if available)\n  Address billing_address = 6;\n}\n\nmessage Address {\n  string line1 = 1;\n  string line2 = 2;\n  string city = 3;\n  string state = 4;\n  string postal_code = 5;\n  string country = 6;  // ISO 3166-1 alpha-2\n}\n```\n\n**HTTP:**\n\n```\nPOST /internal/v1/decrypt\nContent-Type: application/x-protobuf\nX-Service-Auth: <internal-service-token>\nX-Request-ID: <correlation-id>\n\nResponse:\n200 OK - Token decrypted successfully\n400 Bad Request - Invalid token format\n404 Not Found - Token not found\n410 Gone - Token expired\n403 Forbidden - Restaurant ID mismatch or unauthorized service\n500 Internal Server Error\n```\n\n## Behaviors\n\n### B1: Token Creation with Idempotency\n\n**Given** a client calls POST /payment-tokens with an idempotency key **When** the same idempotency key is used within 24 hours **Then** the same token is returned (idempotent behavior) **And** no duplicate database entries are created\n\n### B2: Device-Based Decryption\n\n**Given** POS device encrypts payment data with derived key **When** Payment Token Service receives encrypted data + device\\_token **Then** derive decryption key using BDK and device\\_token **And** decrypt payment data **And** fail with 400 if decryption fails (invalid device\\_token or corrupted data)\n\n### B3: Re-encryption with Rotating Keys\n\n**Given** decrypted payment data **When** storing in database **Then** re-encrypt using current service rotating key **And** store key version for future decryption **And** support multiple key versions during rotation period\n\n### B4: Token Expiration\n\n**Given** a payment token is created **When** 24 hours have passed (configurable per restaurant) **Then** the token is marked as expired and cannot be used for new authorizations **And** GET requests return 410 Gone **And** Decrypt requests return 410 Gone\n\n### B5: Restaurant Scoping\n\n**Given** a payment token **When** any operation is performed **Then** the token can only be accessed by the restaurant that created it **And** attempts to access with wrong restaurant\\_id return 403 Forbidden\n\n### B6: Internal Decryption Authorization\n\n**Given** a decrypt request to /internal/decrypt **When** requesting\\_service is not in allowlist \\[\"auth-processor-worker\", \"void-processor-worker\"\\] **Then** return 403 Forbidden **And** log security violation\n\n### B7: Audit Logging for Decryption\n\n**Given** any decrypt request (internal API) **When** processed (success or failure) **Then** log: payment\\_token, restaurant\\_id, requesting\\_service, timestamp, result **And** logs are immutable and retained for 7 years (PCI compliance)\n\n### B8: Key Rotation Support\n\n**Given** service rotating keys are rotated (e.g., every 90 days) **When** old tokens are decrypted **Then** use key\\_version stored with token to select correct decryption key **And** support N previous key versions (e.g., 4 versions = 1 year retention) **And** background job re-encrypts old tokens with new key\n\n### B9: BDK Security\n\n**Given** BDK must never leave AWS KMS **When** deriving device keys **Then** use KMS Decrypt API with encryption context **And** derived keys exist only in memory, never persisted **And** rotate BDK annually with migration process\n\n## Database Schema\n\n```sql\nCREATE TABLE payment_tokens (\n    payment_token VARCHAR(64) PRIMARY KEY,  -- pt_<uuid>\n    restaurant_id UUID NOT NULL,\n    \n    -- Re-encrypted payment data (service key)\n    encrypted_payment_data BYTEA NOT NULL,\n    encryption_key_version VARCHAR(50) NOT NULL,  -- For key rotation\n    \n    -- Original device info (for audit)\n    device_token VARCHAR(255) NOT NULL,\n    \n    -- Lifecycle\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    expires_at TIMESTAMP NOT NULL,\n    \n    -- Metadata (non-sensitive)\n    metadata JSONB,  -- card_brand, last4, exp_month (for display)\n    \n    INDEX idx_restaurant_created (restaurant_id, created_at),\n    INDEX idx_expires_at (expires_at) WHERE expires_at > NOW()\n);\n\nCREATE TABLE token_idempotency_keys (\n    idempotency_key VARCHAR(255) NOT NULL,\n    restaurant_id UUID NOT NULL,\n    payment_token VARCHAR(64) NOT NULL REFERENCES payment_tokens(payment_token),\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    expires_at TIMESTAMP NOT NULL DEFAULT NOW() + INTERVAL '24 hours',\n    \n    PRIMARY KEY (idempotency_key, restaurant_id),\n    INDEX idx_expires_at (expires_at)\n);\n\n-- Encryption key versions (for rotation)\nCREATE TABLE encryption_keys (\n    key_version VARCHAR(50) PRIMARY KEY,\n    kms_key_id VARCHAR(255) NOT NULL,  -- AWS KMS key ARN\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    is_active BOOLEAN NOT NULL DEFAULT true,\n    retired_at TIMESTAMP,\n    \n    CONSTRAINT only_one_active CHECK (\n        NOT is_active OR \n        (SELECT COUNT(*) FROM encryption_keys WHERE is_active = true) = 1\n    )\n);\n\n-- Audit log for decryption requests (PCI compliance)\nCREATE TABLE decrypt_audit_log (\n    id BIGSERIAL PRIMARY KEY,\n    payment_token VARCHAR(64) NOT NULL,\n    restaurant_id UUID NOT NULL,\n    requesting_service VARCHAR(100) NOT NULL,\n    request_id VARCHAR(255) NOT NULL,  -- Correlation ID\n    success BOOLEAN NOT NULL,\n    error_code VARCHAR(50),\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    \n    INDEX idx_token_created (payment_token, created_at),\n    INDEX idx_created_at (created_at)\n);\n\n-- Partition audit log by month for archival\nCREATE TABLE decrypt_audit_log_2024_01 PARTITION OF decrypt_audit_log\n    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');\n```\n\n## Key Derivation Function (KDF)\n\nUse **HKDF (HMAC-based Key Derivation Function)** per RFC 5869:\n\n```python\ndef derive_device_key(bdk: bytes, device_token: str) -> bytes:\n    \"\"\"\n    Derives device-specific encryption key from BDK.\n    \n    Args:\n        bdk: Base Derivation Key (from AWS KMS)\n        device_token: Device identifier\n    \n    Returns:\n        32-byte AES-256 key\n    \"\"\"\n    return HKDF(\n        algorithm=hashes.SHA256(),\n        length=32,\n        salt=None,\n        info=b\"payment-token-v1:\" + device_token.encode('utf-8')\n    ).derive(bdk)\n```\n\n## Dependencies\n\n- **AWS KMS**: For BDK storage and key management\n- **PostgreSQL**: For token storage (isolated instance)\n- None on other microservices (fully isolated)\n\n## Security Requirements\n\n- **PCI DSS Level 1** compliance\n- **Separate VPC**/network isolation from other services\n- **Separate database instance** (not shared)\n- **Mutual TLS** for internal /decrypt endpoint\n- **API keys** for public endpoints\n- **BDK** never leaves AWS KMS (use KMS Decrypt API)\n- **Derived keys** exist only in memory during request\n- **Audit logging** for all decrypt operations (immutable, 7-year retention)\n- **Encrypted connections only** (TLS 1.3)\n- **Rate limiting** per restaurant and per service\n\n## Configuration\n\n```yaml\nencryption:\n  bdk_kms_key_id: \"arn:aws:kms:us-east-1:...:key/...\"\n  current_key_version: \"v3\"\n  supported_key_versions: [\"v1\", \"v2\", \"v3\"]\n  key_rotation_days: 90\n\ntokens:\n  default_ttl_hours: 24\n  format: \"pt_{uuid}\"\n\ninternal_api:\n  allowed_services:\n    - \"auth-processor-worker\"\n    - \"void-processor-worker\"\n  require_mtls: true\n\nrate_limiting:\n  per_restaurant_rpm: 1000\n  per_service_rpm: 10000\n```\n\n## Deployment\n\n- **ECS Service** (long-running, not Lambda due to KMS cold start latency)\n- **Auto-scaling** based on CPU and request rate\n- **Health check**: GET /health\n- **Separate VPC subnet** (PCI zone)\n- **Security groups**: Only allow ingress from API Gateway (public) and Auth Workers (internal)\n\n## Key Rotation Process\n\n### Rotating Service Keys (Every 90 Days)\n\n1. Generate new key version in AWS KMS\n1. Insert new row in `encryption_keys` table with `is_active = true`\n1. Update old key: `is_active = false, retired_at = NOW()`\n1. New tokens use new key immediately\n1. Background job re-encrypts old tokens over 30 days:\n\n```sql\nUPDATE payment_tokens\nSET encrypted_payment_data = re_encrypt(encrypted_payment_data, old_key, new_key),\n    encryption_key_version = 'v4'\nWHERE encryption_key_version = 'v3'\nLIMIT 1000;\n```\n\n1. After all tokens re-encrypted, delete old KMS key (90 days later)\n\n### Rotating BDK (Annually)\n\n1. Generate new BDK in AWS KMS\n1. Update configuration to support both old and new BDK\n1. New tokens use new BDK for device key derivation\n1. Keep old BDK for 24 hours (token TTL)\n1. After 24 hours, retire old BDK\n\n## Testing Strategy\n\n- **Unit tests**: Key derivation, encryption/decryption, idempotency, expiration\n- **Integration tests**: Full API flow with test database + LocalStack KMS\n- **Security tests**:\n  - Cross-restaurant access attempts\n  - Expired token handling\n  - Invalid device\\_token (decryption failures)\n  - Unauthorized service access to /internal/decrypt\n- **Key rotation tests**: Decrypt tokens encrypted with old key versions\n- **Load tests**: Token creation throughput (target: 500 RPS)\n- **PCI compliance audit**: Annual third-party assessment\n\n## Monitoring & Alerts\n\n- **Metrics**: Token creation rate, decrypt request rate, KMS API latency, error rates\n- **Alarms**:\n  - Decryption failure rate > 1%\n  - KMS throttling errors\n  - Unauthorized decrypt attempts > 10/min\n- **Audit**: Daily review of decrypt\\_audit\\_log for anomalies","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-10 04:35:29","updated_at":"2025-11-14 02:48:10","parent_id":null,"parent_uuid":null,"relationships":[{"from":"s-7ujm","from_type":"spec","to":"s-8c0t","to_type":"spec","type":"references"}],"tags":["pci-compliant","service-spec","tokenization"]}
{"id":"s-9jeq","uuid":"152dae2a-283e-476c-926b-785cc96de8a4","title":"Authorization API Service","file_path":"specs/authorization_api_service.md","content":"## Overview\n\nPrimary API service for handling payment authorization requests. Implements event sourcing with **Transactional Outbox Pattern**, idempotency, and request/response polling. This is the main entry point for restaurant POS systems.\n\n## Service Boundaries\n\n- **Owns**: Auth request lifecycle, event storage, read model updates, idempotency, status queries, void requests, outbox processing\n- **Does NOT own**: Actual payment processing (delegated to workers), token decryption, processor integration\n- **Responsibilities**: API layer, event sourcing, read model maintenance (synchronous), queue management via outbox\n\n## Transaction Boundaries & Outbox Pattern\n\n### Critical Design Decision: At-Least-Once Delivery via Outbox\n\nTo ensure **atomic** event writes + queue messages, we use the **Transactional Outbox Pattern**:\n\n```\n┌─────────────────────────────────────────────────────────┐\n│                  POST /authorize                         │\n│                                                          │\n│  BEGIN TRANSACTION                                       │\n│    1. Check idempotency                                  │\n│    2. Write event: AuthRequestCreated                    │\n│    3. Update read model: auth_request_state (INSERT)     │\n│    4. Write to outbox: auth_request_queued               │\n│  COMMIT (all or nothing!)                                │\n│                                                          │\n│  Return auth_request_id to client                        │\n└─────────────────────────────────────────────────────────┘\n                          │\n                          │ (asynchronously)\n                          ▼\n┌─────────────────────────────────────────────────────────┐\n│              Outbox Processor (background)               │\n│                                                          │\n│  Every 100ms:                                            │\n│    1. SELECT * FROM outbox WHERE processed_at IS NULL    │\n│       FOR UPDATE SKIP LOCKED LIMIT 100                   │\n│    2. Send each message to SQS                           │\n│    3. UPDATE outbox SET processed_at = NOW()             │\n└─────────────────────────────────────────────────────────┘\n```\n\n**Guarantees:**\n\n- ✅ Event + Read Model + Outbox written atomically\n- ✅ At-least-once delivery to SQS (outbox processor retries until success)\n- ✅ No message loss (even if outbox processor crashes, messages remain in DB)\n- ✅ SQS FIFO deduplication handles any duplicate sends\n\n## API Specification\n\n### POST /authorize\n\nCreates an authorization request and waits up to 5 seconds for completion.\n\n**Request:**\n\n```protobuf\nmessage AuthorizeRequest {\n  string payment_token = 1;  // From Payment Token Service\n  string restaurant_id = 2;  // UUID of restaurant\n  int64 amount_cents = 3;  // Amount in cents (e.g., 1050 = $10.50)\n  string currency = 4;  // ISO 4217 currency code (e.g., \"USD\")\n  string idempotency_key = 5;  // Client-provided\n  map<string, string> metadata = 6;  // Optional: order_id, table_number, etc.\n}\n\nmessage AuthorizeResponse {\n  string auth_request_id = 1;  // UUID\n  AuthStatus status = 2;\n  \n  // Populated if status = AUTHORIZED or DENIED\n  AuthorizationResult result = 3;\n  \n  // Populated if status = PROCESSING\n  string status_url = 4;  // URL to poll for status\n}\n\nenum AuthStatus {\n  PROCESSING = 0;  // Still in progress\n  AUTHORIZED = 1;  // Successfully authorized\n  DENIED = 2;  // Declined by processor\n  FAILED = 3;  // System error\n  VOIDED = 4;  // Voided by user\n  EXPIRED = 5;  // Request expired before processing\n}\n\nmessage AuthorizationResult {\n  string processor_auth_id = 1;  // e.g., Stripe charge ID\n  string processor_name = 2;  // \"stripe\", \"chase\", etc.\n  int64 authorized_amount_cents = 3;\n  string currency = 4;\n  string authorization_code = 5;  // Processor-provided auth code\n  int64 authorized_at = 6;  // Unix timestamp\n  \n  // For DENIED status\n  string denial_code = 7;  // Processor decline code\n  string denial_reason = 8;  // Human-readable reason\n  \n  map<string, string> processor_metadata = 9;  // Raw processor response\n}\n```\n\n**HTTP:**\n\n```\nPOST /v1/authorize\nContent-Type: application/x-protobuf\nX-Idempotency-Key: <uuid>\n\nResponse:\n200 OK - Authorization completed within 5 seconds (AUTHORIZED/DENIED)\n202 Accepted - Authorization still processing (client should poll)\n400 Bad Request - Invalid request\n404 Not Found - Payment token not found/expired\n409 Conflict - Auth request already voided\n500 Internal Server Error\n```\n\n**Implementation (Pseudocode):**\n\n```python\nasync def post_authorize(request: AuthorizeRequest) -> AuthorizeResponse:\n    # 1. Check idempotency\n    existing = await db.fetch_one(\n        \"SELECT auth_request_id FROM auth_idempotency_keys WHERE idempotency_key = $1\",\n        request.idempotency_key\n    )\n    if existing:\n        return await get_status(existing.auth_request_id)\n    \n    auth_request_id = generate_uuid()\n    \n    # 2. ATOMIC TRANSACTION\n    async with db.transaction():\n        # 2a. Write event\n        await db.execute(\"\"\"\n            INSERT INTO payment_events (event_id, aggregate_id, aggregate_type, event_type, event_data, sequence_number)\n            VALUES ($1, $2, 'auth_request', 'AuthRequestCreated', $3, 1)\n        \"\"\", generate_uuid(), auth_request_id, serialize_protobuf(AuthRequestCreated(...)))\n        \n        # 2b. Write read model (strong consistency!)\n        await db.execute(\"\"\"\n            INSERT INTO auth_request_state (auth_request_id, restaurant_id, payment_token, status, amount_cents, currency, created_at, updated_at, last_event_sequence)\n            VALUES ($1, $2, $3, 'PENDING', $4, $5, NOW(), NOW(), 1)\n        \"\"\", auth_request_id, request.restaurant_id, request.payment_token, request.amount_cents, request.currency)\n        \n        # 2c. Write to outbox (reliable queue delivery!)\n        await db.execute(\"\"\"\n            INSERT INTO outbox (aggregate_id, message_type, payload, created_at)\n            VALUES ($1, 'auth_request_queued', $2, NOW())\n        \"\"\", auth_request_id, json.dumps({\n            \"auth_request_id\": auth_request_id,\n            \"restaurant_id\": request.restaurant_id\n        }))\n        \n        # 2d. Write idempotency key\n        await db.execute(\"\"\"\n            INSERT INTO auth_idempotency_keys (idempotency_key, auth_request_id, restaurant_id, created_at, expires_at)\n            VALUES ($1, $2, $3, NOW(), NOW() + INTERVAL '24 hours')\n        \"\"\", request.idempotency_key, auth_request_id, request.restaurant_id)\n        \n        # COMMIT - all or nothing!\n    \n    # 3. Wait up to 5 seconds for response (poll read model)\n    for _ in range(50):  # 50 * 100ms = 5 seconds\n        await asyncio.sleep(0.1)\n        \n        state = await db.fetch_one(\n            \"SELECT status, processor_auth_id, authorization_code, denial_code, denial_reason FROM auth_request_state WHERE auth_request_id = $1\",\n            auth_request_id\n        )\n        \n        if state.status in ('AUTHORIZED', 'DENIED', 'FAILED'):\n            return AuthorizeResponse(\n                auth_request_id=auth_request_id,\n                status=state.status,\n                result=AuthorizationResult(...) if state.status != 'FAILED' else None\n            )\n    \n    # 4. Timeout - return 202 Accepted\n    return AuthorizeResponse(\n        auth_request_id=auth_request_id,\n        status=AuthStatus.PROCESSING,\n        status_url=f\"/v1/authorize/{auth_request_id}/status\"\n    )\n```\n\n### GET /authorize/{auth\\_request\\_id}/status\n\nPolls for authorization status (reads from read model).\n\n**Request:**\n\n```protobuf\nmessage GetAuthStatusRequest {\n  string auth_request_id = 1;\n  string restaurant_id = 2;  // Must match\n}\n\nmessage GetAuthStatusResponse {\n  string auth_request_id = 1;\n  AuthStatus status = 2;\n  AuthorizationResult result = 3;  // If completed\n  int64 created_at = 4;\n  int64 updated_at = 5;\n}\n```\n\n**HTTP:**\n\n```\nGET /v1/authorize/{auth_request_id}/status?restaurant_id={restaurant_id}\n\nResponse:\n200 OK - Status retrieved\n404 Not Found - Auth request not found or wrong restaurant\n```\n\n**Implementation:**\n\n```python\nasync def get_status(auth_request_id: str, restaurant_id: str) -> GetAuthStatusResponse:\n    # Simple read from read model (no transaction needed)\n    state = await db.fetch_one(\"\"\"\n        SELECT auth_request_id, status, processor_auth_id, processor_name, \n               authorized_amount_cents, authorization_code, denial_code, denial_reason,\n               created_at, updated_at\n        FROM auth_request_state\n        WHERE auth_request_id = $1 AND restaurant_id = $2\n    \"\"\", auth_request_id, restaurant_id)\n    \n    if not state:\n        raise NotFound(\"Auth request not found\")\n    \n    return GetAuthStatusResponse(\n        auth_request_id=state.auth_request_id,\n        status=state.status,\n        result=build_result(state) if state.status in ('AUTHORIZED', 'DENIED') else None,\n        created_at=state.created_at,\n        updated_at=state.updated_at\n    )\n```\n\n### POST /authorize/{auth\\_request\\_id}/void\n\nVoids an authorization request (similar transaction pattern).\n\n**Request:**\n\n```protobuf\nmessage VoidAuthRequest {\n  string auth_request_id = 1;\n  string restaurant_id = 2;\n  string reason = 3;  // Optional: \"customer_cancelled\", etc.\n  string idempotency_key = 4;\n}\n\nmessage VoidAuthResponse {\n  string auth_request_id = 1;\n  VoidStatus status = 2;\n  int64 voided_at = 3;\n}\n\nenum VoidStatus {\n  VOID_PENDING = 0;  // Void request queued\n  VOID_COMPLETED = 1;  // Void successful\n  VOID_FAILED = 2;  // Could not void (already captured, etc.)\n  VOID_NOT_REQUIRED = 3;  // Never authorized, just cancelled queue\n}\n```\n\n**HTTP:**\n\n```\nPOST /v1/authorize/{auth_request_id}/void\nContent-Type: application/x-protobuf\n\nResponse:\n200 OK - Void processed\n404 Not Found - Auth request not found\n409 Conflict - Already voided or captured\n```\n\n**Implementation:**\n\n```python\nasync def post_void(auth_request_id: str, request: VoidAuthRequest) -> VoidAuthResponse:\n    async with db.transaction():\n        # 1. Get current state\n        state = await db.fetch_one(\n            \"SELECT status FROM auth_request_state WHERE auth_request_id = $1 AND restaurant_id = $2 FOR UPDATE\",\n            auth_request_id, request.restaurant_id\n        )\n        \n        if not state:\n            raise NotFound(\"Auth request not found\")\n        \n        if state.status == 'VOIDED':\n            raise Conflict(\"Already voided\")\n        \n        # 2. Write void event\n        next_seq = await db.fetch_val(\n            \"SELECT MAX(sequence_number) + 1 FROM payment_events WHERE aggregate_id = $1\",\n            auth_request_id\n        )\n        \n        await db.execute(\"\"\"\n            INSERT INTO payment_events (event_id, aggregate_id, aggregate_type, event_type, event_data, sequence_number)\n            VALUES ($1, $2, 'auth_request', 'AuthVoidRequested', $3, $4)\n        \"\"\", generate_uuid(), auth_request_id, serialize_protobuf(AuthVoidRequested(...)), next_seq)\n        \n        # 3. Update read model\n        await db.execute(\"\"\"\n            UPDATE auth_request_state\n            SET status = 'VOIDED', updated_at = NOW(), last_event_sequence = $2\n            WHERE auth_request_id = $1\n        \"\"\", auth_request_id, next_seq)\n        \n        # 4. If AUTHORIZED, write to outbox for void worker\n        if state.status == 'AUTHORIZED':\n            await db.execute(\"\"\"\n                INSERT INTO outbox (aggregate_id, message_type, payload, created_at)\n                VALUES ($1, 'void_request_queued', $2, NOW())\n            \"\"\", auth_request_id, json.dumps({\n                \"auth_request_id\": auth_request_id,\n                \"restaurant_id\": request.restaurant_id,\n                \"reason\": request.reason\n            }))\n        \n        # COMMIT\n    \n    return VoidAuthResponse(\n        auth_request_id=auth_request_id,\n        status=VoidStatus.VOID_PENDING if state.status == 'AUTHORIZED' else VoidStatus.VOID_NOT_REQUIRED,\n        voided_at=int(time.time())\n    )\n```\n\n## Outbox Processor (Background Service)\n\n**Runs as separate process/thread within Authorization API deployment.**\n\n```python\nasync def outbox_processor():\n    \"\"\"\n    Background process that polls outbox and sends messages to SQS.\n    Runs continuously every 100ms.\n    \"\"\"\n    while True:\n        try:\n            # 1. Fetch unprocessed messages (with locking to prevent duplicate processing)\n            messages = await db.fetch(\"\"\"\n                SELECT id, aggregate_id, message_type, payload\n                FROM outbox\n                WHERE processed_at IS NULL\n                ORDER BY created_at\n                LIMIT 100\n                FOR UPDATE SKIP LOCKED\n            \"\"\")\n            \n            for msg in messages:\n                try:\n                    # 2. Send to appropriate SQS queue\n                    if msg.message_type == 'auth_request_queued':\n                        await sqs.send_message(\n                            QueueUrl=AUTH_REQUESTS_QUEUE_URL,\n                            MessageBody=msg.payload,\n                            MessageDeduplicationId=msg.aggregate_id,  # SQS FIFO deduplication\n                            MessageGroupId=json.loads(msg.payload)[\"restaurant_id\"]\n                        )\n                    elif msg.message_type == 'void_request_queued':\n                        await sqs.send_message(\n                            QueueUrl=VOID_REQUESTS_QUEUE_URL,\n                            MessageBody=msg.payload\n                        )\n                    \n                    # 3. Mark as processed\n                    await db.execute(\n                        \"UPDATE outbox SET processed_at = NOW() WHERE id = $1\",\n                        msg.id\n                    )\n                    \n                except Exception as e:\n                    # Log error but continue (will retry on next poll)\n                    logger.error(f\"Failed to process outbox message {msg.id}: {e}\")\n            \n            # 4. Sleep 100ms\n            await asyncio.sleep(0.1)\n            \n        except Exception as e:\n            logger.error(f\"Outbox processor error: {e}\")\n            await asyncio.sleep(1)  # Back off on error\n```\n\n## Event Definitions\n\nAll events stored in `payment_events` table.\n\n```protobuf\n// Event: AuthRequestCreated\nmessage AuthRequestCreated {\n  string auth_request_id = 1;\n  string payment_token = 2;\n  string restaurant_id = 3;\n  int64 amount_cents = 4;\n  string currency = 5;\n  map<string, string> metadata = 6;\n  int64 created_at = 7;\n}\n\n// Event: AuthRequestQueued (outbox message type, not an event)\n// Stored as JSON in outbox.payload\n\n// Event: AuthAttemptStarted (written by worker)\nmessage AuthAttemptStarted {\n  string auth_request_id = 1;\n  string worker_id = 2;  // Which worker is processing\n  string restaurant_payment_config_version = 3;\n  int64 started_at = 4;\n}\n\n// Event: AuthResponseReceived (written by worker)\nmessage AuthResponseReceived {\n  string auth_request_id = 1;\n  AuthStatus status = 2;  // AUTHORIZED or DENIED\n  AuthorizationResult result = 3;\n  int64 received_at = 4;\n}\n\n// Event: AuthAttemptFailed (written by worker)\nmessage AuthAttemptFailed {\n  string auth_request_id = 1;\n  string error_code = 2;  // \"token_invalid\", \"processor_timeout\", etc.\n  string error_message = 3;\n  bool is_retryable = 4;\n  int32 retry_count = 5;\n  int64 next_retry_at = 6;  // If retryable\n  int64 failed_at = 7;\n}\n\n// Event: AuthVoidRequested\nmessage AuthVoidRequested {\n  string auth_request_id = 1;\n  string reason = 2;\n  int64 requested_at = 3;\n}\n\n// Event: AuthRequestExpired (written by worker or timeout process)\nmessage AuthRequestExpired {\n  string auth_request_id = 1;\n  int64 expired_at = 2;\n  string reason = 3;  // \"timeout\", \"max_retries_exceeded\", \"voided_before_processing\"\n}\n```\n\n## Behaviors\n\n### B1: Idempotency\n\n**Given** POST /authorize with idempotency key \"xyz\" **When** called multiple times **Then** same auth\\_request\\_id is returned **And** only ONE event is created **And** only ONE outbox entry is created **And** only ONE SQS message is sent\n\n### B2: Synchronous Response (Fast Path)\n\n**Given** POST /authorize is called **When** processor responds within 5 seconds **Then** return 200 with AUTHORIZED or DENIED status **And** do NOT return status\\_url\n\n### B3: Asynchronous Response (Slow Path)\n\n**Given** POST /authorize is called **When** 5 seconds pass without response **Then** return 202 Accepted with status\\_url **And** client should poll GET /authorize/{id}/status\n\n### B4: Atomic Event + Read Model + Outbox\n\n**Given** POST /authorize is called **When** transaction commits **Then** event, read model, and outbox entry are ALL written atomically **When** transaction fails/rolls back **Then** NONE are written (no partial state)\n\n### B5: Outbox Guarantees At-Least-Once Delivery\n\n**Given** outbox entry is written **When** outbox processor runs **Then** message is sent to SQS at least once **And** SQS FIFO deduplication prevents duplicate processing **And** even if processor crashes, message remains in outbox and is retried\n\n### B6: Read Model is Strongly Consistent\n\n**Given** transaction commits with read model update **When** GET /authorize/{id}/status is called immediately **Then** latest status is returned (no eventual consistency delay)\n\n### B7: Void Before Processing\n\n**Given** auth request is PENDING or PROCESSING **When** void is requested **Then** emit AuthVoidRequested event **And** update read model status to VOIDED **And** worker checks for void event before calling processor **And** return VOID\\_NOT\\_REQUIRED (no processor call needed)\n\n### B8: Void After Authorization\n\n**Given** auth request is AUTHORIZED **When** void is requested **Then** emit AuthVoidRequested event **And** update read model status to VOIDED **And** enqueue void request to void queue via outbox **And** void worker processes void with retries\n\n### B9: Dead Letter - Invalid Token (handled by worker)\n\n**Given** auth request with invalid/expired token **When** worker attempts to process **Then** worker writes AuthAttemptFailed event **And** worker updates read model status to FAILED **And** move to dead letter queue\n\n### B10: Restaurant Payment Config Changes\n\n**Given** restaurant config changes (e.g., switch from Stripe to Chase) **When** queued auth request is processed **Then** worker uses CURRENT config at processing time (optimistic read) **And** allows replaying with new config\n\n## Database Schema\n\n```sql\n-- Event store (append-only)\nCREATE TABLE payment_events (\n    id BIGSERIAL PRIMARY KEY,\n    event_id UUID UNIQUE NOT NULL,\n    aggregate_id UUID NOT NULL,  -- auth_request_id\n    aggregate_type VARCHAR(50) NOT NULL DEFAULT 'auth_request',\n    event_type VARCHAR(100) NOT NULL,  -- 'AuthRequestCreated', etc.\n    event_data BYTEA NOT NULL,  -- Serialized protobuf\n    metadata JSONB,  -- correlation_id, causation_id, user_id\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    sequence_number INTEGER NOT NULL,\n    UNIQUE(aggregate_id, sequence_number)\n);\n\nCREATE INDEX idx_aggregate_events ON payment_events(aggregate_id, sequence_number);\nCREATE INDEX idx_event_type_created ON payment_events(event_type, created_at);\nCREATE INDEX idx_created_at ON payment_events(created_at);\n\n-- Read model for fast queries (updated synchronously in same transaction as event)\nCREATE TABLE auth_request_state (\n    auth_request_id UUID PRIMARY KEY,\n    restaurant_id UUID NOT NULL,\n    payment_token VARCHAR(64) NOT NULL,\n    status VARCHAR(20) NOT NULL,  -- PENDING, PROCESSING, AUTHORIZED, etc.\n    amount_cents BIGINT NOT NULL,\n    currency VARCHAR(3) NOT NULL,\n    \n    -- Result (populated when completed by worker)\n    processor_auth_id VARCHAR(255),\n    processor_name VARCHAR(50),\n    authorized_amount_cents BIGINT,\n    authorization_code VARCHAR(100),\n    denial_code VARCHAR(50),\n    denial_reason TEXT,\n    \n    created_at TIMESTAMP NOT NULL,\n    updated_at TIMESTAMP NOT NULL,\n    completed_at TIMESTAMP,\n    \n    metadata JSONB,\n    last_event_sequence INTEGER NOT NULL,  -- For consistency check\n    \n    INDEX idx_restaurant_created (restaurant_id, created_at),\n    INDEX idx_status (status),\n    INDEX idx_payment_token (payment_token)\n);\n\n-- Outbox for reliable queue delivery (Transactional Outbox Pattern)\nCREATE TABLE outbox (\n    id BIGSERIAL PRIMARY KEY,\n    aggregate_id UUID NOT NULL,  -- auth_request_id or void_request_id\n    message_type VARCHAR(100) NOT NULL,  -- 'auth_request_queued', 'void_request_queued'\n    payload JSONB NOT NULL,  -- Message body for SQS\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    processed_at TIMESTAMP,  -- NULL = unprocessed\n    \n    INDEX idx_unprocessed (created_at) WHERE processed_at IS NULL  -- Partial index for efficiency!\n);\n\n-- Idempotency keys\nCREATE TABLE auth_idempotency_keys (\n    idempotency_key VARCHAR(255) PRIMARY KEY,\n    auth_request_id UUID NOT NULL REFERENCES auth_request_state(auth_request_id),\n    restaurant_id UUID NOT NULL,\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    expires_at TIMESTAMP NOT NULL DEFAULT NOW() + INTERVAL '24 hours',\n    INDEX idx_expires_at (expires_at)\n);\n\n-- Restaurant payment configs (mocked for now, single Stripe config)\nCREATE TABLE restaurant_payment_configs (\n    restaurant_id UUID PRIMARY KEY,\n    config_version VARCHAR(50) NOT NULL,\n    processor_name VARCHAR(50) NOT NULL,  -- \"stripe\"\n    processor_config JSONB NOT NULL,  -- {\"stripe_api_key\": \"sk_test_...\"}\n    updated_at TIMESTAMP NOT NULL,\n    is_active BOOLEAN NOT NULL DEFAULT true\n);\n\n-- Lock table for workers (used by Auth Processor Worker)\nCREATE TABLE auth_processing_locks (\n    auth_request_id UUID PRIMARY KEY,\n    worker_id VARCHAR(255) NOT NULL,\n    locked_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    expires_at TIMESTAMP NOT NULL,\n    INDEX idx_expires_at (expires_at)\n);\n```\n\n## Dependencies\n\n- **Payment Token Service**: Validates token exists (not directly called by this service)\n- **SQS FIFO Queue**: Receives auth requests from outbox processor\n- **PostgreSQL**: Event store, read models, outbox\n- **Auth Processor Workers**: Processes queued requests (separate service)\n\n## Queue Configuration\n\n**Auth Request Queue** (SQS FIFO):\n\n- Name: `auth-requests.fifo`\n- Deduplication: Message deduplication ID = auth\\_request\\_id\n- Message Group ID: restaurant\\_id (ordering per restaurant)\n- Visibility timeout: 30 seconds\n- Max receive count: 5 → Dead letter queue\n\n**Void Request Queue** (SQS Standard):\n\n- Name: `void-requests`\n- Retries with exponential backoff\n\n**Dead Letter Queues**:\n\n- `auth-requests-dlq.fifo`: Terminal auth failures\n- `void-requests-dlq`: Failed voids\n\n## Background Jobs\n\n### Outbox Processor\n\n- **Frequency**: Every 100ms\n- **Batch size**: 100 messages\n- **Responsibility**: Poll outbox, send to SQS, mark as processed\n\n### Expired Idempotency Keys Cleanup\n\n- **Frequency**: Hourly\n- **Query**: `DELETE FROM auth_idempotency_keys WHERE expires_at < NOW()`\n\n### Expired Locks Cleanup (redundant with worker cleanup, but good hygiene)\n\n- **Frequency**: Every minute\n- **Query**: `DELETE FROM auth_processing_locks WHERE expires_at < NOW()`\n\n## Deployment\n\n- **ECS Service** or **Lambda**: API handlers\n- **Background thread/process**: Outbox processor (within same deployment)\n- **Auto-scaling**: Based on request rate\n- **Health check**: GET /health (includes outbox processor health)\n\n## Testing Strategy\n\n- **Unit tests**:\n  - Transaction logic (event + read model + outbox atomic writes)\n  - Idempotency\n  - State reconstruction from events\n- **Integration tests**:\n  - Full API flow with test database\n  - Outbox processor sends to LocalStack SQS\n  - Verify at-least-once delivery\n- **Behavior tests**: Each behavior spec (B1-B10) has dedicated test\n- **End-to-end tests**: POST /authorize → outbox → SQS → worker processes → GET status returns result\n- **Chaos tests**: Kill outbox processor mid-processing, verify messages are retried\n- **Load tests**: 300 QPS sustained, measure p50/p95/p99 latency","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-10 04:35:30","updated_at":"2025-11-14 02:48:05","parent_id":null,"parent_uuid":null,"relationships":[{"from":"s-9jeq","from_type":"spec","to":"s-94si","to_type":"spec","type":"implements"},{"from":"s-9jeq","from_type":"spec","to":"s-8c0t","to_type":"spec","type":"depends-on"}],"tags":["api","event-sourcing","service-spec"]}
{"id":"s-w5sf","uuid":"6ed0e286-c807-4bb7-902f-c6975f4fb75b","title":"Auth Processor Worker Service","file_path":"specs/auth_processor_worker_service.md","content":"## Overview\nBackground worker service that dequeues authorization requests, calls external services (payment token service for decryption, payment processors), and records results. Implements exactly-once processing with distributed locking and **atomic event + read model updates**.\n\n## Service Boundaries\n- **Owns**: Auth request processing, processor integration, retry logic, locking, **read model updates for worker events**\n- **Does NOT own**: API layer, event storage schema, token encryption/decryption logic\n- **Responsibilities**: Dequeue, lock, process, record result (event + read model), unlock\n\n## Transaction Boundaries\n\n### Critical: Worker Updates Read Model Atomically\n\nWorkers write events AND update the read model in the **same transaction**:\n\n```\n┌─────────────────────────────────────────────────────────┐\n│            Worker Processes Auth Request                 │\n│                                                          │\n│  BEGIN TRANSACTION                                       │\n│    1. Write event: AuthResponseReceived                  │\n│    2. Update read model: auth_request_state              │\n│       SET status = 'AUTHORIZED', processor_auth_id = ... │\n│  COMMIT (all or nothing!)                                │\n│                                                          │\n│  DELETE SQS message                                      │\n└─────────────────────────────────────────────────────────┘\n```\n\n**Guarantees:**\n- ✅ Event + Read Model written atomically\n- ✅ If transaction fails, SQS message remains visible (will retry)\n- ✅ Read model always reflects latest event\n- ✅ No eventual consistency delay\n\n## Worker Architecture\n\n```\n┌─────────────────────────────────────────────────────────┐\n│         SQS FIFO Consumer (Auth Request Queue)          │\n│  - Long polling (20 second wait)                        │\n│  - Batch size: 1 (for simplicity, can optimize later)  │\n│  - Visibility timeout: 30 seconds                       │\n└─────────────────────────────────────────────────────────┘\n                        │\n                        ▼\n┌─────────────────────────────────────────────────────────┐\n│              Acquire Distributed Lock                    │\n│  - INSERT INTO auth_processing_locks                    │\n│  - If lock exists and not expired → skip (race)         │\n│  - Lock TTL: 30 seconds                                 │\n└─────────────────────────────────────────────────────────┘\n                        │\n                        ▼\n┌─────────────────────────────────────────────────────────┐\n│           Check for Void Event (Race Check)             │\n│  - Query: SELECT event_type = 'AuthVoidRequested'      │\n│  - If found → skip processing, delete from queue        │\n└─────────────────────────────────────────────────────────┘\n                        │\n                        ▼\n┌─────────────────────────────────────────────────────────┐\n│      Fetch Restaurant Payment Config (Optimistic)       │\n│  - Read from cached table: restaurant_payment_configs   │\n│  - Determines which processor to use                    │\n└─────────────────────────────────────────────────────────┘\n                        │\n                        ▼\n┌─────────────────────────────────────────────────────────┐\n│    Call Payment Token Service /internal/decrypt         │\n│  - POST /internal/decrypt                               │\n│  - Returns decrypted payment data                       │\n└─────────────────────────────────────────────────────────┘\n                        │\n                        ▼\n┌─────────────────────────────────────────────────────────┐\n│        Call Payment Processor (Stripe, Chase, etc)      │\n│  - Stripe: POST /v1/charges                             │\n│  - Handle response: success, decline, error             │\n└─────────────────────────────────────────────────────────┘\n                        │\n                        ▼\n┌─────────────────────────────────────────────────────────┐\n│     ATOMIC: Write Event + Update Read Model             │\n│  BEGIN TRANSACTION                                       │\n│    - Write event: AuthResponseReceived                   │\n│    - Update auth_request_state                          │\n│  COMMIT                                                  │\n└─────────────────────────────────────────────────────────┘\n                        │\n                        ▼\n┌─────────────────────────────────────────────────────────┐\n│              Release Lock & Delete Message              │\n│  - DELETE FROM auth_processing_locks                    │\n│  - SQS DeleteMessage (ack)                              │\n└─────────────────────────────────────────────────────────┘\n```\n\n## Processing Logic (Pseudocode)\n\n```python\nasync def process_auth_request(message: SQSMessage):\n    auth_request_id = message.body['auth_request_id']\n    \n    # 1. Acquire lock\n    lock_acquired = await acquire_lock(auth_request_id)\n    if not lock_acquired:\n        # Another worker is processing, skip\n        return\n    \n    try:\n        # 2. Check for void (race condition check)\n        if await is_voided(auth_request_id):\n            # Write void completion event + update read model atomically\n            async with db.transaction():\n                await record_event(AuthRequestExpired(\n                    auth_request_id=auth_request_id,\n                    reason=\"voided_before_processing\"\n                ))\n                await db.execute(\"\"\"\n                    UPDATE auth_request_state\n                    SET status = 'EXPIRED', updated_at = NOW()\n                    WHERE auth_request_id = $1\n                \"\"\", auth_request_id)\n            \n            await delete_message(message)\n            return\n        \n        # 3. Emit processing event + update read model atomically\n        async with db.transaction():\n            next_seq = await get_next_sequence(auth_request_id)\n            await record_event(AuthAttemptStarted(\n                auth_request_id=auth_request_id,\n                worker_id=WORKER_ID,\n                started_at=now()\n            ), sequence=next_seq)\n            \n            await db.execute(\"\"\"\n                UPDATE auth_request_state\n                SET status = 'PROCESSING', updated_at = NOW(), last_event_sequence = $2\n                WHERE auth_request_id = $1\n            \"\"\", auth_request_id, next_seq)\n        \n        # 4. Fetch auth request details\n        auth_req = await get_auth_request(auth_request_id)\n        \n        # 5. Fetch restaurant config (optimistic)\n        config = await get_restaurant_config(auth_req.restaurant_id)\n        \n        # 6. Decrypt payment token via Payment Token Service\n        try:\n            payment_data = await payment_token_service.decrypt(\n                payment_token=auth_req.payment_token,\n                restaurant_id=auth_req.restaurant_id,\n                requesting_service=\"auth-processor-worker\"\n            )\n        except TokenNotFound:\n            # Terminal error - write event + update read model + dead letter\n            async with db.transaction():\n                next_seq = await get_next_sequence(auth_request_id)\n                await record_event(AuthAttemptFailed(\n                    auth_request_id=auth_request_id,\n                    error_code=\"token_invalid\",\n                    is_retryable=False\n                ), sequence=next_seq)\n                \n                await db.execute(\"\"\"\n                    UPDATE auth_request_state\n                    SET status = 'FAILED', updated_at = NOW(), last_event_sequence = $2\n                    WHERE auth_request_id = $1\n                \"\"\", auth_request_id, next_seq)\n            \n            await send_to_dlq(message)\n            await delete_message(message)\n            return\n        \n        except TokenExpired:\n            # Terminal error - write event + update read model + dead letter\n            async with db.transaction():\n                next_seq = await get_next_sequence(auth_request_id)\n                await record_event(AuthAttemptFailed(\n                    auth_request_id=auth_request_id,\n                    error_code=\"token_expired\",\n                    is_retryable=False\n                ), sequence=next_seq)\n                \n                await db.execute(\"\"\"\n                    UPDATE auth_request_state\n                    SET status = 'FAILED', updated_at = NOW(), last_event_sequence = $2\n                    WHERE auth_request_id = $1\n                \"\"\", auth_request_id, next_seq)\n            \n            await send_to_dlq(message)\n            await delete_message(message)\n            return\n        \n        # 7. Call processor\n        processor = get_processor_client(config.processor_name)\n        try:\n            result = await processor.authorize(\n                payment_data=payment_data,\n                amount_cents=auth_req.amount_cents,\n                currency=auth_req.currency,\n                config=config.processor_config\n            )\n            \n            # 8. ATOMIC: Record event + update read model\n            async with db.transaction():\n                next_seq = await get_next_sequence(auth_request_id)\n                \n                # Write event\n                await record_event(AuthResponseReceived(\n                    auth_request_id=auth_request_id,\n                    status=result.status,  # AUTHORIZED or DENIED\n                    result=result\n                ), sequence=next_seq)\n                \n                # Update read model\n                if result.status == AuthStatus.AUTHORIZED:\n                    await db.execute(\"\"\"\n                        UPDATE auth_request_state\n                        SET status = 'AUTHORIZED',\n                            processor_auth_id = $2,\n                            processor_name = $3,\n                            authorized_amount_cents = $4,\n                            authorization_code = $5,\n                            completed_at = NOW(),\n                            updated_at = NOW(),\n                            last_event_sequence = $6\n                        WHERE auth_request_id = $1\n                    \"\"\", auth_request_id, result.processor_auth_id, result.processor_name,\n                         result.authorized_amount_cents, result.authorization_code, next_seq)\n                \n                elif result.status == AuthStatus.DENIED:\n                    await db.execute(\"\"\"\n                        UPDATE auth_request_state\n                        SET status = 'DENIED',\n                            processor_name = $2,\n                            denial_code = $3,\n                            denial_reason = $4,\n                            completed_at = NOW(),\n                            updated_at = NOW(),\n                            last_event_sequence = $5\n                        WHERE auth_request_id = $1\n                    \"\"\", auth_request_id, result.processor_name, result.denial_code,\n                         result.denial_reason, next_seq)\n                \n                # COMMIT - event + read model together!\n            \n            # 9. Delete from queue (after successful commit)\n            await delete_message(message)\n            \n        except ProcessorTimeout:\n            # Retryable error - record attempt but don't update status to FAILED yet\n            retry_count = message.attributes['ApproximateReceiveCount']\n            \n            if retry_count >= MAX_RETRIES:\n                # Max retries exceeded - terminal failure\n                async with db.transaction():\n                    next_seq = await get_next_sequence(auth_request_id)\n                    await record_event(AuthAttemptFailed(\n                        auth_request_id=auth_request_id,\n                        error_code=\"processor_timeout\",\n                        is_retryable=False,\n                        retry_count=retry_count\n                    ), sequence=next_seq)\n                    \n                    await db.execute(\"\"\"\n                        UPDATE auth_request_state\n                        SET status = 'FAILED', updated_at = NOW(), last_event_sequence = $2\n                        WHERE auth_request_id = $1\n                    \"\"\", auth_request_id, next_seq)\n                \n                await send_to_dlq(message)\n                await delete_message(message)\n            else:\n                # Let it retry - just record the attempt\n                async with db.transaction():\n                    next_seq = await get_next_sequence(auth_request_id)\n                    await record_event(AuthAttemptFailed(\n                        auth_request_id=auth_request_id,\n                        error_code=\"processor_timeout\",\n                        is_retryable=True,\n                        retry_count=retry_count,\n                        next_retry_at=now() + exponential_backoff(retry_count)\n                    ), sequence=next_seq)\n                    \n                    # Don't update status - keep as PROCESSING\n                    await db.execute(\"\"\"\n                        UPDATE auth_request_state\n                        SET updated_at = NOW(), last_event_sequence = $2\n                        WHERE auth_request_id = $1\n                    \"\"\", auth_request_id, next_seq)\n                \n                # Don't delete - let visibility timeout expire for retry\n    \n    finally:\n        # Always release lock\n        await release_lock(auth_request_id)\n```\n\n## Behaviors\n\n### B1: Exactly-Once Processing\n**Given** an auth request is queued\n**When** multiple workers attempt to process\n**Then** only ONE worker acquires the lock\n**And** only ONE processor call is made\n**And** lock prevents duplicate attempts\n\n### B2: Atomic Event + Read Model Update\n**Given** worker processes auth successfully\n**When** writing result\n**Then** event AND read model are written in same transaction\n**And** both commit or both rollback (no partial state)\n**And** read model immediately reflects latest event\n\n### B3: Void Race Condition Handling\n**Given** void is requested while auth is being processed\n**When** worker checks for void event before calling processor\n**Then** if void event exists, skip processing\n**And** atomically write AuthRequestExpired event + update read model to EXPIRED\n\n### B4: Transient Failure Retry\n**Given** processor returns 500 or timeout\n**When** retry count < MAX_RETRIES (5)\n**Then** record AuthAttemptFailed event with is_retryable=true\n**And** status remains PROCESSING (not FAILED yet)\n**And** message becomes visible again after visibility timeout\n**And** retry with exponential backoff\n\n### B5: Terminal Failure - Invalid Token\n**Given** Payment Token Service returns 404 (token not found)\n**When** worker processes\n**Then** atomically write AuthAttemptFailed event + update read model to FAILED\n**And** send to dead letter queue\n**And** do NOT retry\n\n### B6: Terminal Failure - Expired Token\n**Given** Payment Token Service returns 410 (token expired)\n**When** worker processes\n**Then** atomically write AuthAttemptFailed event + update read model to FAILED\n**And** send to dead letter queue\n**And** do NOT retry\n\n### B7: Terminal Failure - Max Retries\n**Given** processor fails 5 times\n**When** retry count = MAX_RETRIES\n**Then** atomically write final AuthAttemptFailed event + update read model to FAILED\n**And** send to dead letter queue\n\n### B8: Processor Denial (Not a Failure)\n**Given** processor returns decline (e.g., insufficient funds)\n**When** worker processes\n**Then** atomically write AuthResponseReceived (status=DENIED) + update read model to DENIED\n**And** include denial_code and denial_reason in read model\n**And** this is NOT a failure (expected outcome)\n**And** mark as completed\n\n### B9: Lock Timeout (Worker Crash)\n**Given** worker crashes while holding lock\n**When** lock TTL expires (30 seconds)\n**Then** another worker can acquire lock\n**And** reprocess the request\n**And** read model tracks retry count via events\n\n### B10: Config-Based Processor Routing\n**Given** restaurant config specifies processor=\"stripe\"\n**When** worker processes auth request\n**Then** use Stripe client\n**When** config changes to processor=\"chase\"\n**Then** new requests use Chase client\n**And** replayed requests use current config\n\n### B11: Payment Token Service Unavailable\n**Given** Payment Token Service is down or timing out\n**When** worker attempts to decrypt token\n**Then** treat as retryable error (like processor timeout)\n**And** retry with backoff\n**And** after MAX_RETRIES, atomically write event + update to FAILED + send to DLQ\n\n## Payment Token Service Client\n\n```python\nclass PaymentTokenServiceClient:\n    def __init__(self, base_url: str, service_auth_token: str):\n        self.base_url = base_url\n        self.auth_token = service_auth_token\n    \n    async def decrypt(\n        self,\n        payment_token: str,\n        restaurant_id: str,\n        requesting_service: str\n    ) -> PaymentData:\n        \"\"\"\n        Calls Payment Token Service /internal/decrypt endpoint.\n        \n        Returns:\n            PaymentData with decrypted card details\n        \n        Raises:\n            TokenNotFound: 404 - token doesn't exist\n            TokenExpired: 410 - token expired\n            Forbidden: 403 - restaurant mismatch or unauthorized\n            ServiceUnavailable: 5xx or timeout\n        \"\"\"\n        response = await self.http_client.post(\n            f\"{self.base_url}/internal/v1/decrypt\",\n            headers={\n                \"Content-Type\": \"application/x-protobuf\",\n                \"X-Service-Auth\": self.auth_token,\n                \"X-Request-ID\": generate_correlation_id()\n            },\n            data=DecryptTokenRequest(\n                payment_token=payment_token,\n                restaurant_id=restaurant_id,\n                requesting_service=requesting_service\n            ).SerializeToString(),\n            timeout=5.0\n        )\n        \n        if response.status == 404:\n            raise TokenNotFound(f\"Token {payment_token} not found\")\n        elif response.status == 410:\n            raise TokenExpired(f\"Token {payment_token} expired\")\n        elif response.status == 403:\n            raise Forbidden(f\"Unauthorized access to token {payment_token}\")\n        elif response.status >= 500 or response.timeout:\n            raise ServiceUnavailable(\"Payment Token Service unavailable\")\n        \n        return DecryptTokenResponse.FromString(response.body).payment_data\n```\n\n## Processor Integration Interfaces\n\n### Stripe Processor\n```python\nclass StripeProcessor:\n    async def authorize(\n        self,\n        payment_data: PaymentData,\n        amount_cents: int,\n        currency: str,\n        config: dict\n    ) -> AuthorizationResult:\n        \"\"\"\n        Calls Stripe API: POST /v1/charges\n        \n        Errors:\n        - StripeCardError (decline) → DENIED\n        - StripeAPIError (5xx) → Retry\n        - StripeTimeout → Retry\n        \"\"\"\n        import stripe\n        \n        stripe.api_key = config['api_key']\n        \n        try:\n            charge = stripe.Charge.create(\n                amount=amount_cents,\n                currency=currency.lower(),\n                source={\n                    \"object\": \"card\",\n                    \"number\": payment_data.card_number,\n                    \"exp_month\": payment_data.exp_month,\n                    \"exp_year\": payment_data.exp_year,\n                    \"cvc\": payment_data.cvv,\n                    \"name\": payment_data.cardholder_name\n                },\n                capture=False,  # Authorization only, capture later\n                statement_descriptor=config.get('statement_descriptor')\n            )\n            \n            return AuthorizationResult(\n                status=AuthStatus.AUTHORIZED,\n                processor_auth_id=charge.id,\n                processor_name=\"stripe\",\n                authorized_amount_cents=charge.amount,\n                currency=charge.currency.upper(),\n                authorization_code=charge.authorization_code,\n                authorized_at=charge.created,\n                processor_metadata={\n                    \"balance_transaction\": charge.balance_transaction,\n                    \"network\": charge.payment_method_details.card.network\n                }\n            )\n            \n        except stripe.error.CardError as e:\n            # Card declined\n            return AuthorizationResult(\n                status=AuthStatus.DENIED,\n                processor_name=\"stripe\",\n                denial_code=e.code,\n                denial_reason=e.user_message,\n                processor_metadata={\"decline_code\": e.decline_code}\n            )\n        \n        except (stripe.error.APIError, stripe.error.RateLimitError) as e:\n            # Retryable errors\n            raise ProcessorTimeout(f\"Stripe API error: {e}\")\n```\n\n### Chase Processor (Future)\n```python\nclass ChaseProcessor:\n    async def authorize(...) -> AuthorizationResult:\n        \"\"\"\n        Calls Chase payment gateway\n        \"\"\"\n```\n\n## Error Classification\n\n**Retryable Errors (Transient):**\n- Processor timeout\n- Processor 500/503 errors\n- Network errors\n- Payment Token Service unavailable (5xx, timeout)\n\n**Non-Retryable Errors (Terminal):**\n- Invalid payment token (404 from Payment Token Service)\n- Expired payment token (410 from Payment Token Service)\n- Invalid request format (400)\n- Authentication failure (401)\n- Processor hard decline (but record as DENIED, not FAILED)\n\n## Database Operations\n\n### Acquire Lock\n```sql\nINSERT INTO auth_processing_locks (auth_request_id, worker_id, expires_at)\nVALUES ($1, $2, NOW() + INTERVAL '30 seconds')\nON CONFLICT (auth_request_id) DO NOTHING\nRETURNING auth_request_id;\n\n-- If returns NULL → lock already held\n```\n\n### Release Lock\n```sql\nDELETE FROM auth_processing_locks\nWHERE auth_request_id = $1 AND worker_id = $2;\n```\n\n### Check for Void\n```sql\nSELECT EXISTS (\n    SELECT 1 FROM payment_events\n    WHERE aggregate_id = $1\n      AND event_type = 'AuthVoidRequested'\n) AS is_voided;\n```\n\n### Get Next Sequence Number\n```sql\nSELECT COALESCE(MAX(sequence_number), 0) + 1\nFROM payment_events\nWHERE aggregate_id = $1;\n```\n\n### Cleanup Expired Locks (Background Task)\n```sql\nDELETE FROM auth_processing_locks\nWHERE expires_at < NOW();\n```\n\n## Configuration\n\n```yaml\nworker:\n  sqs_queue_url: \"https://sqs.us-east-1.amazonaws.com/.../auth-requests.fifo\"\n  batch_size: 1\n  wait_time_seconds: 20  # Long polling\n  visibility_timeout: 30\n  max_retries: 5\n  lock_ttl_seconds: 30\n  \npayment_token_service:\n  base_url: \"https://payment-token-service.internal\"\n  service_auth_token: \"<from-secrets-manager>\"\n  timeout_seconds: 5\n  max_retries: 2\n  \nprocessors:\n  stripe:\n    api_key: \"sk_live_...\"\n    timeout_seconds: 10\n  chase:\n    merchant_id: \"...\"\n    timeout_seconds: 15\n```\n\n## Dependencies\n- **Payment Token Service**: Internal /internal/decrypt endpoint\n- **Payment Processors**: Stripe, Chase, Worldpay APIs\n- **PostgreSQL**: Event store and read models (shared with Authorization API)\n- **SQS**: Auth request queue\n\n## Deployment\n- **ECS Service**: Long-running workers (recommended for stable connections)\n- **OR Lambda**: Triggered by SQS (for auto-scaling, but cold starts)\n- **Scaling**: Auto-scale based on SQS queue depth\n- **Health Check**: Worker heartbeat to CloudWatch\n\n## Monitoring & Observability\n- **Metrics**: Auth processing latency, success/failure rates, retry counts, lock contention\n- **Logs**: Structured logging (JSON) with correlation IDs\n- **Alarms**: \n  - Dead letter queue depth > 10\n  - Processing latency > p99\n  - Payment Token Service error rate > 5%\n- **Tracing**: X-Ray for distributed tracing across services\n\n## Testing Strategy\n- **Unit tests**: Lock acquisition, error classification, retry logic, transaction logic\n- **Integration tests**: Full flow with mocked Payment Token Service + mocked processor + real database\n- **Contract tests**: Verify Payment Token Service client matches actual API\n- **Transaction tests**: Verify event + read model are atomic (simulate failures)\n- **Chaos tests**: Simulate worker crashes, processor timeouts, lock expiry, Payment Token Service outages\n- **Load tests**: Sustained 300 QPS with queue backlog","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-10 04:35:31","updated_at":"2025-11-10 06:42:17","parent_id":null,"parent_uuid":null,"relationships":[{"from":"s-w5sf","from_type":"spec","to":"s-7ujm","to_type":"spec","type":"depends-on"},{"from":"s-w5sf","from_type":"spec","to":"s-94si","to_type":"spec","type":"implements"},{"from":"s-w5sf","from_type":"spec","to":"s-8c0t","to_type":"spec","type":"depends-on"}],"tags":["processor","service-spec","worker"]}
{"id":"s-4nmw","uuid":"4eaf2f58-1686-4093-b8d2-cae3dd56021f","title":"Detokenization Service","file_path":"specs/detokenization_service.md","content":"## DEPRECATED\n\nThis service has been merged into the **Payment Token Service** (s-7ujm).\n\nThe internal decryption endpoint `/internal/decrypt` is now part of the Payment Token Service, as both services share the same database and PCI compliance boundary.\n\nSee **Payment Token Service** spec for the combined service architecture.\n\n## Migration Notes\n- Auth Processor Workers now call Payment Token Service directly\n- Detokenization logic is part of Payment Token Service\n- Single database, single service for PCI zone\n- Internal `/internal/decrypt` endpoint documented in Payment Token Service spec\n","priority":0,"archived":1,"archived_at":"2025-11-10T06:47:51.946Z","created_at":"2025-11-10 04:35:32","updated_at":"2025-11-10 06:47:51","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["internal","pci-compliant","service-spec"]}
{"id":"s-8c0t","uuid":"c9d1a884-9641-4933-ab43-1161a52be508","title":"Shared Infrastructure Components","file_path":"specs/shared_infrastructure_components.md","content":"## Overview\n\nShared infrastructure, database schemas, queue definitions, and cross-cutting concerns used by all services. Includes **Transactional Outbox Pattern** for reliable event-to-queue delivery.\n\n## Database: PostgreSQL (Aurora)\n\n### Instance Configuration\n\n- **Engine**: PostgreSQL 15+ (Aurora Serverless v2 recommended)\n- **Multi-AZ**: Enabled for high availability\n- **Backups**: Automated daily snapshots, 30-day retention\n- **Read Replicas**: 1-2 for read scaling (status queries)\n- **Connection Pooling**: PgBouncer or RDS Proxy\n\n### Database Separation\n\n**Payment Token Database** (PCI zone):\n\n- Isolated RDS instance\n- Only accessible by Payment Token Service\n- Encrypted at rest with AWS KMS LALALA\n- Separate VPC subnet with strict security groups\n\n**Payment Events Database** (main):\n\n- Shared by Authorization API and Auth Processor Workers\n- Contains: payment\\_events, auth\\_request\\_state, outbox, configs\n\n```sql\n-- payment_tokens_db (isolated)\nCREATE DATABASE payment_tokens_db;\n\n-- payment_events_db (main)\nCREATE DATABASE payment_events_db;\n```\n\n## Queue Architecture (AWS SQS)\n\n### Auth Request Queue (FIFO)\n\n```\nName: payment-auth-requests.fifo\nType: FIFO\nDeduplication: Message deduplication ID = auth_request_id\nMessage Group ID: restaurant_id\nVisibility Timeout: 30 seconds\nMessage Retention: 4 days\nMax Receive Count: 5\nDead Letter Queue: payment-auth-requests-dlq.fifo\n```\n\n**Message Format:**\n\n```json\n{\n  \"auth_request_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"restaurant_id\": \"f47ac10b-58cc-4372-a567-0e02b2c3d479\",\n  \"created_at\": 1234567890\n}\n```\n\n**Population Method**: Outbox processor (runs in Authorization API) polls `outbox` table and sends to SQS\n\n### Void Request Queue (Standard)\n\n```\nName: payment-void-requests\nType: Standard (order not critical)\nVisibility Timeout: 60 seconds\nMessage Retention: 14 days (retry for up to X hours)\nMax Receive Count: 20 (more retries for voids)\nDead Letter Queue: payment-void-requests-dlq\n```\n\n### Dead Letter Queues\n\n**Auth Requests DLQ:**\n\n```\nName: payment-auth-requests-dlq.fifo\nPurpose: Terminal auth failures (invalid token, max retries)\nAlarm: > 10 messages\nRetention: 14 days (manual review)\n```\n\n**Void Requests DLQ:**\n\n```\nName: payment-void-requests-dlq\nPurpose: Failed voids after all retries\nAlarm: > 5 messages\n```\n\n## Event Store Schema (Detailed)\n\n```sql\n-- Main event store (append-only, never update/delete)\nCREATE TABLE payment_events (\n    id BIGSERIAL PRIMARY KEY,\n    event_id UUID UNIQUE NOT NULL DEFAULT gen_random_uuid(),\n    aggregate_id UUID NOT NULL,  -- auth_request_id, void_request_id, etc.\n    aggregate_type VARCHAR(50) NOT NULL,  -- 'auth_request', 'void_request'\n    event_type VARCHAR(100) NOT NULL,\n    event_data BYTEA NOT NULL,  -- Protobuf serialized\n    metadata JSONB DEFAULT '{}'::jsonb,\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    sequence_number INTEGER NOT NULL,\n\n    CONSTRAINT unique_aggregate_sequence UNIQUE(aggregate_id, sequence_number),\n    CONSTRAINT check_sequence_positive CHECK (sequence_number > 0)\n);\n\n-- Indexes for fast queries\nCREATE INDEX idx_aggregate_events ON payment_events(aggregate_id, sequence_number);\nCREATE INDEX idx_event_type_created ON payment_events(event_type, created_at DESC);\nCREATE INDEX idx_created_at ON payment_events(created_at DESC);\n\n-- Partitioning for archival (optional, for future)\n-- Partition by created_at monthly for easy archival\n```\n\n## Transactional Outbox Pattern\n\n### Outbox Table\n\n**Critical for reliable event → queue delivery with at-least-once guarantee.**\n\n```sql\n-- Outbox for reliable queue delivery (Transactional Outbox Pattern)\nCREATE TABLE outbox (\n    id BIGSERIAL PRIMARY KEY,\n    aggregate_id UUID NOT NULL,  -- auth_request_id or void_request_id\n    message_type VARCHAR(100) NOT NULL,  -- 'auth_request_queued', 'void_request_queued'\n    payload JSONB NOT NULL,  -- Message body for SQS\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    processed_at TIMESTAMP,  -- NULL = unprocessed, NOT NULL = sent to SQS\n\n    INDEX idx_unprocessed (created_at) WHERE processed_at IS NULL  -- Partial index for efficiency!\n);\n```\n\n**How it works:**\n\n1. Authorization API writes event + read model + outbox entry in **single transaction**\n1. Outbox processor (background thread in Authorization API) polls `WHERE processed_at IS NULL`\n1. Sends messages to SQS\n1. Marks as processed: `UPDATE outbox SET processed_at = NOW()`\n\n**Guarantees:**\n\n- ✅ Atomic write (event + outbox)\n- ✅ At-least-once delivery to SQS\n- ✅ No message loss (survives crashes)\n- ✅ SQS FIFO deduplication handles duplicates\n\n### Outbox Cleanup (Optional)\n\nProcessed outbox entries can be archived/deleted after retention period:\n\n```sql\n-- Delete processed outbox entries older than 7 days\nDELETE FROM outbox\nWHERE processed_at < NOW() - INTERVAL '7 days';\n```\n\nRun daily as maintenance job.\n\n## Read Models (Materialized Views)\n\n### Auth Request State (Optimized for Queries)\n\n**Updated synchronously in same transaction as events (by Authorization API and Workers).**\n\n```sql\nCREATE TABLE auth_request_state (\n    auth_request_id UUID PRIMARY KEY,\n    restaurant_id UUID NOT NULL,\n    payment_token VARCHAR(64) NOT NULL,\n\n    -- Current state\n    status VARCHAR(20) NOT NULL,  -- PENDING, PROCESSING, AUTHORIZED, DENIED, etc.\n\n    -- Request details\n    amount_cents BIGINT NOT NULL,\n    currency VARCHAR(3) NOT NULL,\n\n    -- Result (populated when completed by worker)\n    processor_auth_id VARCHAR(255),\n    processor_name VARCHAR(50),\n    authorized_amount_cents BIGINT,\n    authorization_code VARCHAR(100),\n\n    -- Denial details (if DENIED)\n    denial_code VARCHAR(50),\n    denial_reason TEXT,\n\n    -- Timestamps\n    created_at TIMESTAMP NOT NULL,\n    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    completed_at TIMESTAMP,\n\n    -- Metadata\n    metadata JSONB DEFAULT '{}'::jsonb,\n\n    -- Event sourcing bookkeeping\n    last_event_sequence INTEGER NOT NULL DEFAULT 0,\n    last_event_id UUID,\n\n    -- Indexes\n    CONSTRAINT check_status CHECK (status IN ('PENDING', 'PROCESSING', 'AUTHORIZED', 'DENIED', 'FAILED', 'VOIDED', 'EXPIRED'))\n);\n\nCREATE INDEX idx_restaurant_created ON auth_request_state(restaurant_id, created_at DESC);\nCREATE INDEX idx_status ON auth_request_state(status) WHERE status IN ('PENDING', 'PROCESSING');\nCREATE INDEX idx_payment_token ON auth_request_state(payment_token);\nCREATE INDEX idx_completed_at ON auth_request_state(completed_at DESC) WHERE completed_at IS NOT NULL;\n\n-- Auto-update updated_at trigger\nCREATE OR REPLACE FUNCTION update_updated_at_column()\nRETURNS TRIGGER AS $$\nBEGIN\n   NEW.updated_at = NOW();\n   RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER update_auth_request_state_updated_at\n    BEFORE UPDATE ON auth_request_state\n    FOR EACH ROW\n    EXECUTE FUNCTION update_updated_at_column();\n```\n\n### Restaurant Payment Configs (Cache)\n\n```sql\nCREATE TABLE restaurant_payment_configs (\n    restaurant_id UUID PRIMARY KEY,\n    config_version VARCHAR(50) NOT NULL,\n\n    -- Processor selection\n    processor_name VARCHAR(50) NOT NULL,  -- \"stripe\", \"chase\", \"worldpay\"\n\n    -- Processor-specific config (JSON)\n    processor_config JSONB NOT NULL,\n    -- Example for Stripe:\n    -- {\n    --   \"stripe_api_key\": \"sk_test_...\",\n    --   \"statement_descriptor\": \"RESTAURANT NAME\"\n    -- }\n\n    -- Metadata\n    is_active BOOLEAN NOT NULL DEFAULT true,\n    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n\n    CONSTRAINT check_processor CHECK (processor_name IN ('stripe', 'chase', 'worldpay'))\n);\n\nCREATE INDEX idx_active_configs ON restaurant_payment_configs(is_active) WHERE is_active = true;\n\n-- Initial seed data (for testing - single restaurant with Stripe)\nINSERT INTO restaurant_payment_configs (restaurant_id, config_version, processor_name, processor_config, updated_at)\nVALUES (\n    '00000000-0000-0000-0000-000000000001'::UUID,\n    'v1',\n    'stripe',\n    '{\"stripe_api_key\": \"sk_test_...\", \"statement_descriptor\": \"TEST RESTAURANT\"}'::JSONB,\n    NOW()\n);\n```\n\n### Idempotency Keys\n\n```sql\nCREATE TABLE auth_idempotency_keys (\n    idempotency_key VARCHAR(255) NOT NULL,\n    restaurant_id UUID NOT NULL,\n    auth_request_id UUID NOT NULL,\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    expires_at TIMESTAMP NOT NULL DEFAULT NOW() + INTERVAL '24 hours',\n\n    PRIMARY KEY (idempotency_key, restaurant_id)\n);\n\nCREATE INDEX idx_idempotency_expires ON auth_idempotency_keys(expires_at);\n\n-- Cleanup expired keys (background job)\nCREATE INDEX idx_expired_keys ON auth_idempotency_keys(expires_at) WHERE expires_at < NOW();\n```\n\n### Processing Locks\n\n```sql\nCREATE TABLE auth_processing_locks (\n    auth_request_id UUID PRIMARY KEY,\n    worker_id VARCHAR(255) NOT NULL,\n    locked_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    expires_at TIMESTAMP NOT NULL DEFAULT NOW() + INTERVAL '30 seconds',\n\n    CONSTRAINT check_expires_after_locked CHECK (expires_at > locked_at)\n);\n\nCREATE INDEX idx_lock_expires ON auth_processing_locks(expires_at);\n\n-- Cleanup expired locks (background job)\n-- Note: This is also done by workers, but good hygiene to have separate cleanup\n```\n\n## Protobuf Definitions (Shared)\n\nAll services share common protobuf definitions for consistency.\n\n**See Issue [[i-xxxx]]: Complete Protobuf Definitions** for full `.proto` files.\n\n```protobuf\nsyntax = \"proto3\";\n\npackage payments.v1;\n\n// Common types\nmessage Money {\n  int64 amount_cents = 1;\n  string currency = 2;  // ISO 4217\n}\n\nmessage Timestamp {\n  int64 seconds = 1;\n  int32 nanos = 2;\n}\n\n// Status enums\nenum AuthStatus {\n  AUTH_STATUS_UNSPECIFIED = 0;\n  AUTH_STATUS_PENDING = 1;\n  AUTH_STATUS_PROCESSING = 2;\n  AUTH_STATUS_AUTHORIZED = 3;\n  AUTH_STATUS_DENIED = 4;\n  AUTH_STATUS_FAILED = 5;\n  AUTH_STATUS_VOIDED = 6;\n  AUTH_STATUS_EXPIRED = 7;\n}\n\n// Event base\nmessage EventMetadata {\n  string event_id = 1;\n  string correlation_id = 2;\n  string causation_id = 3;\n  Timestamp created_at = 4;\n}\n\n// Error types\nmessage ErrorDetails {\n  string error_code = 1;\n  string error_message = 2;\n  bool is_retryable = 3;\n  int32 retry_count = 4;\n}\n```\n\n## Archival Strategy\n\n### Hot Data (0-30 days)\n\n- Stored in primary PostgreSQL database\n- Full query capabilities\n- Indexed for fast lookups\n\n### Warm Data (30-365 days)\n\n- Move to separate archive table or database\n- Partitioned by month\n- Less frequently accessed\n- Consider read replicas for queries\n\n### Cold Data (365+ days)\n\n- Export to S3 (Parquet format)\n- Queryable via AWS Athena\n- Compressed and encrypted\n- Retained for 7 years (PCI compliance)\n\n### Archival Process (Cron Job)\n\n```sql\n-- Monthly job: Archive events older than 30 days\nINSERT INTO payment_events_archive\nSELECT * FROM payment_events\nWHERE created_at < NOW() - INTERVAL '30 days';\n\nDELETE FROM payment_events\nWHERE created_at < NOW() - INTERVAL '30 days';\n\n-- Export to S3\nCOPY payment_events_archive TO 's3://payment-events/archive/2024-01.parquet'\nWITH (FORMAT PARQUET, COMPRESSION GZIP);\n```\n\n## Monitoring & Observability\n\n### Key Metrics\n\n- **Auth Request Latency**: p50, p95, p99 from POST /authorize to completion\n- **Queue Depth**: Number of pending messages in SQS\n- **Outbox Depth**: Number of unprocessed outbox entries (`COUNT(*) WHERE processed_at IS NULL`)\n- **Worker Processing Rate**: Messages processed per second\n- **Error Rates**: Failed auths, DLQ depth\n- **Lock Contention**: Failed lock acquisitions\n\n### CloudWatch Alarms\n\n- **DLQ depth > 10** → Page on-call\n- **Outbox unprocessed > 1000** → Warning (outbox processor may be down)\n- **Auth latency p99 > 10s** → Warning\n- **Worker processing rate drop > 50%** → Warning\n- **Database CPU > 80%** → Scale up\n\n### Structured Logging Format\n\n```json\n{\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"level\": \"INFO\",\n  \"service\": \"auth-processor-worker\",\n  \"correlation_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"auth_request_id\": \"f47ac10b-58cc-4372-a567-0e02b2c3d479\",\n  \"event\": \"auth_attempt_started\",\n  \"duration_ms\": 150,\n  \"processor\": \"stripe\"\n}\n```\n\n## Security & Compliance\n\n### PCI DSS Requirements\n\n- Payment Token Service isolated (separate VPC, database)\n- All payment data encrypted at rest (AWS KMS)\n- All connections use TLS 1.3\n- Audit logs immutable and retained\n- No payment data in application logs\n\n### Network Architecture\n\n```\n┌─────────────────────────────────────────────────────┐\n│                  Public Subnet                      │\n│  - API Gateway / Load Balancer                      │\n└─────────────────────────────────────────────────────┘\n                      │\n┌─────────────────────────────────────────────────────┐\n│                 Private Subnet (App)                │\n│  - Authorization API (with outbox processor)        │\n│  - Auth Processor Workers                           │\n└─────────────────────────────────────────────────────┘\n                      │\n┌─────────────────────────────────────────────────────┐\n│             Private Subnet (PCI Zone)               │\n│  - Payment Token Service                            │\n│  - Payment Token Database (isolated RDS)            │\n└─────────────────────────────────────────────────────┘\n                      │\n┌─────────────────────────────────────────────────────┐\n│                 Private Subnet (Data)               │\n│  - Payment Events Database (RDS Aurora)             │\n│    - payment_events                                 │\n│    - auth_request_state                             │\n│    - outbox                                         │\n│  - ElastiCache (optional, for caching)              │\n└─────────────────────────────────────────────────────┘\n```\n\n## Testing Infrastructure\n\n### LocalStack (for local development)\n\n```yaml\n# docker-compose.yml\nservices:\n  localstack:\n    image: localstack/localstack\n    ports:\n      - \"4566:4566\"\n    environment:\n      - SERVICES=sqs,kms\n      - DEBUG=1\n\n  postgres:\n    image: postgres:15\n    ports:\n      - \"5432:5432\"\n    environment:\n      - POSTGRES_PASSWORD=password\n      - POSTGRES_DB=payment_events_db\n    volumes:\n      - ./init.sql:/docker-entrypoint-initdb.d/init.sql\n```\n\n### init.sql (Database Bootstrap)\n\n```sql\n-- Run all CREATE TABLE statements from above\n-- Includes: payment_events, outbox, auth_request_state, etc.\n```\n\n### Test Data Fixtures\n\n- Factory pattern for creating test events\n- Seed data for restaurant configs\n- Mock payment processor responses\n\n## Configuration Management\n\nAll configuration stored in AWS SSM Parameter Store or Secrets Manager:\n\n```\n/payments/production/database/url\n/payments/production/sqs/auth-requests-queue-url\n/payments/production/stripe/api-key (SecretString)\n/payments/production/token-service/internal-api-url\n```\n\n## Background Jobs\n\n### Outbox Processor (in Authorization API)\n\n- **Frequency**: Every 100ms\n- **Query**: `SELECT * FROM outbox WHERE processed_at IS NULL ORDER BY created_at LIMIT 100 FOR UPDATE SKIP LOCKED`\n- **Action**: Send to SQS, mark as processed\n\n### Expired Idempotency Keys Cleanup\n\n- **Frequency**: Hourly\n- **Query**: `DELETE FROM auth_idempotency_keys WHERE expires_at < NOW()`\n\n### Expired Locks Cleanup\n\n- **Frequency**: Every minute\n- **Query**: `DELETE FROM auth_processing_locks WHERE expires_at < NOW()`\n\n### Outbox Cleanup (Optional)\n\n- **Frequency**: Daily\n- **Query**: `DELETE FROM outbox WHERE processed_at < NOW() - INTERVAL '7 days'`","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-10 04:35:33","updated_at":"2025-11-10 18:14:47","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["database","infrastructure","shared"]}
{"id":"s-94si","uuid":"a5b75599-960a-478a-9832-126b098c2faf","title":"Event Sourcing & Read Model Architecture","file_path":"specs/event_sourcing_read_model_architecture.md","content":"## Overview\nComprehensive guide to the event sourcing and read model architecture used across the payments infrastructure. This document clarifies **transaction boundaries**, **read model update patterns**, and **outbox-based queue integration**.\n\n## Core Principles\n\n1. **Events are immutable source of truth** - stored in `payment_events` table, never updated or deleted\n2. **Read models are derived projections** - updated synchronously in same transaction as events\n3. **Outbox pattern ensures reliable queue delivery** - atomic writes, at-least-once delivery\n4. **Strong consistency for reads** - no eventual consistency delay for status queries\n\n## Transaction Boundaries\n\n### Authorization API: POST /authorize\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                     BEGIN TRANSACTION                        │\n│                                                              │\n│  1. Check idempotency (SELECT)                               │\n│  2. Write event: AuthRequestCreated                          │\n│     INSERT INTO payment_events (...)                         │\n│                                                              │\n│  3. Write read model                                         │\n│     INSERT INTO auth_request_state (status='PENDING', ...)   │\n│                                                              │\n│  4. Write outbox entry                                       │\n│     INSERT INTO outbox (message_type='auth_request_queued')  │\n│                                                              │\n│  5. Write idempotency key                                    │\n│     INSERT INTO auth_idempotency_keys (...)                  │\n│                                                              │\n│                      COMMIT                                  │\n└─────────────────────────────────────────────────────────────┘\n\nResult: Event + Read Model + Outbox + Idempotency written atomically\nIf any step fails → entire transaction rolls back\n```\n\n### Auth Processor Worker: Process Request\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│  1. Dequeue from SQS (visibility timeout starts)             │\n│  2. Acquire lock (INSERT INTO auth_processing_locks)         │\n│  3. Check for void event (SELECT)                            │\n│  4. Fetch config (SELECT)                                    │\n│  5. Call Payment Token Service (external API)                │\n│  6. Call Payment Processor (external API - Stripe)           │\n│                                                              │\n│                     BEGIN TRANSACTION                        │\n│                                                              │\n│  7. Write event: AuthResponseReceived                        │\n│     INSERT INTO payment_events (...)                         │\n│                                                              │\n│  8. Update read model                                        │\n│     UPDATE auth_request_state                                │\n│     SET status='AUTHORIZED', processor_auth_id=..., ...      │\n│                                                              │\n│                      COMMIT                                  │\n│                                                              │\n│  9. Delete SQS message (ACK)                                 │\n│  10. Release lock (DELETE FROM auth_processing_locks)        │\n└─────────────────────────────────────────────────────────────┘\n\nResult: Event + Read Model updated atomically\nExternal API calls happen BEFORE transaction (if they fail, retry via SQS)\n```\n\n## Read Model Update Patterns\n\n### Pattern: Synchronous Updates (RECOMMENDED)\n\n**Both Authorization API and Workers update read models in same transaction as events.**\n\n**Advantages:**\n- ✅ Strong consistency - read models always reflect latest events\n- ✅ No delay for status queries\n- ✅ Simpler architecture - no separate projection service\n- ✅ Transactional guarantees\n\n**Trade-offs:**\n- ⚠️ Read model logic distributed across services (API writes PENDING, worker writes AUTHORIZED)\n- ⚠️ Cannot rebuild read models from events alone (need application logic)\n\n**When to use:** When you need immediate consistency for user-facing queries (like payment status).\n\n### Alternative Pattern: Event-Driven Projections (NOT USED)\n\nA separate projection service listens to events and updates read models asynchronously.\n\n**NOT recommended for this system** because:\n- ❌ Eventual consistency not acceptable for payment status (users expect immediate updates)\n- ❌ Adds complexity (another service to maintain)\n- ❌ 100-500ms delay unacceptable for POST /authorize 5-second polling\n\n**When to use:** Analytics, reporting, or non-critical read models where eventual consistency is acceptable.\n\n## Outbox Pattern Details\n\n### Purpose\n\nEnsure **atomic** write of events + queue messages without distributed transactions.\n\n### How It Works\n\n```\nAuthorization API Transaction:\n  1. Write event to payment_events\n  2. Write read model to auth_request_state\n  3. Write outbox entry to outbox table\n  ───────────────────────────────────────\n  COMMIT (all succeed or all fail)\n\nBackground Outbox Processor (every 100ms):\n  1. SELECT * FROM outbox WHERE processed_at IS NULL FOR UPDATE SKIP LOCKED\n  2. Send each message to SQS\n  3. UPDATE outbox SET processed_at = NOW()\n```\n\n### Guarantees\n\n| Scenario | Outcome |\n|----------|---------|\n| Transaction commits | Outbox entry exists, will be sent to SQS |\n| Transaction rolls back | No outbox entry, no SQS message |\n| Outbox processor crashes | Unprocessed messages remain in DB, retried on restart |\n| SQS send fails | Outbox entry remains unprocessed, retried on next poll |\n| Duplicate SQS sends | SQS FIFO deduplication prevents duplicate processing |\n\n### Failure Modes\n\n**Q: What if outbox processor is down for extended period?**  \nA: Outbox entries queue up in database. Alarms trigger at > 1000 unprocessed. Messages sent when processor restarts.\n\n**Q: What if database fails after SQS send but before marking as processed?**  \nA: Message sent twice. SQS FIFO deduplication (MessageDeduplicationId=auth_request_id) prevents duplicate processing by worker.\n\n**Q: What if outbox table fills up?**  \nA: Run daily cleanup job: `DELETE FROM outbox WHERE processed_at < NOW() - INTERVAL '7 days'`. Monitor disk usage.\n\n## Event Replay & Debugging\n\n### Replaying Events\n\nEvents are immutable, so you can replay them to rebuild state:\n\n```sql\n-- Rebuild auth_request_state for a specific request\nDELETE FROM auth_request_state WHERE auth_request_id = $1;\n\nSELECT aggregate_id, event_type, event_data, sequence_number\nFROM payment_events\nWHERE aggregate_id = $1\nORDER BY sequence_number;\n\n-- Apply each event in order to reconstruct state\n```\n\n### Debugging Payment Flow\n\n```sql\n-- See full history of an auth request\nSELECT \n    event_type,\n    event_data,\n    created_at,\n    sequence_number\nFROM payment_events\nWHERE aggregate_id = '550e8400-e29b-41d4-a716-446655440000'\nORDER BY sequence_number;\n\n-- Check current state\nSELECT * FROM auth_request_state\nWHERE auth_request_id = '550e8400-e29b-41d4-a716-446655440000';\n\n-- Check if queued\nSELECT * FROM outbox\nWHERE aggregate_id = '550e8400-e29b-41d4-a716-446655440000';\n```\n\n## Consistency Checks\n\n### Event vs Read Model Consistency\n\nVerify read model is up-to-date:\n\n```sql\n-- Check if read model is behind\nSELECT \n    ars.auth_request_id,\n    ars.status,\n    ars.last_event_sequence,\n    (SELECT MAX(sequence_number) FROM payment_events WHERE aggregate_id = ars.auth_request_id) AS latest_event_sequence\nFROM auth_request_state ars\nWHERE ars.last_event_sequence < (SELECT MAX(sequence_number) FROM payment_events WHERE aggregate_id = ars.auth_request_id);\n```\n\nIf rows returned → read model is stale (should never happen if transactions are used correctly).\n\n### Outbox Lag\n\nMonitor unprocessed outbox entries:\n\n```sql\n-- Check outbox depth\nSELECT COUNT(*) AS unprocessed_count\nFROM outbox\nWHERE processed_at IS NULL;\n\n-- Check oldest unprocessed message\nSELECT MIN(created_at) AS oldest_unprocessed\nFROM outbox\nWHERE processed_at IS NULL;\n```\n\nAlert if `unprocessed_count > 1000` or `oldest_unprocessed > 5 minutes`.\n\n## Idempotency\n\n### Request-Level Idempotency\n\nClient provides `X-Idempotency-Key` header:\n\n```\nPOST /authorize\nX-Idempotency-Key: 8f7d6c5b-4a3e-2d1c-0b9a-8e7f6d5c4b3a\n\n→ Same idempotency key within 24 hours returns same auth_request_id\n```\n\n**Implementation:**\n```sql\n-- Check idempotency\nSELECT auth_request_id FROM auth_idempotency_keys\nWHERE idempotency_key = $1 AND restaurant_id = $2;\n\n-- If exists, return existing auth_request\n-- If not exists, create new auth request + write idempotency key\n```\n\n### Event-Level Idempotency\n\nEach event has unique `event_id` (UUID):\n\n```sql\nINSERT INTO payment_events (event_id, aggregate_id, event_type, ...)\nVALUES ($1, $2, $3, ...)\nON CONFLICT (event_id) DO NOTHING;\n```\n\nPrevents duplicate events if retry occurs.\n\n### Outbox-Level Idempotency\n\nSQS FIFO deduplication:\n\n```python\nsqs.send_message(\n    QueueUrl=\"auth-requests.fifo\",\n    MessageBody=payload,\n    MessageDeduplicationId=auth_request_id,  # Deduplication key\n    MessageGroupId=restaurant_id\n)\n```\n\nIf same `auth_request_id` sent twice within 5 minutes → SQS ignores duplicate.\n\n## Sequence Diagrams\n\n### Happy Path: POST /authorize → Worker → Response\n\n```\nClient          Auth API         Outbox Proc    SQS Queue      Worker          Processor\n  │                │                 │              │             │                │\n  ├─POST /auth────>│                 │              │             │                │\n  │                ├─BEGIN TX────────┤              │             │                │\n  │                ├─Write Event─────┤              │             │                │\n  │                ├─Write Read Model│              │             │                │\n  │                ├─Write Outbox────┤              │             │                │\n  │                ├─COMMIT──────────┤              │             │                │\n  │                │                 │              │             │                │\n  │<─202 Accepted──┤ (returns immediately)          │             │                │\n  │                │                 │              │             │                │\n  │                │   (100ms later) │              │             │                │\n  │                │                 ├─Poll Outbox─>│             │                │\n  │                │                 ├─Send to SQS──>│            │                │\n  │                │                 ├─Mark Processed              │                │\n  │                │                 │              │             │                │\n  │                │                 │              ├─Dequeue────>│                │\n  │                │                 │              │             ├─Decrypt Token─>│\n  │                │                 │              │             ├─Authorize─────>│\n  │                │                 │              │             │<─Response──────┤\n  │                │                 │              │             │                │\n  │                │                 │              │             ├─BEGIN TX───────┤\n  │                │                 │              │             ├─Write Event────┤\n  │                │                 │              │             ├─Update Read Mdl┤\n  │                │                 │              │             ├─COMMIT─────────┤\n  │                │                 │              │             ├─Delete Msg─────┤\n  │                │                 │              │             │                │\n  ├─GET /status───>│                 │              │             │                │\n  │<─200 AUTHORIZED┤ (reads from read model)        │             │                │\n```\n\n### Error Path: Invalid Token\n\n```\nClient          Auth API         Outbox Proc    SQS Queue      Worker          Token Svc\n  │                │                 │              │             │                │\n  ├─POST /auth────>│                 │              │             │                │\n  │                ├─[Transaction: write event + read model + outbox]             │\n  │<─202 Accepted──┤                 │              │             │                │\n  │                │                 ├─[Outbox sends to SQS]─────>│                │\n  │                │                 │              ├─Dequeue────>│                │\n  │                │                 │              │             ├─Decrypt Token─>│\n  │                │                 │              │             │<─404 Not Found─┤\n  │                │                 │              │             │                │\n  │                │                 │              │             ├─BEGIN TX───────┤\n  │                │                 │              │             ├─Write Event────┤\n  │                │                 │              │             │  (AuthAttempt  │\n  │                │                 │              │             │   Failed)      │\n  │                │                 │              │             ├─Update Read Mdl┤\n  │                │                 │              │             │  (status=FAILED│\n  │                │                 │              │             ├─COMMIT─────────┤\n  │                │                 │              │             ├─Send to DLQ────┤\n  │                │                 │              │             ├─Delete Msg─────┤\n  │                │                 │              │             │                │\n  ├─GET /status───>│                 │              │             │                │\n  │<─200 FAILED────┤ (reads from read model)        │             │                │\n```\n\n## Best Practices\n\n### DO:\n- ✅ Always write events + read models in same transaction\n- ✅ Use outbox pattern for queue messages\n- ✅ Include sequence numbers on events for ordering\n- ✅ Store protobuf-serialized events for forward/backward compatibility\n- ✅ Monitor outbox depth and event lag\n\n### DON'T:\n- ❌ Never update or delete events\n- ❌ Don't send to SQS directly from application code (use outbox)\n- ❌ Don't update read models outside of transactions\n- ❌ Don't skip sequence numbers (use `MAX(sequence_number) + 1`)\n- ❌ Don't store sensitive data in event metadata\n\n## Testing Strategy\n\n### Unit Tests\n- Event serialization/deserialization\n- Read model projection logic\n- Idempotency key checks\n\n### Integration Tests\n- Full transaction flows (event + read model + outbox)\n- Outbox processor sends to LocalStack SQS\n- Worker processes and updates read model\n\n### Chaos Tests\n- Kill outbox processor mid-processing → verify messages retried\n- Simulate transaction failures → verify rollback\n- Send duplicate SQS messages → verify deduplication\n\n### Consistency Tests\n- Verify read model matches event history\n- Verify outbox eventually empties (no stuck messages)\n- Verify no lost messages (every event has outbox entry)\n\n## References\n\n- **Transactional Outbox Pattern**: https://microservices.io/patterns/data/transactional-outbox.html\n- **Event Sourcing**: https://martinfowler.com/eaaDev/EventSourcing.html\n- **CQRS**: https://martinfowler.com/bliki/CQRS.html","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-10 06:45:11","updated_at":"2025-11-10 06:45:11","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","event-sourcing","patterns"]}
{"id":"s-5for","uuid":"b5cae9c7-0d03-4083-bb77-624518c8de67","title":"Payment Token Service - AWS Deployment Infrastructure","file_path":"specs/payment_token_service_aws_deployment_infrastructur.md","content":"## Overview\n\nTerraform infrastructure specification for deploying the Payment Token Service ([[s-7ujm]]) to AWS with PCI DSS compliance, network isolation, autoscaling, and high availability. This spec defines the complete AWS infrastructure stack required for production deployment.\n\n## Architecture Principles\n\n- **PCI Compliance**: Isolated VPC subnet, encrypted at rest/in transit, audit logging, no cardholder data in logs\n- **Zero Trust**: Network segmentation, mTLS for internal APIs, principle of least privilege\n- **High Availability**: Multi-AZ deployment, autoscaling, health checks, automatic failover\n- **Observability**: Comprehensive logging, metrics, tracing, and alerting\n- **Immutable Infrastructure**: Container-based deployments, blue-green strategy, infrastructure as code\n\n## AWS Services Used\n\n- **ECS Fargate**: Serverless container orchestration (no EC2 management)\n- **RDS PostgreSQL**: Isolated database instance for payment_tokens_db\n- **Application Load Balancer (ALB)**: Public API traffic distribution\n- **Network Load Balancer (NLB)**: Internal API for auth workers (VPC-only)\n- **API Gateway**: Public REST API with authentication, rate limiting, WAF\n- **KMS**: Base Derivation Key (BDK) and encryption key management\n- **Secrets Manager**: Database credentials, API keys, processor secrets\n- **CloudWatch**: Metrics, logs, alarms, dashboards\n- **VPC**: Network isolation with PCI-compliant subnet\n- **ECR**: Docker image registry\n- **Route 53**: DNS management\n- **Certificate Manager (ACM)**: TLS certificates\n\n## Network Architecture\n\n### VPC Design\n\n```\nVPC: payments-infra-vpc (10.0.0.0/16)\n├── Public Subnets (Internet-facing)\n│   ├── 10.0.1.0/24 (us-east-1a) - ALB, NAT Gateway\n│   └── 10.0.2.0/24 (us-east-1b) - ALB, NAT Gateway\n│\n├── Private Subnets - Application Tier\n│   ├── 10.0.10.0/24 (us-east-1a) - Authorization API, Auth Workers\n│   └── 10.0.11.0/24 (us-east-1b) - Authorization API, Auth Workers\n│\n├── Private Subnets - PCI Zone (ISOLATED)\n│   ├── 10.0.20.0/24 (us-east-1a) - Payment Token Service ECS Tasks\n│   └── 10.0.21.0/24 (us-east-1b) - Payment Token Service ECS Tasks\n│\n└── Private Subnets - Data Tier\n    ├── 10.0.30.0/24 (us-east-1a) - RDS payment_tokens_db, payment_events_db\n    └── 10.0.31.0/24 (us-east-1b) - RDS replicas\n```\n\n### Security Groups\n\n**SG-ALB-Public** (API Gateway VPC Link → Public ALB):\n```\nInbound:\n  - 443 from 0.0.0.0/0 (HTTPS only, via API Gateway VPC Link)\nOutbound:\n  - 8000 to SG-PTS-ECS (Payment Token Service)\n```\n\n**SG-NLB-Internal** (Auth Workers → Internal NLB):\n```\nInbound:\n  - 8001 from SG-Auth-Workers (internal /decrypt endpoint)\nOutbound:\n  - 8001 to SG-PTS-ECS\n```\n\n**SG-PTS-ECS** (Payment Token Service containers):\n```\nInbound:\n  - 8000 from SG-ALB-Public (public API)\n  - 8001 from SG-NLB-Internal (internal API)\nOutbound:\n  - 5432 to SG-RDS-PTS (PostgreSQL payment_tokens_db)\n  - 443 to AWS KMS endpoint (VPC endpoint)\n  - 443 to AWS Secrets Manager endpoint (VPC endpoint)\n  - 443 to CloudWatch Logs endpoint (VPC endpoint)\n```\n\n**SG-RDS-PTS** (Isolated RDS for payment_tokens_db):\n```\nInbound:\n  - 5432 from SG-PTS-ECS ONLY\nOutbound:\n  - None (database is destination only)\n```\n\n**SG-Auth-Workers** (Authorization processor workers):\n```\nOutbound:\n  - 8001 to SG-NLB-Internal (Payment Token Service internal API)\n```\n\n### VPC Endpoints (PrivateLink)\n\nTo avoid NAT Gateway costs and improve security, deploy VPC endpoints:\n\n- **com.amazonaws.us-east-1.kms** - KMS API calls\n- **com.amazonaws.us-east-1.secretsmanager** - Secrets retrieval\n- **com.amazonaws.us-east-1.logs** - CloudWatch Logs\n- **com.amazonaws.us-east-1.ecr.dkr** - ECR Docker registry\n- **com.amazonaws.us-east-1.ecr.api** - ECR API\n- **com.amazonaws.us-east-1.s3** (Gateway endpoint) - ECR layer storage\n\n## ECS Fargate Configuration\n\n### Cluster\n\n```hcl\nresource \"aws_ecs_cluster\" \"payment_token_service\" {\n  name = \"payment-token-service-${var.environment}\"\n\n  setting {\n    name  = \"containerInsights\"\n    value = \"enabled\"  # CloudWatch Container Insights\n  }\n\n  configuration {\n    execute_command_configuration {\n      logging = \"OVERRIDE\"\n      log_configuration {\n        cloud_watch_log_group_name = \"/ecs/payment-token-service\"\n      }\n    }\n  }\n}\n```\n\n### Task Definition\n\n```hcl\nresource \"aws_ecs_task_definition\" \"payment_token_service\" {\n  family                   = \"payment-token-service\"\n  network_mode             = \"awsvpc\"\n  requires_compatibilities = [\"FARGATE\"]\n  cpu                      = var.task_cpu       # 512, 1024, 2048, 4096\n  memory                   = var.task_memory    # 1024, 2048, 4096, 8192\n  execution_role_arn       = aws_iam_role.ecs_execution.arn\n  task_role_arn            = aws_iam_role.ecs_task.arn\n\n  container_definitions = jsonencode([{\n    name  = \"payment-token-service\"\n    image = \"${aws_ecr_repository.payment_token_service.repository_url}:${var.image_tag}\"\n    \n    portMappings = [\n      {\n        containerPort = 8000\n        protocol      = \"tcp\"\n        name          = \"public-api\"\n      },\n      {\n        containerPort = 8001\n        protocol      = \"tcp\"\n        name          = \"internal-api\"\n      }\n    ]\n\n    environment = [\n      { name = \"ENVIRONMENT\", value = var.environment },\n      { name = \"AWS_REGION\", value = var.aws_region },\n      { name = \"LOG_LEVEL\", value = var.log_level },\n      { name = \"PUBLIC_API_PORT\", value = \"8000\" },\n      { name = \"INTERNAL_API_PORT\", value = \"8001\" }\n    ]\n\n    secrets = [\n      {\n        name      = \"DATABASE_URL\"\n        valueFrom = \"${aws_secretsmanager_secret.pts_db_url.arn}\"\n      },\n      {\n        name      = \"BDK_KMS_KEY_ID\"\n        valueFrom = \"${aws_secretsmanager_secret.bdk_kms_key_id.arn}\"\n      },\n      {\n        name      = \"CURRENT_ENCRYPTION_KEY_VERSION\"\n        valueFrom = \"${aws_secretsmanager_secret.current_key_version.arn}\"\n      }\n    ]\n\n    logConfiguration = {\n      logDriver = \"awslogs\"\n      options = {\n        \"awslogs-group\"         = \"/ecs/payment-token-service\"\n        \"awslogs-region\"        = var.aws_region\n        \"awslogs-stream-prefix\" = \"ecs\"\n      }\n    }\n\n    healthCheck = {\n      command     = [\"CMD-SHELL\", \"curl -f http://localhost:8000/health || exit 1\"]\n      interval    = 30\n      timeout     = 5\n      retries     = 3\n      startPeriod = 60\n    }\n\n    # Security\n    readonlyRootFilesystem = false  # Poetry requires writable filesystem\n    user                   = \"1000:1000\"  # Non-root user\n\n    # Resource limits\n    ulimits = [{\n      name      = \"nofile\"\n      softLimit = 65536\n      hardLimit = 65536\n    }]\n  }])\n\n  # Ephemeral storage (for temp files during request processing)\n  ephemeral_storage {\n    size_in_gib = 21  # Default is 20, can go up to 200\n  }\n}\n```\n\n### ECS Service\n\n```hcl\nresource \"aws_ecs_service\" \"payment_token_service\" {\n  name            = \"payment-token-service\"\n  cluster         = aws_ecs_cluster.payment_token_service.id\n  task_definition = aws_ecs_task_definition.payment_token_service.arn\n  desired_count   = var.desired_count  # Start with 2, autoscale to 10+\n  launch_type     = \"FARGATE\"\n  platform_version = \"1.4.0\"  # Latest Fargate platform\n\n  network_configuration {\n    subnets         = aws_subnet.pci_zone[*].id  # PCI isolated subnets\n    security_groups = [aws_security_group.pts_ecs.id]\n    assign_public_ip = false  # Private subnets only\n  }\n\n  # Public API Load Balancer (via API Gateway)\n  load_balancer {\n    target_group_arn = aws_lb_target_group.pts_public.arn\n    container_name   = \"payment-token-service\"\n    container_port   = 8000\n  }\n\n  # Internal API Load Balancer (auth workers)\n  load_balancer {\n    target_group_arn = aws_lb_target_group.pts_internal.arn\n    container_name   = \"payment-token-service\"\n    container_port   = 8001\n  }\n\n  # Blue-Green Deployment\n  deployment_controller {\n    type = \"ECS\"  # Use ECS rolling deployment (can switch to CODE_DEPLOY for blue-green)\n  }\n\n  deployment_configuration {\n    maximum_percent         = 200  # Allow double capacity during deployment\n    minimum_healthy_percent = 100  # Always maintain full capacity\n    \n    deployment_circuit_breaker {\n      enable   = true\n      rollback = true  # Auto-rollback on failure\n    }\n  }\n\n  # Service discovery (optional, for internal service mesh)\n  service_registries {\n    registry_arn = aws_service_discovery_service.pts.arn\n  }\n\n  # Prevent service updates from recreating tasks unnecessarily\n  lifecycle {\n    ignore_changes = [desired_count]  # Autoscaling manages this\n  }\n\n  depends_on = [\n    aws_lb_listener.public_https,\n    aws_lb_listener.internal_https,\n    aws_iam_role_policy_attachment.ecs_execution,\n    aws_iam_role_policy_attachment.ecs_task\n  ]\n}\n```\n\n## Load Balancers\n\n### Public API - Application Load Balancer (ALB)\n\n```hcl\nresource \"aws_lb\" \"public_api\" {\n  name               = \"pts-public-api-${var.environment}\"\n  internal           = true  # Internal to VPC, accessed via API Gateway VPC Link\n  load_balancer_type = \"application\"\n  security_groups    = [aws_security_group.alb_public.id]\n  subnets            = aws_subnet.public[*].id\n\n  enable_deletion_protection = var.environment == \"production\"\n  enable_http2              = true\n  enable_cross_zone_load_balancing = true\n\n  access_logs {\n    bucket  = aws_s3_bucket.lb_logs.id\n    prefix  = \"public-api\"\n    enabled = true\n  }\n\n  tags = {\n    Name        = \"pts-public-api\"\n    Environment = var.environment\n    PCI         = \"true\"\n  }\n}\n\n# Target Group for public API (port 8000)\nresource \"aws_lb_target_group\" \"pts_public\" {\n  name        = \"pts-public-${var.environment}\"\n  port        = 8000\n  protocol    = \"HTTP\"\n  vpc_id      = aws_vpc.main.id\n  target_type = \"ip\"  # Required for Fargate\n\n  health_check {\n    enabled             = true\n    healthy_threshold   = 2\n    unhealthy_threshold = 3\n    timeout             = 5\n    interval            = 30\n    path                = \"/health\"\n    protocol            = \"HTTP\"\n    matcher             = \"200\"\n  }\n\n  deregistration_delay = 30  # Drain connections gracefully\n\n  stickiness {\n    type            = \"lb_cookie\"\n    enabled         = false  # Stateless service\n  }\n}\n\n# HTTPS Listener (API Gateway → ALB)\nresource \"aws_lb_listener\" \"public_https\" {\n  load_balancer_arn = aws_lb.public_api.arn\n  port              = \"443\"\n  protocol          = \"HTTPS\"\n  ssl_policy        = \"ELBSecurityPolicy-TLS13-1-2-2021-06\"  # TLS 1.3 only\n  certificate_arn   = aws_acm_certificate.pts_public.arn\n\n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.pts_public.arn\n  }\n}\n```\n\n### Internal API - Network Load Balancer (NLB)\n\n```hcl\nresource \"aws_lb\" \"internal_api\" {\n  name               = \"pts-internal-api-${var.environment}\"\n  internal           = true  # VPC-only, for auth workers\n  load_balancer_type = \"network\"\n  subnets            = aws_subnet.pci_zone[*].id\n\n  enable_deletion_protection       = var.environment == \"production\"\n  enable_cross_zone_load_balancing = true\n\n  tags = {\n    Name        = \"pts-internal-api\"\n    Environment = var.environment\n    PCI         = \"true\"\n  }\n}\n\n# Target Group for internal API (port 8001, mTLS)\nresource \"aws_lb_target_group\" \"pts_internal\" {\n  name        = \"pts-internal-${var.environment}\"\n  port        = 8001\n  protocol    = \"TCP\"  # NLB uses TCP, mTLS handled at application layer\n  vpc_id      = aws_vpc.main.id\n  target_type = \"ip\"\n\n  health_check {\n    enabled             = true\n    healthy_threshold   = 2\n    unhealthy_threshold = 3\n    timeout             = 10\n    interval            = 30\n    protocol            = \"TCP\"\n    port                = \"8001\"\n  }\n\n  deregistration_delay = 30\n}\n\n# TCP Listener (mTLS enforced at application layer)\nresource \"aws_lb_listener\" \"internal_https\" {\n  load_balancer_arn = aws_lb.internal_api.arn\n  port              = \"8001\"\n  protocol          = \"TCP\"\n\n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.pts_internal.arn\n  }\n}\n```\n\n## API Gateway\n\n### REST API Configuration\n\n```hcl\nresource \"aws_api_gateway_rest_api\" \"payment_token_service\" {\n  name        = \"payment-token-service-${var.environment}\"\n  description = \"Payment Token Service Public API\"\n\n  endpoint_configuration {\n    types = [\"REGIONAL\"]  # Use CloudFront for edge optimization if needed\n  }\n\n  binary_media_types = [\"application/x-protobuf\"]  # Protobuf support\n}\n\n# VPC Link (API Gateway → Internal ALB)\nresource \"aws_api_gateway_vpc_link\" \"pts\" {\n  name        = \"pts-vpc-link-${var.environment}\"\n  target_arns = [aws_lb.public_api.arn]\n}\n\n# Resource: /v1/payment-tokens\nresource \"aws_api_gateway_resource\" \"payment_tokens\" {\n  rest_api_id = aws_api_gateway_rest_api.payment_token_service.id\n  parent_id   = aws_api_gateway_rest_api.payment_token_service.root_resource_id\n  path_part   = \"v1\"\n}\n\nresource \"aws_api_gateway_resource\" \"payment_tokens_collection\" {\n  rest_api_id = aws_api_gateway_rest_api.payment_token_service.id\n  parent_id   = aws_api_gateway_resource.payment_tokens.id\n  path_part   = \"payment-tokens\"\n}\n\n# POST /v1/payment-tokens\nresource \"aws_api_gateway_method\" \"create_token\" {\n  rest_api_id   = aws_api_gateway_rest_api.payment_token_service.id\n  resource_id   = aws_api_gateway_resource.payment_tokens_collection.id\n  http_method   = \"POST\"\n  authorization = \"CUSTOM\"  # Custom authorizer for API key validation\n  authorizer_id = aws_api_gateway_authorizer.api_key.id\n\n  request_parameters = {\n    \"method.request.header.X-Idempotency-Key\" = true\n    \"method.request.header.Authorization\"     = true\n  }\n}\n\n# Integration with VPC Link\nresource \"aws_api_gateway_integration\" \"create_token\" {\n  rest_api_id = aws_api_gateway_rest_api.payment_token_service.id\n  resource_id = aws_api_gateway_resource.payment_tokens_collection.id\n  http_method = aws_api_gateway_method.create_token.http_method\n\n  type                    = \"HTTP_PROXY\"\n  integration_http_method = \"POST\"\n  uri                     = \"https://${aws_lb.public_api.dns_name}/v1/payment-tokens\"\n  connection_type         = \"VPC_LINK\"\n  connection_id           = aws_api_gateway_vpc_link.pts.id\n\n  request_parameters = {\n    \"integration.request.header.X-Idempotency-Key\" = \"method.request.header.X-Idempotency-Key\"\n    \"integration.request.header.Authorization\"     = \"method.request.header.Authorization\"\n  }\n\n  timeout_milliseconds = 29000  # API Gateway max is 29s\n}\n\n# Rate Limiting (Usage Plan)\nresource \"aws_api_gateway_usage_plan\" \"standard\" {\n  name = \"pts-standard-${var.environment}\"\n\n  throttle_settings {\n    burst_limit = 2000   # Burst capacity\n    rate_limit  = 1000   # Sustained requests per second\n  }\n\n  quota_settings {\n    limit  = 1000000  # 1M requests per month\n    period = \"MONTH\"\n  }\n\n  api_stages {\n    api_id = aws_api_gateway_rest_api.payment_token_service.id\n    stage  = aws_api_gateway_stage.production.stage_name\n  }\n}\n\n# WAF for API Gateway\nresource \"aws_wafv2_web_acl\" \"api_gateway\" {\n  name  = \"pts-api-gateway-${var.environment}\"\n  scope = \"REGIONAL\"\n\n  default_action {\n    allow {}\n  }\n\n  # Rate limiting rule (per IP)\n  rule {\n    name     = \"rate-limit-per-ip\"\n    priority = 1\n\n    action {\n      block {}\n    }\n\n    statement {\n      rate_based_statement {\n        limit              = 2000  # Requests per 5 minutes\n        aggregate_key_type = \"IP\"\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = true\n      metric_name                = \"RateLimitPerIP\"\n      sampled_requests_enabled   = true\n    }\n  }\n\n  # AWS Managed Rules - Core rule set\n  rule {\n    name     = \"aws-managed-core-rules\"\n    priority = 2\n\n    override_action {\n      none {}\n    }\n\n    statement {\n      managed_rule_group_statement {\n        vendor_name = \"AWS\"\n        name        = \"AWSManagedRulesCommonRuleSet\"\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = true\n      metric_name                = \"AWSManagedCoreRules\"\n      sampled_requests_enabled   = true\n    }\n  }\n\n  visibility_config {\n    cloudwatch_metrics_enabled = true\n    metric_name                = \"PTSAPIGatewayWAF\"\n    sampled_requests_enabled   = true\n  }\n}\n```\n\n## RDS Database (Isolated)\n\n### PostgreSQL Instance Configuration\n\n```hcl\nresource \"aws_db_instance\" \"payment_tokens_db\" {\n  identifier     = \"payment-tokens-db-${var.environment}\"\n  engine         = \"postgres\"\n  engine_version = \"15.4\"  # Latest PostgreSQL 15\n  instance_class = var.db_instance_class  # db.t3.medium for dev, db.r6g.xlarge for prod\n\n  allocated_storage     = 100  # GB, can autoscale\n  max_allocated_storage = 1000 # Autoscale up to 1TB\n  storage_type          = \"gp3\"\n  storage_encrypted     = true\n  kms_key_id            = aws_kms_key.rds_encryption.arn\n\n  db_name  = \"payment_tokens_db\"\n  username = \"pts_admin\"\n  password = random_password.db_password.result  # Managed by Terraform, stored in Secrets Manager\n\n  # Network\n  db_subnet_group_name   = aws_db_subnet_group.payment_tokens.name\n  vpc_security_group_ids = [aws_security_group.rds_pts.id]\n  publicly_accessible    = false\n\n  # High Availability\n  multi_az = var.environment == \"production\"\n\n  # Backups\n  backup_retention_period = var.environment == \"production\" ? 30 : 7  # 30 days for prod\n  backup_window           = \"03:00-04:00\"  # UTC\n  maintenance_window      = \"mon:04:00-mon:05:00\"  # UTC\n\n  # Performance\n  performance_insights_enabled    = true\n  performance_insights_kms_key_id = aws_kms_key.performance_insights.arn\n  performance_insights_retention_period = 7\n\n  enabled_cloudwatch_logs_exports = [\"postgresql\", \"upgrade\"]\n\n  # Deletion protection\n  deletion_protection = var.environment == \"production\"\n  skip_final_snapshot = var.environment != \"production\"\n  final_snapshot_identifier = var.environment == \"production\" ? \"payment-tokens-db-final-${formatdate(\"YYYY-MM-DD-hhmm\", timestamp())}\" : null\n\n  # Parameter group for PCI compliance\n  parameter_group_name = aws_db_parameter_group.payment_tokens.name\n\n  tags = {\n    Name        = \"payment-tokens-db\"\n    Environment = var.environment\n    PCI         = \"true\"\n    Backup      = \"required\"\n  }\n}\n\n# DB Subnet Group (data tier subnets)\nresource \"aws_db_subnet_group\" \"payment_tokens\" {\n  name       = \"payment-tokens-${var.environment}\"\n  subnet_ids = aws_subnet.data_tier[*].id\n\n  tags = {\n    Name = \"payment-tokens-db-subnet-group\"\n  }\n}\n\n# Parameter Group (security hardening)\nresource \"aws_db_parameter_group\" \"payment_tokens\" {\n  name   = \"payment-tokens-pg15-${var.environment}\"\n  family = \"postgres15\"\n\n  # Enforce SSL connections\n  parameter {\n    name  = \"rds.force_ssl\"\n    value = \"1\"\n  }\n\n  # Audit logging for PCI compliance\n  parameter {\n    name  = \"log_connections\"\n    value = \"1\"\n  }\n\n  parameter {\n    name  = \"log_disconnections\"\n    value = \"1\"\n  }\n\n  parameter {\n    name  = \"log_statement\"\n    value = \"all\"  # Log all SQL statements (mod or ddl for less verbose)\n  }\n\n  parameter {\n    name  = \"log_min_duration_statement\"\n    value = \"1000\"  # Log queries slower than 1s\n  }\n\n  # Connection pooling\n  parameter {\n    name  = \"max_connections\"\n    value = var.db_max_connections  # 100 for dev, 500 for prod\n  }\n}\n\n# Read Replica (optional, for scaling reads)\nresource \"aws_db_instance\" \"payment_tokens_replica\" {\n  count = var.environment == \"production\" ? 1 : 0\n\n  identifier     = \"payment-tokens-db-replica-${var.environment}\"\n  replicate_source_db = aws_db_instance.payment_tokens_db.identifier\n\n  instance_class = var.db_instance_class\n  publicly_accessible = false\n\n  # Inherit most settings from primary\n  \n  tags = {\n    Name        = \"payment-tokens-db-replica\"\n    Environment = var.environment\n    PCI         = \"true\"\n  }\n}\n```\n\n## KMS Key Management\n\n### Base Derivation Key (BDK)\n\n```hcl\nresource \"aws_kms_key\" \"bdk\" {\n  description             = \"Payment Token Service - Base Derivation Key (BDK)\"\n  deletion_window_in_days = 30\n  enable_key_rotation     = true  # Automatic annual rotation\n\n  # Key policy (most restrictive)\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid    = \"Enable IAM User Permissions\"\n        Effect = \"Allow\"\n        Principal = {\n          AWS = \"arn:aws:iam::${data.aws_caller_identity.current.account_id}:root\"\n        }\n        Action   = \"kms:*\"\n        Resource = \"*\"\n      },\n      {\n        Sid    = \"Allow Payment Token Service to Decrypt BDK\"\n        Effect = \"Allow\"\n        Principal = {\n          AWS = aws_iam_role.ecs_task.arn\n        }\n        Action = [\n          \"kms:Decrypt\",\n          \"kms:DescribeKey\"\n        ]\n        Resource = \"*\"\n        Condition = {\n          StringEquals = {\n            \"kms:EncryptionContext:service\" = \"payment-token-service\"\n          }\n        }\n      }\n    ]\n  })\n\n  tags = {\n    Name        = \"pts-bdk\"\n    Environment = var.environment\n    PCI         = \"true\"\n    Rotation    = \"annual\"\n  }\n}\n\nresource \"aws_kms_alias\" \"bdk\" {\n  name          = \"alias/pts-bdk-${var.environment}\"\n  target_key_id = aws_kms_key.bdk.key_id\n}\n```\n\n### Service Encryption Keys (Rotating)\n\n```hcl\nresource \"aws_kms_key\" \"service_encryption\" {\n  description             = \"Payment Token Service - Service Encryption Key (Rotating)\"\n  deletion_window_in_days = 30\n  enable_key_rotation     = true  # Rotate every 90 days (managed via Lambda)\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid    = \"Enable IAM User Permissions\"\n        Effect = \"Allow\"\n        Principal = {\n          AWS = \"arn:aws:iam::${data.aws_caller_identity.current.account_id}:root\"\n        }\n        Action   = \"kms:*\"\n        Resource = \"*\"\n      },\n      {\n        Sid    = \"Allow Payment Token Service Encryption/Decryption\"\n        Effect = \"Allow\"\n        Principal = {\n          AWS = aws_iam_role.ecs_task.arn\n        }\n        Action = [\n          \"kms:Encrypt\",\n          \"kms:Decrypt\",\n          \"kms:GenerateDataKey\",\n          \"kms:DescribeKey\"\n        ]\n        Resource = \"*\"\n      }\n    ]\n  })\n\n  tags = {\n    Name        = \"pts-service-encryption\"\n    Environment = var.environment\n    PCI         = \"true\"\n  }\n}\n```\n\n### RDS Encryption Key\n\n```hcl\nresource \"aws_kms_key\" \"rds_encryption\" {\n  description             = \"Payment Tokens RDS Database Encryption\"\n  deletion_window_in_days = 30\n  enable_key_rotation     = true\n\n  tags = {\n    Name        = \"pts-rds-encryption\"\n    Environment = var.environment\n    PCI         = \"true\"\n  }\n}\n```\n\n## Autoscaling\n\n### Target Tracking - CPU and Memory\n\n```hcl\nresource \"aws_appautoscaling_target\" \"ecs_target\" {\n  max_capacity       = var.max_capacity  # 20 for prod, 5 for dev\n  min_capacity       = var.min_capacity  # 2 for prod, 1 for dev\n  resource_id        = \"service/${aws_ecs_cluster.payment_token_service.name}/${aws_ecs_service.payment_token_service.name}\"\n  scalable_dimension = \"ecs:service:DesiredCount\"\n  service_namespace  = \"ecs\"\n}\n\n# Scale on CPU utilization\nresource \"aws_appautoscaling_policy\" \"ecs_cpu\" {\n  name               = \"cpu-autoscaling\"\n  policy_type        = \"TargetTrackingScaling\"\n  resource_id        = aws_appautoscaling_target.ecs_target.resource_id\n  scalable_dimension = aws_appautoscaling_target.ecs_target.scalable_dimension\n  service_namespace  = aws_appautoscaling_target.ecs_target.service_namespace\n\n  target_tracking_scaling_policy_configuration {\n    target_value       = 70.0  # Target 70% CPU\n    scale_in_cooldown  = 300   # 5 minutes before scaling in\n    scale_out_cooldown = 60    # 1 minute before scaling out\n\n    predefined_metric_specification {\n      predefined_metric_type = \"ECSServiceAverageCPUUtilization\"\n    }\n  }\n}\n\n# Scale on Memory utilization\nresource \"aws_appautoscaling_policy\" \"ecs_memory\" {\n  name               = \"memory-autoscaling\"\n  policy_type        = \"TargetTrackingScaling\"\n  resource_id        = aws_appautoscaling_target.ecs_target.resource_id\n  scalable_dimension = aws_appautoscaling_target.ecs_target.scalable_dimension\n  service_namespace  = aws_appautoscaling_target.ecs_target.service_namespace\n\n  target_tracking_scaling_policy_configuration {\n    target_value       = 80.0  # Target 80% memory\n    scale_in_cooldown  = 300\n    scale_out_cooldown = 60\n\n    predefined_metric_specification {\n      predefined_metric_type = \"ECSServiceAverageMemoryUtilization\"\n    }\n  }\n}\n```\n\n### Step Scaling - Request Count\n\n```hcl\nresource \"aws_appautoscaling_policy\" \"ecs_request_count\" {\n  name               = \"request-count-step-scaling\"\n  policy_type        = \"StepScaling\"\n  resource_id        = aws_appautoscaling_target.ecs_target.resource_id\n  scalable_dimension = aws_appautoscaling_target.ecs_target.scalable_dimension\n  service_namespace  = aws_appautoscaling_target.ecs_target.service_namespace\n\n  step_scaling_policy_configuration {\n    adjustment_type         = \"PercentChangeInCapacity\"\n    cooldown                = 60\n    metric_aggregation_type = \"Average\"\n\n    # Scale out aggressively\n    step_adjustment {\n      metric_interval_lower_bound = 0\n      metric_interval_upper_bound = 10\n      scaling_adjustment          = 10  # Add 10% capacity\n    }\n\n    step_adjustment {\n      metric_interval_lower_bound = 10\n      metric_interval_upper_bound = 20\n      scaling_adjustment          = 20  # Add 20% capacity\n    }\n\n    step_adjustment {\n      metric_interval_lower_bound = 20\n      scaling_adjustment          = 30  # Add 30% capacity\n    }\n  }\n}\n\n# CloudWatch Alarm for request count scaling\nresource \"aws_cloudwatch_metric_alarm\" \"request_count_high\" {\n  alarm_name          = \"pts-request-count-high-${var.environment}\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 2\n  metric_name         = \"RequestCountPerTarget\"\n  namespace           = \"AWS/ApplicationELB\"\n  period              = 60\n  statistic           = \"Sum\"\n  threshold           = 1000  # 1000 requests per target per minute\n  alarm_description   = \"Triggers when request count is too high\"\n  alarm_actions       = [aws_appautoscaling_policy.ecs_request_count.arn]\n\n  dimensions = {\n    TargetGroup  = aws_lb_target_group.pts_public.arn_suffix\n    LoadBalancer = aws_lb.public_api.arn_suffix\n  }\n}\n```\n\n### Scheduled Scaling (Optional)\n\n```hcl\nresource \"aws_appautoscaling_scheduled_action\" \"scale_up_morning\" {\n  count = var.enable_scheduled_scaling ? 1 : 0\n\n  name               = \"scale-up-morning\"\n  service_namespace  = aws_appautoscaling_target.ecs_target.service_namespace\n  resource_id        = aws_appautoscaling_target.ecs_target.resource_id\n  scalable_dimension = aws_appautoscaling_target.ecs_target.scalable_dimension\n  schedule           = \"cron(0 6 * * ? *)\"  # 6 AM UTC daily\n\n  scalable_target_action {\n    min_capacity = var.min_capacity * 2\n    max_capacity = var.max_capacity\n  }\n}\n```\n\n## IAM Roles and Policies\n\n### ECS Task Execution Role (For ECS to pull images, write logs)\n\n```hcl\nresource \"aws_iam_role\" \"ecs_execution\" {\n  name = \"pts-ecs-execution-${var.environment}\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Action = \"sts:AssumeRole\"\n      Effect = \"Allow\"\n      Principal = {\n        Service = \"ecs-tasks.amazonaws.com\"\n      }\n    }]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"ecs_execution\" {\n  role       = aws_iam_role.ecs_execution.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\"\n}\n\n# Additional policy for Secrets Manager\nresource \"aws_iam_role_policy\" \"ecs_execution_secrets\" {\n  name = \"secrets-access\"\n  role = aws_iam_role.ecs_execution.id\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Action = [\n          \"secretsmanager:GetSecretValue\"\n        ]\n        Resource = [\n          aws_secretsmanager_secret.pts_db_url.arn,\n          aws_secretsmanager_secret.bdk_kms_key_id.arn,\n          aws_secretsmanager_secret.current_key_version.arn\n        ]\n      },\n      {\n        Effect = \"Allow\"\n        Action = [\n          \"kms:Decrypt\"\n        ]\n        Resource = [\n          aws_kms_key.secrets_encryption.arn\n        ]\n      }\n    ]\n  })\n}\n```\n\n### ECS Task Role (For application to access AWS services)\n\n```hcl\nresource \"aws_iam_role\" \"ecs_task\" {\n  name = \"pts-ecs-task-${var.environment}\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Action = \"sts:AssumeRole\"\n      Effect = \"Allow\"\n      Principal = {\n        Service = \"ecs-tasks.amazonaws.com\"\n      }\n    }]\n  })\n}\n\n# KMS access for BDK decryption\nresource \"aws_iam_role_policy\" \"ecs_task_kms\" {\n  name = \"kms-access\"\n  role = aws_iam_role.ecs_task.id\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid    = \"DecryptBDK\"\n        Effect = \"Allow\"\n        Action = [\n          \"kms:Decrypt\",\n          \"kms:DescribeKey\"\n        ]\n        Resource = aws_kms_key.bdk.arn\n        Condition = {\n          StringEquals = {\n            \"kms:EncryptionContext:service\" = \"payment-token-service\"\n          }\n        }\n      },\n      {\n        Sid    = \"ServiceEncryption\"\n        Effect = \"Allow\"\n        Action = [\n          \"kms:Encrypt\",\n          \"kms:Decrypt\",\n          \"kms:GenerateDataKey\",\n          \"kms:DescribeKey\"\n        ]\n        Resource = aws_kms_key.service_encryption.arn\n      }\n    ]\n  })\n}\n\n# CloudWatch Logs\nresource \"aws_iam_role_policy\" \"ecs_task_logs\" {\n  name = \"cloudwatch-logs\"\n  role = aws_iam_role.ecs_task.id\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Effect = \"Allow\"\n      Action = [\n        \"logs:CreateLogStream\",\n        \"logs:PutLogEvents\"\n      ]\n      Resource = \"${aws_cloudwatch_log_group.ecs.arn}:*\"\n    }]\n  })\n}\n```\n\n## Monitoring and Observability\n\n### CloudWatch Log Groups\n\n```hcl\nresource \"aws_cloudwatch_log_group\" \"ecs\" {\n  name              = \"/ecs/payment-token-service\"\n  retention_in_days = var.environment == \"production\" ? 2555 : 30  # 7 years for PCI compliance\n\n  kms_key_id = aws_kms_key.cloudwatch_logs.arn\n\n  tags = {\n    Name        = \"pts-ecs-logs\"\n    Environment = var.environment\n    PCI         = \"true\"\n  }\n}\n\n# VPC Flow Logs (PCI compliance)\nresource \"aws_flow_log\" \"pci_zone\" {\n  iam_role_arn    = aws_iam_role.flow_logs.arn\n  log_destination = aws_cloudwatch_log_group.vpc_flow_logs.arn\n  traffic_type    = \"ALL\"\n  vpc_id          = aws_vpc.main.id\n\n  tags = {\n    Name = \"pts-pci-zone-flow-logs\"\n    PCI  = \"true\"\n  }\n}\n\nresource \"aws_cloudwatch_log_group\" \"vpc_flow_logs\" {\n  name              = \"/vpc/payment-token-service\"\n  retention_in_days = var.environment == \"production\" ? 2555 : 90\n\n  tags = {\n    PCI = \"true\"\n  }\n}\n```\n\n### CloudWatch Alarms\n\n```hcl\n# High error rate alarm\nresource \"aws_cloudwatch_metric_alarm\" \"high_error_rate\" {\n  alarm_name          = \"pts-high-error-rate-${var.environment}\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 2\n  metric_name         = \"HTTPCode_Target_5XX_Count\"\n  namespace           = \"AWS/ApplicationELB\"\n  period              = 300\n  statistic           = \"Sum\"\n  threshold           = 10\n  alarm_description   = \"Alert when 5xx errors exceed threshold\"\n  alarm_actions       = [aws_sns_topic.alerts.arn]\n\n  dimensions = {\n    LoadBalancer = aws_lb.public_api.arn_suffix\n    TargetGroup  = aws_lb_target_group.pts_public.arn_suffix\n  }\n}\n\n# Database connection failures\nresource \"aws_cloudwatch_metric_alarm\" \"db_connection_failures\" {\n  alarm_name          = \"pts-db-connection-failures-${var.environment}\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 1\n  metric_name         = \"DatabaseConnectionFailures\"\n  namespace           = \"AWS/RDS\"\n  period              = 60\n  statistic           = \"Sum\"\n  threshold           = 5\n  alarm_description   = \"Alert on database connection failures\"\n  alarm_actions       = [aws_sns_topic.alerts.arn]\n\n  dimensions = {\n    DBInstanceIdentifier = aws_db_instance.payment_tokens_db.id\n  }\n}\n\n# KMS throttling\nresource \"aws_cloudwatch_metric_alarm\" \"kms_throttle\" {\n  alarm_name          = \"pts-kms-throttling-${var.environment}\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 2\n  metric_name         = \"UserErrorCount\"\n  namespace           = \"AWS/KMS\"\n  period              = 60\n  statistic           = \"Sum\"\n  threshold           = 10\n  alarm_description   = \"Alert on KMS throttling\"\n  alarm_actions       = [aws_sns_topic.alerts.arn]\n\n  dimensions = {\n    KeyId = aws_kms_key.bdk.id\n  }\n}\n\n# Unauthorized decrypt attempts (security)\nresource \"aws_cloudwatch_log_metric_filter\" \"unauthorized_decrypt\" {\n  name           = \"unauthorized-decrypt-attempts\"\n  log_group_name = aws_cloudwatch_log_group.ecs.name\n  pattern        = \"[timestamp, request_id, level=ERROR, event=unauthorized_decrypt_attempt, ...]\"\n\n  metric_transformation {\n    name      = \"UnauthorizedDecryptAttempts\"\n    namespace = \"PaymentTokenService\"\n    value     = \"1\"\n  }\n}\n\nresource \"aws_cloudwatch_metric_alarm\" \"unauthorized_decrypt_alarm\" {\n  alarm_name          = \"pts-unauthorized-decrypt-${var.environment}\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 1\n  metric_name         = \"UnauthorizedDecryptAttempts\"\n  namespace           = \"PaymentTokenService\"\n  period              = 300\n  statistic           = \"Sum\"\n  threshold           = 10\n  treat_missing_data  = \"notBreaching\"\n  alarm_description   = \"Security alert: Unauthorized decrypt attempts\"\n  alarm_actions       = [aws_sns_topic.security_alerts.arn]\n}\n```\n\n### CloudWatch Dashboard\n\n```hcl\nresource \"aws_cloudwatch_dashboard\" \"payment_token_service\" {\n  dashboard_name = \"payment-token-service-${var.environment}\"\n\n  dashboard_body = jsonencode({\n    widgets = [\n      {\n        type = \"metric\"\n        properties = {\n          metrics = [\n            [\"AWS/ECS\", \"CPUUtilization\", { stat = \"Average\" }],\n            [\".\", \"MemoryUtilization\", { stat = \"Average\" }]\n          ]\n          period = 300\n          stat   = \"Average\"\n          region = var.aws_region\n          title  = \"ECS Resource Utilization\"\n        }\n      },\n      {\n        type = \"metric\"\n        properties = {\n          metrics = [\n            [\"AWS/ApplicationELB\", \"TargetResponseTime\", { stat = \"p99\" }],\n            [\"...\", { stat = \"p95\" }],\n            [\"...\", { stat = \"p50\" }]\n          ]\n          period = 60\n          stat   = \"Average\"\n          region = var.aws_region\n          title  = \"API Response Time (Latency)\"\n        }\n      },\n      {\n        type = \"metric\"\n        properties = {\n          metrics = [\n            [\"AWS/ApplicationELB\", \"HTTPCode_Target_2XX_Count\", { stat = \"Sum\" }],\n            [\".\", \"HTTPCode_Target_4XX_Count\", { stat = \"Sum\" }],\n            [\".\", \"HTTPCode_Target_5XX_Count\", { stat = \"Sum\" }]\n          ]\n          period = 300\n          stat   = \"Sum\"\n          region = var.aws_region\n          title  = \"HTTP Response Codes\"\n        }\n      },\n      {\n        type = \"metric\"\n        properties = {\n          metrics = [\n            [\"AWS/RDS\", \"DatabaseConnections\", { stat = \"Average\" }],\n            [\".\", \"CPUUtilization\", { stat = \"Average\" }],\n            [\".\", \"FreeableMemory\", { stat = \"Average\" }]\n          ]\n          period = 300\n          stat   = \"Average\"\n          region = var.aws_region\n          title  = \"RDS Performance\"\n        }\n      }\n    ]\n  })\n}\n```\n\n## Secrets Management\n\n```hcl\n# Database URL\nresource \"aws_secretsmanager_secret\" \"pts_db_url\" {\n  name                    = \"pts/database-url-${var.environment}\"\n  recovery_window_in_days = 30\n  kms_key_id              = aws_kms_key.secrets_encryption.arn\n\n  tags = {\n    Environment = var.environment\n    PCI         = \"true\"\n  }\n}\n\nresource \"aws_secretsmanager_secret_version\" \"pts_db_url\" {\n  secret_id = aws_secretsmanager_secret.pts_db_url.id\n  secret_string = \"postgresql://${aws_db_instance.payment_tokens_db.username}:${random_password.db_password.result}@${aws_db_instance.payment_tokens_db.endpoint}/${aws_db_instance.payment_tokens_db.db_name}\"\n}\n\n# BDK KMS Key ID\nresource \"aws_secretsmanager_secret\" \"bdk_kms_key_id\" {\n  name                    = \"pts/bdk-kms-key-id-${var.environment}\"\n  recovery_window_in_days = 30\n  kms_key_id              = aws_kms_key.secrets_encryption.arn\n}\n\nresource \"aws_secretsmanager_secret_version\" \"bdk_kms_key_id\" {\n  secret_id     = aws_secretsmanager_secret.bdk_kms_key_id.id\n  secret_string = aws_kms_key.bdk.arn\n}\n\n# Current encryption key version\nresource \"aws_secretsmanager_secret\" \"current_key_version\" {\n  name                    = \"pts/current-encryption-key-version-${var.environment}\"\n  recovery_window_in_days = 7\n  kms_key_id              = aws_kms_key.secrets_encryption.arn\n}\n\nresource \"aws_secretsmanager_secret_version\" \"current_key_version\" {\n  secret_id     = aws_secretsmanager_secret.current_key_version.id\n  secret_string = jsonencode({\n    version = \"v1\"\n    key_id  = aws_kms_key.service_encryption.id\n  })\n}\n```\n\n## Deployment Strategy\n\n### Blue-Green Deployment with CodeDeploy\n\n```hcl\n# CodeDeploy Application\nresource \"aws_codedeploy_app\" \"payment_token_service\" {\n  name             = \"payment-token-service-${var.environment}\"\n  compute_platform = \"ECS\"\n}\n\n# Deployment Group\nresource \"aws_codedeploy_deployment_group\" \"payment_token_service\" {\n  app_name               = aws_codedeploy_app.payment_token_service.name\n  deployment_group_name  = \"pts-${var.environment}\"\n  service_role_arn       = aws_iam_role.codedeploy.arn\n  deployment_config_name = \"CodeDeployDefault.ECSAllAtOnce\"  # or Custom for canary\n\n  auto_rollback_configuration {\n    enabled = true\n    events  = [\"DEPLOYMENT_FAILURE\", \"DEPLOYMENT_STOP_ON_ALARM\"]\n  }\n\n  blue_green_deployment_config {\n    terminate_blue_instances_on_deployment_success {\n      action                           = \"TERMINATE\"\n      termination_wait_time_in_minutes = 5\n    }\n\n    deployment_ready_option {\n      action_on_timeout = \"CONTINUE_DEPLOYMENT\"\n    }\n  }\n\n  deployment_style {\n    deployment_option = \"WITH_TRAFFIC_CONTROL\"\n    deployment_type   = \"BLUE_GREEN\"\n  }\n\n  ecs_service {\n    cluster_name = aws_ecs_cluster.payment_token_service.name\n    service_name = aws_ecs_service.payment_token_service.name\n  }\n\n  load_balancer_info {\n    target_group_pair_info {\n      prod_traffic_route {\n        listener_arns = [aws_lb_listener.public_https.arn]\n      }\n\n      target_group {\n        name = aws_lb_target_group.pts_public.name\n      }\n\n      target_group {\n        name = aws_lb_target_group.pts_public_blue.name  # Blue target group\n      }\n    }\n  }\n\n  alarm_configuration {\n    alarms  = [aws_cloudwatch_metric_alarm.high_error_rate.alarm_name]\n    enabled = true\n  }\n}\n```\n\n## Terraform Module Structure\n\n```\nterraform/\n├── environments/\n│   ├── dev/\n│   │   ├── main.tf\n│   │   ├── variables.tf\n│   │   └── terraform.tfvars\n│   ├── staging/\n│   │   ├── main.tf\n│   │   ├── variables.tf\n│   │   └── terraform.tfvars\n│   └── production/\n│       ├── main.tf\n│       ├── variables.tf\n│       └── terraform.tfvars\n│\n├── modules/\n│   ├── networking/\n│   │   ├── main.tf          # VPC, subnets, security groups, VPC endpoints\n│   │   ├── variables.tf\n│   │   └── outputs.tf\n│   │\n│   ├── ecs/\n│   │   ├── main.tf          # ECS cluster, task definition, service\n│   │   ├── variables.tf\n│   │   └── outputs.tf\n│   │\n│   ├── load-balancer/\n│   │   ├── main.tf          # ALB, NLB, target groups, listeners\n│   │   ├── variables.tf\n│   │   └── outputs.tf\n│   │\n│   ├── rds/\n│   │   ├── main.tf          # RDS instance, parameter group, subnet group\n│   │   ├── variables.tf\n│   │   └── outputs.tf\n│   │\n│   ├── kms/\n│   │   ├── main.tf          # KMS keys (BDK, service encryption, RDS)\n│   │   ├── variables.tf\n│   │   └── outputs.tf\n│   │\n│   ├── api-gateway/\n│   │   ├── main.tf          # API Gateway, VPC Link, WAF\n│   │   ├── variables.tf\n│   │   └── outputs.tf\n│   │\n│   ├── monitoring/\n│   │   ├── main.tf          # CloudWatch alarms, dashboards, log groups\n│   │   ├── variables.tf\n│   │   └── outputs.tf\n│   │\n│   └── autoscaling/\n│       ├── main.tf          # Autoscaling policies, scheduled actions\n│       ├── variables.tf\n│       └── outputs.tf\n│\n└── backend.tf               # S3 backend for Terraform state\n```\n\n### Example: environments/production/main.tf\n\n```hcl\nterraform {\n  required_version = \">= 1.5.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n\n  backend \"s3\" {\n    bucket         = \"payments-infra-terraform-state\"\n    key            = \"production/payment-token-service/terraform.tfstate\"\n    region         = \"us-east-1\"\n    encrypt        = true\n    kms_key_id     = \"arn:aws:kms:us-east-1:ACCOUNT_ID:key/TERRAFORM_STATE_KEY_ID\"\n    dynamodb_table = \"terraform-state-lock\"\n  }\n}\n\nprovider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = {\n      Environment = \"production\"\n      Project     = \"payments-infra\"\n      Service     = \"payment-token-service\"\n      ManagedBy   = \"terraform\"\n      PCI         = \"true\"\n    }\n  }\n}\n\nmodule \"networking\" {\n  source = \"../../modules/networking\"\n\n  environment          = \"production\"\n  vpc_cidr             = \"10.0.0.0/16\"\n  availability_zones   = [\"us-east-1a\", \"us-east-1b\"]\n  enable_vpc_endpoints = true\n}\n\nmodule \"kms\" {\n  source = \"../../modules/kms\"\n\n  environment = \"production\"\n}\n\nmodule \"rds\" {\n  source = \"../../modules/rds\"\n\n  environment       = \"production\"\n  instance_class    = \"db.r6g.xlarge\"\n  allocated_storage = 500\n  multi_az          = true\n  \n  vpc_id            = module.networking.vpc_id\n  subnet_ids        = module.networking.data_tier_subnet_ids\n  security_group_id = module.networking.rds_security_group_id\n  kms_key_arn       = module.kms.rds_encryption_key_arn\n}\n\nmodule \"ecs\" {\n  source = \"../../modules/ecs\"\n\n  environment = \"production\"\n  \n  cluster_name  = \"payment-token-service\"\n  image_tag     = var.image_tag\n  task_cpu      = 2048\n  task_memory   = 4096\n  desired_count = 4\n\n  vpc_id               = module.networking.vpc_id\n  subnet_ids           = module.networking.pci_zone_subnet_ids\n  security_group_id    = module.networking.ecs_security_group_id\n  \n  bdk_kms_key_arn      = module.kms.bdk_key_arn\n  service_kms_key_arn  = module.kms.service_encryption_key_arn\n  database_secret_arn  = module.rds.db_secret_arn\n}\n\nmodule \"load_balancer\" {\n  source = \"../../modules/load-balancer\"\n\n  environment = \"production\"\n  \n  vpc_id             = module.networking.vpc_id\n  public_subnet_ids  = module.networking.public_subnet_ids\n  pci_subnet_ids     = module.networking.pci_zone_subnet_ids\n  \n  alb_security_group_id = module.networking.alb_security_group_id\n  ecs_security_group_id = module.networking.ecs_security_group_id\n  \n  certificate_arn = var.acm_certificate_arn\n}\n\nmodule \"api_gateway\" {\n  source = \"../../modules/api-gateway\"\n\n  environment = \"production\"\n  \n  alb_arn         = module.load_balancer.public_alb_arn\n  enable_waf      = true\n  rate_limit      = 2000\n}\n\nmodule \"autoscaling\" {\n  source = \"../../modules/autoscaling\"\n\n  environment = \"production\"\n  \n  ecs_cluster_name = module.ecs.cluster_name\n  ecs_service_name = module.ecs.service_name\n  \n  min_capacity = 4\n  max_capacity = 20\n  \n  cpu_target    = 70\n  memory_target = 80\n}\n\nmodule \"monitoring\" {\n  source = \"../../modules/monitoring\"\n\n  environment = \"production\"\n  \n  alb_arn            = module.load_balancer.public_alb_arn\n  target_group_arn   = module.load_balancer.public_target_group_arn\n  ecs_cluster_name   = module.ecs.cluster_name\n  ecs_service_name   = module.ecs.service_name\n  rds_instance_id    = module.rds.instance_id\n  \n  alert_email = var.alert_email\n}\n\noutput \"api_gateway_url\" {\n  value = module.api_gateway.api_url\n}\n\noutput \"internal_nlb_dns\" {\n  value = module.load_balancer.internal_nlb_dns\n}\n```\n\n### Example: environments/production/terraform.tfvars\n\n```hcl\naws_region = \"us-east-1\"\nenvironment = \"production\"\n\n# ECS Configuration\nimage_tag = \"v1.2.3\"  # Updated by CI/CD pipeline\ntask_cpu = 2048       # 2 vCPU\ntask_memory = 4096    # 4 GB\n\n# Autoscaling\nmin_capacity = 4\nmax_capacity = 20\n\n# Database\ndb_instance_class = \"db.r6g.xlarge\"\ndb_allocated_storage = 500\ndb_max_connections = 500\n\n# Alerts\nalert_email = \"oncall-payments@example.com\"\n\n# TLS Certificate\nacm_certificate_arn = \"arn:aws:acm:us-east-1:ACCOUNT_ID:certificate/CERT_ID\"\n```\n\n## CI/CD Pipeline Integration\n\n### GitHub Actions Example\n\n```yaml\nname: Deploy Payment Token Service\n\non:\n  push:\n    branches: [main]\n    paths:\n      - 'services/payment-token/**'\n      - 'terraform/modules/**'\n      - 'terraform/environments/production/**'\n\nenv:\n  AWS_REGION: us-east-1\n  ECR_REPOSITORY: payment-token-service\n  ECS_SERVICE: payment-token-service\n  ECS_CLUSTER: payment-token-service-production\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      \n      - name: Run unit tests\n        run: |\n          cd services/payment-token\n          poetry install\n          poetry run pytest tests/unit\n      \n      - name: Run integration tests\n        run: |\n          cd services/payment-token\n          poetry run pytest tests/integration\n      \n      - name: Run security scan\n        uses: aquasecurity/trivy-action@master\n        with:\n          scan-type: 'fs'\n          scan-ref: 'services/payment-token'\n\n  build:\n    needs: test\n    runs-on: ubuntu-latest\n    outputs:\n      image-tag: ${{ steps.build-image.outputs.image }}\n    steps:\n      - uses: actions/checkout@v3\n      \n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v2\n        with:\n          role-to-assume: ${{ secrets.AWS_DEPLOY_ROLE_ARN }}\n          aws-region: ${{ env.AWS_REGION }}\n      \n      - name: Login to Amazon ECR\n        id: login-ecr\n        uses: aws-actions/amazon-ecr-login@v1\n      \n      - name: Build and push Docker image\n        id: build-image\n        env:\n          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}\n          IMAGE_TAG: ${{ github.sha }}\n        run: |\n          docker build -f services/payment-token/Dockerfile -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .\n          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG\n          echo \"image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG\" >> $GITHUB_OUTPUT\n\n  terraform-plan:\n    needs: build\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      \n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v2\n        with:\n          terraform_version: 1.5.0\n      \n      - name: Terraform Init\n        run: |\n          cd terraform/environments/production\n          terraform init\n      \n      - name: Terraform Plan\n        run: |\n          cd terraform/environments/production\n          terraform plan -var=\"image_tag=${{ needs.build.outputs.image-tag }}\" -out=tfplan\n      \n      - name: Upload plan\n        uses: actions/upload-artifact@v3\n        with:\n          name: tfplan\n          path: terraform/environments/production/tfplan\n\n  deploy:\n    needs: [build, terraform-plan]\n    runs-on: ubuntu-latest\n    environment: production\n    steps:\n      - uses: actions/checkout@v3\n      \n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v2\n      \n      - name: Download plan\n        uses: actions/download-artifact@v3\n        with:\n          name: tfplan\n          path: terraform/environments/production\n      \n      - name: Terraform Apply\n        run: |\n          cd terraform/environments/production\n          terraform apply -auto-approve tfplan\n      \n      - name: Run smoke tests\n        run: |\n          # Wait for deployment\n          sleep 60\n          \n          # Test health endpoint\n          API_URL=$(cd terraform/environments/production && terraform output -raw api_gateway_url)\n          curl -f $API_URL/health || exit 1\n```\n\n## Cost Optimization\n\n### Resource Sizing Recommendations\n\n**Development Environment:**\n- ECS Tasks: 512 CPU / 1024 Memory, 1-2 tasks\n- RDS: db.t3.medium, Single-AZ\n- NAT Gateway: 1 gateway\n- Estimated cost: ~$200-300/month\n\n**Production Environment:**\n- ECS Tasks: 2048 CPU / 4096 Memory, 4-20 tasks (autoscale)\n- RDS: db.r6g.xlarge, Multi-AZ with read replica\n- NAT Gateway: 2 gateways (Multi-AZ)\n- VPC Endpoints: 6 endpoints (~$7/endpoint/month)\n- Estimated cost: ~$1,500-3,000/month (depending on load)\n\n### Cost Saving Strategies\n\n1. **Use VPC Endpoints** instead of NAT Gateway for AWS services ($0.01/GB vs $0.045/GB)\n2. **Fargate Spot** for non-production environments (70% cost reduction)\n3. **Reserved Capacity** for RDS in production (40% savings)\n4. **S3 Lifecycle Policies** for audit log archival (move to Glacier after 90 days)\n5. **CloudWatch Log Retention** policies (retain only what's needed for PCI)\n\n## Security Hardening Checklist\n\n- [ ] All connections use TLS 1.3\n- [ ] mTLS enforced for internal `/decrypt` endpoint\n- [ ] BDK never leaves KMS (use KMS Decrypt API)\n- [ ] Database encrypted at rest with KMS\n- [ ] VPC Flow Logs enabled for PCI zone\n- [ ] CloudTrail logging enabled for all KMS operations\n- [ ] IAM roles follow principle of least privilege\n- [ ] Security groups deny all by default\n- [ ] No public IPs assigned to ECS tasks\n- [ ] Secrets stored in Secrets Manager, not environment variables\n- [ ] Container runs as non-root user\n- [ ] Read-only root filesystem (if possible)\n- [ ] WAF rules enabled on API Gateway\n- [ ] Rate limiting configured per restaurant\n- [ ] Audit logs retained for 7 years (PCI compliance)\n- [ ] Regular security scanning (Trivy, Snyk, etc.)\n\n## Disaster Recovery\n\n### Backup Strategy\n\n**RDS Automated Backups:**\n- Daily snapshots, 30-day retention\n- Automated backup window: 03:00-04:00 UTC\n- Cross-region backup replication for production\n\n**Manual Snapshots:**\n- Before major deployments\n- Before database migrations\n- Retained indefinitely or until explicitly deleted\n\n**Point-in-Time Recovery (PITR):**\n- RDS supports PITR within backup retention period\n- RPO: 5 minutes (transaction log backups)\n\n### Recovery Procedures\n\n**RTO (Recovery Time Objective): 1 hour**\n**RPO (Recovery Point Objective): 5 minutes**\n\n**Scenario 1: Complete AZ Failure**\n- Multi-AZ RDS automatically fails over (1-2 minutes)\n- ECS tasks redistribute across remaining AZ (5 minutes)\n- Update Route 53 health checks if needed\n\n**Scenario 2: Regional Failure (DR)**\n- Restore RDS from cross-region snapshot\n- Deploy ECS tasks in DR region using Terraform\n- Update API Gateway to point to DR region\n- Estimated time: 30-60 minutes\n\n**Scenario 3: Database Corruption**\n- Restore from latest automated snapshot\n- Apply transaction logs for PITR\n- Validate data integrity\n- Estimated time: 15-30 minutes\n\n## Runbooks\n\n### Key Rotation - Service Encryption Keys (Every 90 Days)\n\n1. Generate new KMS key version via Terraform:\n   ```bash\n   terraform apply -var=\"rotate_service_key=true\"\n   ```\n\n2. Update `encryption_keys` table via migration:\n   ```sql\n   INSERT INTO encryption_keys (key_version, kms_key_id, is_active)\n   VALUES ('v2', 'arn:aws:kms:...', true);\n   \n   UPDATE encryption_keys SET is_active = false WHERE key_version = 'v1';\n   ```\n\n3. Deploy updated service configuration (new key version)\n\n4. Background job re-encrypts old tokens over 30 days\n\n5. After 90 days, schedule KMS key deletion\n\n### BDK Rotation (Annual)\n\n1. Create new BDK in KMS via Terraform\n2. Update Secrets Manager with new BDK ARN\n3. Deploy service with support for both BDKs\n4. New tokens use new BDK immediately\n5. After 24 hours (token TTL), retire old BDK\n\n### Zero-Downtime Deployment\n\n1. CI/CD builds new Docker image, pushes to ECR\n2. Terraform updates ECS task definition with new image\n3. ECS performs rolling deployment:\n   - Starts new tasks (green)\n   - Waits for health checks to pass\n   - Drains connections from old tasks (blue)\n   - Terminates old tasks\n4. Circuit breaker auto-rolls back on failure\n\n## Production Readiness Checklist\n\n- [ ] All Terraform modules tested in staging\n- [ ] Database migration tested with production-like data\n- [ ] Load testing completed (target: 500 RPS)\n- [ ] Disaster recovery procedures tested\n- [ ] Runbooks documented and validated\n- [ ] Monitoring dashboards configured\n- [ ] Alerting thresholds tuned\n- [ ] PCI compliance audit passed\n- [ ] Security penetration testing completed\n- [ ] On-call rotation established\n- [ ] Incident response procedures documented\n- [ ] API documentation published\n- [ ] SLAs defined and agreed upon\n\n## Dependencies\n\n- **Blocked by**: \n  - Payment Token Service application code complete [[s-7ujm]]\n  - Docker image builds successfully\n  - E2E tests passing [[i-24o2]]\n  \n- **Depends on**:\n  - AWS account with appropriate permissions\n  - Domain name and DNS hosted zone (Route 53)\n  - TLS certificates (ACM)\n  - Terraform state backend (S3 + DynamoDB)\n\n## Success Criteria\n\n- [ ] Infrastructure deployed via Terraform with no manual steps\n- [ ] All resources tagged appropriately\n- [ ] ECS service autoscales based on load\n- [ ] Blue-green deployments working\n- [ ] All monitoring alarms functional\n- [ ] PCI compliance requirements met\n- [ ] Load testing passes at 500+ RPS\n- [ ] Disaster recovery tested and validated\n- [ ] Documentation complete","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-11 06:43:32","updated_at":"2025-11-11 06:43:32","parent_id":null,"parent_uuid":null,"relationships":[{"from":"s-5for","from_type":"spec","to":"i-3a1m","to_type":"issue","type":"implements"},{"from":"s-5for","from_type":"spec","to":"s-7ujm","to_type":"spec","type":"implements"},{"from":"s-5for","from_type":"spec","to":"s-8c0t","to_type":"spec","type":"references"}],"tags":["aws","deployment","infrastructure","pci-compliant","terraform"]}
{"id":"s-1wow","uuid":"a147b6e4-c7ee-472a-bd8b-e3b9b2499eda","title":"CI/CD Pipeline, Git Hooks, and Test Infrastructure for Monorepo","file_path":"specs/ci_cd_pipeline_git_hooks_and_test_infrastructure_f.md","content":"## Overview\n\nImplement a comprehensive testing and CI/CD infrastructure for the payments-infra monorepo to ensure code quality, prevent regressions, and provide fast feedback loops for developers.\n\n## Goals\n\n1. **Fast feedback loops**: Developers should get test results within seconds locally, minutes in CI\n2. **Prevent bad commits**: Strict pre-commit hooks that block commits on any failure\n3. **Intelligent test execution**: Run only tests affected by changes, but always run critical integration/e2e tests\n4. **Parallel execution**: Run tests for different services in parallel to maximize speed\n5. **Developer ergonomics**: Easy to use, clear error messages, minimal friction\n\n## Architecture\n\n### Monorepo Structure\n```\npayments-infra/\n├── services/\n│   ├── payment-token/           (unit + integration tests)\n│   ├── authorization-api/       (unit + integration tests)\n│   └── auth-processor-worker/   (unit + integration tests)\n├── shared/\n│   ├── payments_common/         (unit tests)\n│   └── payments_proto/          (no tests, generated code)\n├── tests/                       (e2e tests using tox)\n└── infrastructure/\n    └── migrations/              (no tests)\n```\n\n### Change Detection Strategy\n\n**To be determined** - See [[i-TBD]] for investigation of approaches:\n- Custom Python script (git diff based)\n- Nx/Turborepo (sophisticated caching)\n- GitHub Actions path filters\n\nRequirements:\n- Detect which services changed based on file paths\n- Detect when shared packages change (affects ALL services)\n- Support local execution (git hooks) and CI execution\n- Output list of affected services to run tests for\n\n### Test Execution Strategy\n\n#### Test Levels\n1. **Unit tests**: Fast, no external dependencies, per-service\n2. **Integration tests**: Database, SQS, external APIs, per-service\n3. **E2E tests**: Full system tests across all services (always run)\n\n#### Test Caching Rules\n- **Unit tests**: Cache results based on service code + dependencies hash\n- **Integration tests**: Always run for affected services (no caching)\n- **E2E tests**: Always run (critical path, no caching)\n\n#### Execution Priority\n```\nLocal (git hooks):\n  pre-commit: format → lint → typecheck → unit tests (staged files)\n  pre-push: integration tests (affected services)\n\nCI (GitHub Actions):\n  PR: unit → integration → e2e (parallel service jobs)\n  Main: unit → integration → e2e → (future: auto-deploy)\n```\n\n## Components\n\n### 1. Git Hooks (Pre-commit Framework)\n\n**File**: `.pre-commit-config.yaml`\n\nHooks to implement:\n- **black**: Auto-format Python code (all staged files)\n- **ruff**: Lint and fix issues (all staged files)\n- **mypy**: Type check (affected services only)\n- **pytest (unit)**: Run unit tests for affected services\n- **proto validation**: Ensure protobuf files are valid\n\n**Strictness**: Block commits if ANY check fails\n\nConfiguration:\n- Run in parallel where possible (black + ruff can run together)\n- Skip certain hooks with `SKIP=hook-name` env var for emergencies\n- Clear error messages pointing to the failing file and fix instructions\n\n### 2. Claude Code Hooks\n\n**File**: `.claude/hooks.yaml` (or similar)\n\nHooks:\n- **on-file-save**: Auto-format file, show lint warnings\n- **on-file-change**: Run unit tests for affected service (background)\n- **on-git-commit-attempt**: Surface pre-commit hook results in Claude interface\n- **on-pr-create**: Show CI status and test results\n\nBenefits:\n- Developers get instant feedback without leaving Claude\n- Test failures surface immediately during development\n- Reduces context switching\n\n### 3. GitHub Actions CI/CD Pipeline\n\n**Files**: \n- `.github/workflows/ci.yml` (main CI pipeline)\n- `.github/workflows/pr.yml` (PR-specific checks)\n\n#### Main CI Pipeline (`ci.yml`)\n\nTrigger: `push` to any branch, `pull_request`\n\nJobs:\n```yaml\n1. setup:\n   - Checkout code\n   - Setup Python 3.11\n   - Cache poetry dependencies (per service)\n   - Detect changed services (using change detection tool)\n   \n2. lint-and-typecheck:\n   - Run ruff on all services\n   - Run mypy on all services\n   - Fast feedback on code quality\n   \n3. test-[service-name] (matrix job):\n   - For each affected service in parallel:\n     - Run unit tests\n     - Run integration tests\n     - Upload coverage reports\n   \n4. test-e2e:\n   - Start docker-compose (localstack, postgres, etc.)\n   - Run tox e2e tests\n   - Always run (critical path)\n   \n5. report:\n   - Aggregate coverage from all jobs\n   - Comment on PR with results\n   - Fail if coverage drops below threshold\n```\n\n#### Parallel Execution Strategy\n- Lint/typecheck runs once for all code\n- Each service gets its own test job (runs in parallel)\n- E2E tests run after all service tests pass\n- Maximum parallelism with dependencies\n\n#### Caching Strategy\n```yaml\n- Poetry dependencies: Hash pyproject.toml + poetry.lock per service\n- Pytest cache: Hash test files + source files\n- Docker layers: Cache intermediate build stages\n- Tox environments: Cache .tox directory (invalidate on deps change)\n```\n\n### 4. Change Detection Tool\n\n**File**: `scripts/detect_changes.py` (or similar)\n\nInput: `base_ref` (e.g., `origin/main`), `head_ref` (current commit)\n\nOutput: JSON with affected services\n```json\n{\n  \"services\": [\"payment-token\", \"auth-processor-worker\"],\n  \"shared_changed\": true,\n  \"run_all_tests\": false\n}\n```\n\nLogic:\n- If `shared/` changes: run tests for ALL services\n- If `services/X/` changes: run tests for service X\n- If `tests/` changes: run e2e tests\n- If `infrastructure/migrations/` changes: run integration tests for all services\n\n### 5. Test Orchestration Scripts\n\n**Files**: \n- `scripts/run_affected_tests.sh`\n- `scripts/run_tests_parallel.sh`\n\nUsage:\n```bash\n# Local development\n./scripts/run_affected_tests.sh --level=unit --base=main\n\n# CI\n./scripts/run_tests_parallel.sh --services=\"payment-token,authorization-api\"\n```\n\nFeatures:\n- Colorized output\n- Progress indicators\n- Time tracking per service\n- Fail fast or collect all failures\n- Summary report at end\n\n## Success Criteria\n\n1. **Pre-commit hooks**:\n   - Block commits with failing tests\n   - Run in < 30 seconds for typical changes\n   - Clear error messages\n\n2. **CI Pipeline**:\n   - PR feedback in < 5 minutes for service-only changes\n   - Full pipeline (all services + e2e) in < 15 minutes\n   - Parallel service jobs save 50%+ time vs sequential\n\n3. **Developer Experience**:\n   - One command setup: `make setup-hooks`\n   - Hooks can be bypassed in emergencies: `git commit --no-verify`\n   - CI results visible in PR comments\n\n4. **Test Coverage**:\n   - Maintain > 80% coverage for all services\n   - No commits that decrease coverage without justification\n\n## Implementation Phases\n\n### Phase 1: Git Hooks (Highest Priority)\n- Set up pre-commit framework\n- Configure black, ruff, mypy hooks\n- Add unit test execution for affected services\n- Document how to install and use\n\n### Phase 2: Change Detection\n- Investigate approaches (Nx, custom script, path filters)\n- Implement chosen solution\n- Test with various change scenarios\n\n### Phase 3: GitHub Actions CI\n- Create ci.yml workflow\n- Implement parallel service test jobs\n- Add e2e test job\n- Configure caching\n\n### Phase 4: Test Orchestration\n- Create helper scripts for running tests\n- Integrate change detection with test execution\n- Add progress reporting\n\n### Phase 5: Claude Code Integration\n- Configure Claude hooks (if supported)\n- Integrate with pre-commit results\n- Add test running capabilities\n\n### Phase 6: Optimization\n- Fine-tune caching strategies\n- Optimize test selection logic\n- Reduce CI run times\n- Add test result caching\n\n## Open Questions\n\n1. Should we use pre-commit framework or custom git hooks?\n2. What's the right balance between speed and thoroughness in pre-commit?\n3. Should integration tests run in pre-commit or only pre-push?\n4. Do we want branch protection rules in GitHub?\n5. Should we add automatic dependency updates (Dependabot)?\n\n## Related Issues\n\n- [[i-TBD]]: Investigate monorepo change detection approaches\n","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-13 09:47:07","updated_at":"2025-11-13 09:47:07","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["ci-cd","infrastructure","monorepo","testing"]}
{"id":"s-63fi","uuid":"c5c2bc04-80ee-4791-9cda-ff72306ae315","title":"Frontend Online Ordering Demo Application","file_path":"specs/frontend_online_ordering_demo_application.md","content":"## Overview\n\nA frontend web application that demonstrates the complete payment processing flow using the payments infrastructure. This application provides a realistic online ordering experience for a fictional restaurant, allowing users to browse a menu, build a cart, and complete payment transactions using real payment processing.\n\n**Primary Goals:**\n\n1. Showcase the end-to-end payment flow: token creation → authorization → status tracking\n1. Provide a user-friendly interface for testing and demonstrating the payment system\n1. Demonstrate integration with Stripe payment processor\n1. Serve as a reference implementation for future restaurant integrations\n\n**NOT Goals (Future Scope):**\n\n- Real restaurant menu management system\n- Multi-restaurant support\n- User authentication/accounts\n- Order fulfillment workflow\n- Production-ready security hardening\n\n## Service Boundaries\n\n- **Owns**: Frontend UI, cart management, mock menu data, payment form, status display\n- **Does NOT own**: Payment processing, token encryption, restaurant configuration, menu management API\n- **Dependencies**: Payment Token Service, Authorization API Service, Stripe processor\n\n## Mock Data Architecture\n\n### Restaurant Configuration\n\n**Hardcoded for demo purposes:**\n\n```javascript\nconst DEMO_RESTAURANT = {\n  id: '12345678-1234-5678-1234-567812345678',  // Fixed UUID\n  name: 'Demo Pizzeria',\n  address: '123 Main St, San Francisco, CA',\n  currency: 'USD'\n};\n```\n\n### Menu Items (Mock Data)\n\n**Stored in frontend code**, with placeholder for future Menu API Service:\n\n```javascript\n// TODO: Replace with Menu API Service call\n// GET /api/v1/restaurants/{restaurant_id}/menu\nconst MOCK_MENU_ITEMS = [\n  {\n    id: 'item-001',\n    category: 'Pizza',\n    name: 'Margherita Pizza',\n    description: 'Fresh mozzarella, tomato sauce, basil',\n    price_cents: 1400,  // $14.00\n    image_url: '/assets/margherita.jpg'\n  },\n  {\n    id: 'item-002',\n    category: 'Pizza',\n    name: 'Pepperoni Pizza',\n    description: 'Classic pepperoni with mozzarella',\n    price_cents: 1600,\n    image_url: '/assets/pepperoni.jpg'\n  },\n  {\n    id: 'item-003',\n    category: 'Appetizers',\n    name: 'Garlic Bread',\n    description: 'Toasted bread with garlic butter',\n    price_cents: 600,\n    image_url: '/assets/garlic-bread.jpg'\n  },\n  {\n    id: 'item-004',\n    category: 'Beverages',\n    name: 'Coca-Cola',\n    description: 'Classic Coca-Cola (12 oz)',\n    price_cents: 300,\n    image_url: '/assets/coke.jpg'\n  },\n  {\n    id: 'item-005',\n    category: 'Pizza',\n    name: 'Vegetarian Supreme',\n    description: 'Mushrooms, peppers, onions, olives, tomatoes',\n    price_cents: 1500,\n    image_url: '/assets/veggie.jpg'\n  }\n];\n```\n\n### Cart State Management\n\n**Client-side state**, with placeholder for future Order Management Service:\n\n```javascript\n// TODO: Replace with Order Management API\n// POST /api/v1/orders (create order draft)\n// PATCH /api/v1/orders/{order_id} (update cart)\nconst cart = {\n  items: [\n    {\n      menu_item_id: 'item-001',\n      quantity: 2,\n      unit_price_cents: 1400,\n      subtotal_cents: 2800\n    }\n  ],\n  subtotal_cents: 2800,\n  tax_cents: 252,  // 9% tax (hardcoded for demo)\n  total_cents: 3052\n};\n```\n\n## Frontend Technology Stack\n\n### Recommended: Simple HTML/JavaScript\n\n**For maximum accessibility and ease of modification:**\n\n```\nfrontend/\n├── index.html           # Main page (menu + cart)\n├── checkout.html        # Checkout page (payment form)\n├── status.html          # Payment status page\n├── assets/\n│   ├── css/\n│   │   └── styles.css\n│   ├── js/\n│   │   ├── menu.js      # Menu rendering\n│   │   ├── cart.js      # Cart management\n│   │   ├── payment.js   # Payment flow\n│   │   └── api.js       # API client for backend services\n│   └── images/\n│       └── [menu item images]\n└── config.js            # Configuration (restaurant ID, API URLs)\n```\n\n**Technology choices:**\n\n- Plain HTML/CSS/JavaScript (no framework required)\n- Bootstrap or Tailwind for styling (optional)\n- LocalStorage for cart persistence\n- Fetch API for HTTP requests\n\n**Alternative (if team prefers framework):**\n\n- React + Vite (for modern dev experience)\n- Vue.js (for simplicity)\n- Next.js (if SSR needed in future)\n\n## Page Structure & User Flow\n\n### Page 1: Menu & Cart (`/` or `/index.html`)\n\n**Layout:**\n\n```\n┌─────────────────────────────────────────────────────────┐\n│  Demo Pizzeria - Online Ordering                        │\n├─────────────────────────────────────────────────────────┤\n│                                                          │\n│  Menu                           Cart (3 items) $30.52   │\n│  ────                           ──────────────────────  │\n│                                                          │\n│  [Pizza]                        2x Margherita    $28.00 │\n│  • Margherita  [$14.00] [Add]   1x Garlic Bread  $ 6.00 │\n│  • Pepperoni   [$16.00] [Add]                           │\n│  • Veggie      [$15.00] [Add]   Subtotal:        $34.00 │\n│                                  Tax (9%):        $ 3.06 │\n│  [Appetizers]                   ──────────────────────  │\n│  • Garlic Bread [$6.00] [Add]   Total:           $37.06 │\n│                                                          │\n│  [Beverages]                    [Clear Cart] [Checkout] │\n│  • Coca-Cola    [$3.00] [Add]                           │\n└─────────────────────────────────────────────────────────┘\n```\n\n**Features:**\n\n- Category-based menu display\n- Add to cart with quantity increment\n- Live cart total calculation\n- Clear cart button\n- Checkout button (disabled if cart empty)\n\n### Page 2: Checkout & Payment (`/checkout.html`)\n\n**Layout:**\n\n```\n┌─────────────────────────────────────────────────────────┐\n│  Checkout - Demo Pizzeria                               │\n├─────────────────────────────────────────────────────────┤\n│                                                          │\n│  Order Summary                                          │\n│  ────────────                                           │\n│  2x Margherita Pizza                           $28.00   │\n│  1x Garlic Bread                               $ 6.00   │\n│                                                          │\n│  Subtotal:                                     $34.00   │\n│  Tax (9%):                                     $ 3.06   │\n│  Total:                                        $37.06   │\n│                                                          │\n│  ─────────────────────────────────────────────────────  │\n│                                                          │\n│  Payment Information                                    │\n│  ───────────────────                                    │\n│                                                          │\n│  Card Number:    [4242 4242 4242 4242]                 │\n│  Expiry:         [12] / [2025]                          │\n│  CVV:            [123]                                   │\n│  Cardholder:     [John Doe]                             │\n│                                                          │\n│  [Back to Menu]              [Place Order & Pay]        │\n│                                                          │\n│  ──────────────────────────────────────────────────────│\n│  Test Cards:                                            │\n│  • 4242424242424242 - Success                           │\n│  • 4000000000009995 - Declined (insufficient funds)     │\n│  • 4000000000000002 - Declined (card declined)          │\n└─────────────────────────────────────────────────────────┘\n```\n\n**Payment Flow:**\n\n1. User enters card details\n1. Frontend creates payment token (POST /v1/payment-tokens)\n1. Frontend submits authorization (POST /v1/authorize)\n1. Redirect to status page with auth\\_request\\_id\n\n### Page 3: Payment Status (`/status.html?auth_request_id=xxx`)\n\n**Layout (Processing):**\n\n```\n┌─────────────────────────────────────────────────────────┐\n│  Payment Status - Demo Pizzeria                         │\n├─────────────────────────────────────────────────────────┤\n│                                                          │\n│         [Spinner Animation]                             │\n│                                                          │\n│         Processing your payment...                      │\n│         Please wait                                     │\n│                                                          │\n│  Order Total: $37.06                                    │\n│  Auth Request ID: 550e8400-e29b-41d4-a716-446655440000  │\n│                                                          │\n└─────────────────────────────────────────────────────────┘\n```\n\n**Layout (Success):**\n\n```\n┌─────────────────────────────────────────────────────────┐\n│  Payment Status - Demo Pizzeria                         │\n├─────────────────────────────────────────────────────────┤\n│                                                          │\n│         ✅ Payment Successful!                          │\n│                                                          │\n│  Order Details                                          │\n│  ─────────────                                          │\n│  Amount:              $37.06 USD                        │\n│  Status:              Authorized                        │\n│                                                          │\n│  Transaction Details                                    │\n│  ────────────────────                                   │\n│  Auth Request ID:     550e8400-e29b-...                 │\n│  Authorization Code:  AUTH_123456                       │\n│  Processor:           Stripe                            │\n│  Processor ID:        ch_3N...                          │\n│  Timestamp:           2025-11-13 14:32:10 UTC           │\n│                                                          │\n│  [Place New Order]     [View on Stripe Dashboard]       │\n│                                                          │\n└─────────────────────────────────────────────────────────┘\n```\n\n**Layout (Declined):**\n\n```\n┌─────────────────────────────────────────────────────────┐\n│  Payment Status - Demo Pizzeria                         │\n├─────────────────────────────────────────────────────────┤\n│                                                          │\n│         ❌ Payment Declined                             │\n│                                                          │\n│  Reason: Insufficient funds                             │\n│  Decline Code: insufficient_funds                       │\n│                                                          │\n│  Order Total: $37.06                                    │\n│                                                          │\n│  [Try Again]          [Back to Menu]                    │\n│                                                          │\n└─────────────────────────────────────────────────────────┘\n```\n\n**Status Polling:**\n\n- Poll GET /v1/authorize/{id}/status every 1 second\n- Max 30 seconds timeout\n- Display appropriate UI based on status:\n  - PENDING/PROCESSING → Show spinner\n  - AUTHORIZED → Show success\n  - DENIED → Show decline reason\n  - FAILED → Show error message\n\n## API Partner Encryption Keys\n\n### Overview\n\n**This frontend demonstrates the online ordering flow**, not POS terminal encryption. In this model:\n\n- **API partners** (restaurant websites, mobile apps) get their own encryption keys\n- Each API partner has a unique **encryption key ID** embedded in their code\n- Our backend maintains corresponding **decryption keys** in KMS\n- Encrypted payloads include metadata about which key was used\n\n### Key Management Architecture (Future)\n\n**Future implementation** will include an API Partner Key Management Service:\n\n```\nAPI Partner Onboarding Flow:\n1. Restaurant/partner requests encryption key\n2. Key Management API generates:\n   - Encryption key (delivered to partner)\n   - Corresponding decryption key (stored in KMS)\n   - Unique key_id for identification\n3. Partner embeds encryption key + key_id in their website/app\n4. Payment Token Service looks up decryption key by key_id\n```\n\n**Key Management API (placeholder):**\n\n```\nPOST /v1/api-keys/generate\n{\n  \"partner_name\": \"Demo Pizzeria Web\",\n  \"partner_type\": \"online_ordering\",\n  \"restaurant_id\": \"12345678-...\"\n}\n\nResponse:\n{\n  \"key_id\": \"ak_550e8400...\",\n  \"encryption_key\": \"base64EncodedKey...\",\n  \"created_at\": \"2025-11-13T...\",\n  \"expires_at\": null\n}\n```\n\n**For this demo**, we'll use a **primary encryption key** that's pre-configured, but the code will be structured to support multiple keys in the future.\n\n### Demo Implementation: Single Primary Key\n\n**For initial demo**, use a hardcoded primary key:\n\n```javascript\nconst CONFIG = {\n  // API Partner Key (for online ordering)\n  // In production: Each API partner gets their own unique key\n  // For demo: We use a single primary key\n  API_PARTNER_KEY_ID: 'demo-primary-key-001',\n  \n  // This would normally be retrieved from environment or key server\n  // For demo: Hardcoded (NOT SECURE - for demo only!)\n  API_PARTNER_ENCRYPTION_KEY: 'demo-encryption-key-not-for-production',\n  \n  // Note: Real implementation would NOT expose the encryption key in frontend\n  // Instead, encryption would happen server-side or use a different approach\n  // (e.g., Stripe Elements for web, or encrypted communication channel)\n};\n```\n\n### Production Key Management (Future)\n\n**Phase 1 (Demo):**\n\n- Single primary key hardcoded\n- `key_id` = \"primary\"\n- Encryption/decryption both use same primary key from config\n\n**Phase 2 (Multi-partner):**\n\n- Key Generation API for partner onboarding\n- Each partner gets unique `key_id` and encryption key\n- Decryption keys stored in AWS KMS\n- Payment Token Service looks up decryption key by `key_id`\n\n**Phase 3 (Key Rotation):**\n\n- Support multiple active keys per partner\n- Automatic key rotation (e.g., every 90 days)\n- Graceful deprecation of old keys\n\n**Phase 4 (BDK for Hardware):**\n\n- For POS terminals: BDK-based key derivation\n- For online: Continue using API partner keys\n- Different encryption paths for different device types\n\n## API Integration\n\n### Configuration (`config.js`)\n\n```javascript\nconst CONFIG = {\n  RESTAURANT_ID: '12345678-1234-5678-1234-567812345678',\n  \n  // Service URLs (configurable for local vs deployed)\n  PAYMENT_TOKEN_SERVICE_URL: 'http://localhost:8001',\n  AUTHORIZATION_API_URL: 'http://localhost:8002',\n  \n  // API Partner Encryption Key (for online ordering)\n  // NOTE: In production, encryption should happen server-side or use\n  // a secure method like Stripe Elements. This is for demo purposes only.\n  API_PARTNER_KEY_ID: 'demo-primary-key-001',\n  \n  // Tax rate (hardcoded for demo)\n  TAX_RATE: 0.09,  // 9%\n  \n  // Polling config\n  STATUS_POLL_INTERVAL_MS: 1000,\n  STATUS_POLL_TIMEOUT_MS: 30000\n};\n```\n\n### Payment Token Creation\n\n**Endpoint:** `POST /v1/payment-tokens`\n\n```javascript\nasync function createPaymentToken(cardData) {\n  // 1. Get encryption key for this API partner\n  // In production: Retrieved securely from backend or key server\n  // For demo: Using hardcoded primary key\n  const encryptionKey = await getApiPartnerEncryptionKey(CONFIG.API_PARTNER_KEY_ID);\n  \n  // 2. Encrypt card data\n  const { encrypted, iv, keyId } = await encryptCardData(cardData, encryptionKey, CONFIG.API_PARTNER_KEY_ID);\n  \n  // 3. Create payment token\n  const response = await fetch(`${CONFIG.PAYMENT_TOKEN_SERVICE_URL}/v1/payment-tokens`, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n      'X-Idempotency-Key': generateUUID()\n    },\n    body: JSON.stringify({\n      restaurant_id: CONFIG.RESTAURANT_ID,\n      encrypted_payment_data: base64Encode(encrypted),\n      encryption_metadata: {\n        key_id: keyId,           // Which key was used to encrypt\n        algorithm: 'AES-256-GCM',\n        iv: base64Encode(iv)\n      },\n      metadata: {\n        card_brand: detectCardBrand(cardData.card_number),\n        last4: cardData.card_number.slice(-4),\n        source: 'online_ordering'\n      }\n    })\n  });\n  \n  const result = await response.json();\n  return result.payment_token;  // e.g., \"pt_550e8400-...\"\n}\n\n// Get encryption key for API partner\nasync function getApiPartnerEncryptionKey(keyId) {\n  // DEMO IMPLEMENTATION: Use hardcoded primary key\n  // Production implementation would fetch from secure key server\n  \n  if (keyId === 'demo-primary-key-001') {\n    // For demo: derive from a known master key\n    // NOTE: This is NOT secure - real implementation uses proper key management\n    const mockMasterKey = 'demo-master-key-not-for-production';\n    return await deriveEncryptionKey(mockMasterKey, keyId);\n  }\n  \n  throw new Error(`Unknown key_id: ${keyId}`);\n  \n  // FUTURE IMPLEMENTATION:\n  // const response = await fetch(`${KEY_SERVER_URL}/v1/keys/${keyId}`);\n  // return await response.json();\n}\n\nasync function deriveEncryptionKey(masterKey, keyId) {\n  // Simple HKDF-based key derivation for demo\n  // In production, use proper KMS or HSM\n  const encoder = new TextEncoder();\n  const keyMaterial = await crypto.subtle.importKey(\n    'raw',\n    encoder.encode(masterKey),\n    { name: 'PBKDF2' },\n    false,\n    ['deriveKey']\n  );\n  \n  return await crypto.subtle.deriveKey(\n    {\n      name: 'PBKDF2',\n      salt: encoder.encode(keyId),\n      iterations: 100000,\n      hash: 'SHA-256'\n    },\n    keyMaterial,\n    { name: 'AES-GCM', length: 256 },\n    true,\n    ['encrypt']\n  );\n}\n\nasync function encryptCardData(cardData, key, keyId) {\n  // AES-GCM encryption\n  const plaintext = JSON.stringify({\n    card_number: cardData.card_number,\n    exp_month: cardData.exp_month,\n    exp_year: cardData.exp_year,\n    cvv: cardData.cvv,\n    cardholder_name: cardData.cardholder_name\n  });\n  \n  const iv = crypto.getRandomValues(new Uint8Array(12));\n  const encrypted = await crypto.subtle.encrypt(\n    { name: 'AES-GCM', iv },\n    key,\n    new TextEncoder().encode(plaintext)\n  );\n  \n  return { \n    encrypted, \n    iv,\n    keyId  // Return key ID so backend knows which decryption key to use\n  };\n}\n```\n\n**IMPORTANT Security Notes:**\n\n1. **This demo simplifies encryption** for demonstration purposes\n1. **In production for online ordering:**\n\n- Card data should NEVER be encrypted in browser JavaScript\n- Use Stripe Elements or similar (card data goes directly to processor)\n- OR encrypt server-side after collecting over HTTPS\n- Browser-based encryption is inherently insecure (keys can be extracted)\n\n1. **For POS terminals:**\n\n- Encryption happens in secure hardware module\n- BDK-based key derivation (different from API partner keys)\n- Derived keys never leave the device\n\n1. **This architecture supports both:**\n\n- Online ordering: API partner keys (this spec)\n- POS terminals: BDK-based encryption (different flow)\n\n### Authorization Request\n\n**Endpoint:** `POST /v1/authorize`\n\n```javascript\nasync function authorizePayment(paymentToken, amountCents) {\n  const idempotencyKey = generateUUID();\n  \n  const response = await fetch(`${CONFIG.AUTHORIZATION_API_URL}/v1/authorize`, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n      'X-Idempotency-Key': idempotencyKey\n    },\n    body: JSON.stringify({\n      restaurant_id: CONFIG.RESTAURANT_ID,\n      payment_token: paymentToken,\n      amount_cents: amountCents,\n      currency: 'USD',\n      metadata: {\n        order_source: 'frontend_demo',\n        cart_items: getCartItemsSummary()\n      }\n    })\n  });\n  \n  const result = await response.json();\n  return result.auth_request_id;\n}\n```\n\n### Status Polling\n\n**Endpoint:** `GET /v1/authorize/{auth_request_id}/status`\n\n```javascript\nasync function pollPaymentStatus(authRequestId) {\n  const startTime = Date.now();\n  \n  while (Date.now() - startTime < CONFIG.STATUS_POLL_TIMEOUT_MS) {\n    const response = await fetch(\n      `${CONFIG.AUTHORIZATION_API_URL}/v1/authorize/${authRequestId}/status?restaurant_id=${CONFIG.RESTAURANT_ID}`\n    );\n    \n    const status = await response.json();\n    \n    // Check if terminal state\n    if (['AUTHORIZED', 'DENIED', 'FAILED'].includes(status.status)) {\n      return status;\n    }\n    \n    // Wait before next poll\n    await sleep(CONFIG.STATUS_POLL_INTERVAL_MS);\n  }\n  \n  throw new Error('Payment status polling timeout');\n}\n```\n\n## Payment Token Service Changes\n\n**To support API partner keys**, the Payment Token Service needs to:\n\n1. **Accept** `encryption_metadata` **in request:**\n\n```json\n{\n  \"encrypted_payment_data\": \"base64...\",\n  \"encryption_metadata\": {\n    \"key_id\": \"demo-primary-key-001\",\n    \"algorithm\": \"AES-256-GCM\",\n    \"iv\": \"base64...\"\n  }\n}\n```\n\n1. **Look up decryption key by** `key_id`**:**\n\n```python\nasync def get_decryption_key(key_id: str) -> bytes:\n    # Phase 1: Use primary key for demo\n    if key_id == \"demo-primary-key-001\" or key_id == \"primary\":\n        return get_primary_decryption_key()\n    \n    # Phase 2: Look up in database\n    key_config = await db.get_api_partner_key(key_id)\n    return await kms_client.decrypt(key_config.encrypted_decryption_key)\n```\n\n1. **Store** `key_id` **with encrypted token** (for audit trail)\n1. **Support multiple active keys** per restaurant (for key rotation)\n\n**See issue for implementation details:** (will create below)\n\n## Deployment & Make Commands\n\n### Docker Compose Configuration\n\n**Create** `frontend/Dockerfile`**:**\n\n```dockerfile\nFROM nginx:alpine\n\n# Copy frontend files\nCOPY index.html /usr/share/nginx/html/\nCOPY checkout.html /usr/share/nginx/html/\nCOPY status.html /usr/share/nginx/html/\nCOPY assets/ /usr/share/nginx/html/assets/\nCOPY config.js /usr/share/nginx/html/\n\n# Configure nginx\nCOPY nginx.conf /etc/nginx/conf.d/default.conf\n\nEXPOSE 80\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n```\n\n### Root-Level Makefile\n\n**Add to root** `Makefile`**:**\n\n```makefile\n.PHONY: start-all start-frontend start-payment-token start-auth-api start-worker stop-all\n\n# Start all services together\nstart-all:\n\\t@echo \"Starting all services...\"\n\\tdocker-compose up -d postgres localstack\n\\t@echo \"Waiting for infrastructure...\"\n\\tsleep 5\n\\tdocker-compose up -d payment-token authorization-api auth-worker frontend\n\\t@echo \"\"\n\\t@echo \"✅ All services started!\"\n\\t@echo \"\"\n\\t@echo \"Frontend:            http://localhost:3000\"\n\\t@echo \"Payment Token API:   http://localhost:8001\"\n\\t@echo \"Authorization API:   http://localhost:8002\"\n\\t@echo \"Stripe Dashboard:    https://dashboard.stripe.com/test/payments\"\n\n# Start individual services\nstart-frontend:\n\\tdocker-compose up -d frontend\n\\t@echo \"Frontend available at http://localhost:3000\"\n\nstart-payment-token:\n\\tdocker-compose up -d postgres localstack\n\\tsleep 3\n\\tdocker-compose up -d payment-token\n\\t@echo \"Payment Token Service available at http://localhost:8001\"\n\nstart-auth-api:\n\\tdocker-compose up -d postgres localstack\n\\tsleep 3\n\\tdocker-compose up -d authorization-api\n\\t@echo \"Authorization API available at http://localhost:8002\"\n\nstart-worker:\n\\tdocker-compose up -d postgres localstack\n\\tsleep 3\n\\tdocker-compose up -d auth-worker\n\\t@echo \"Auth Processor Worker started\"\n\n# Stop all services\nstop-all:\n\\tdocker-compose down\n\\t@echo \"All services stopped\"\n\n# Clean restart\nrestart-all: stop-all start-all\n\n# View logs\nlogs-frontend:\n\\tdocker-compose logs -f frontend\n\nlogs-payment:\n\\tdocker-compose logs -f payment-token authorization-api auth-worker\n\n# Database setup\nsetup-db:\n\\t@echo \"Running database migrations...\"\n\\tcd services/payment-token && poetry run alembic upgrade head\n\\tcd services/authorization-api && poetry run alembic upgrade head\n\\t@echo \"Database setup complete\"\n\n# Setup test restaurant config\nsetup-demo-restaurant:\n\\t@echo \"Setting up demo restaurant configuration...\"\n\\t./scripts/setup-demo-restaurant.sh\n\\t@echo \"Demo restaurant configured\"\n```\n\n### Setup Script\n\n**Create** `scripts/setup-demo-restaurant.sh`**:**\n\n```bash\n#!/bin/bash\nset -e\n\nRESTAURANT_ID=\"12345678-1234-5678-1234-567812345678\"\nSTRIPE_API_KEY=\"${STRIPE_API_KEY:-sk_test_...}\"\n\necho \"Configuring restaurant: $RESTAURANT_ID\"\n\n# Insert restaurant payment config\ndocker-compose exec -T postgres psql -U postgres -d payment_events <<EOF\nINSERT INTO restaurant_payment_configs (\n    restaurant_id,\n    config_version,\n    processor_name,\n    processor_config,\n    updated_at,\n    is_active\n) VALUES (\n    '$RESTAURANT_ID',\n    'v1',\n    'stripe',\n    '{\"stripe_api_key\": \"$STRIPE_API_KEY\"}'::jsonb,\n    NOW(),\n    true\n) ON CONFLICT (restaurant_id) DO UPDATE\nSET processor_config = '{\"stripe_api_key\": \"$STRIPE_API_KEY\"}'::jsonb,\n    updated_at = NOW();\nEOF\n\necho \"✅ Restaurant configured with Stripe processor\"\n```\n\n## Stripe Integration\n\n### Configuration\n\n**Required environment variables:**\n\n```bash\n# Stripe API keys (from https://dashboard.stripe.com/test/apikeys)\nSTRIPE_API_KEY=sk_test_...\nSTRIPE_PUBLISHABLE_KEY=pk_test_...  # Not used in backend, but frontend can display\n\n# Webhook secret (optional, for production)\nSTRIPE_WEBHOOK_SECRET=whsec_...\n```\n\n### Restaurant Payment Config\n\n**Database entry for demo restaurant:**\n\n```sql\nINSERT INTO restaurant_payment_configs (\n    restaurant_id,\n    config_version,\n    processor_name,\n    processor_config,\n    updated_at,\n    is_active\n) VALUES (\n    '12345678-1234-5678-1234-567812345678',\n    'v1',\n    'stripe',\n    '{\n        \"stripe_api_key\": \"sk_test_...\",\n        \"capture_method\": \"automatic\",\n        \"statement_descriptor\": \"DEMO PIZZERIA\"\n    }'::jsonb,\n    NOW(),\n    true\n);\n```\n\n### Stripe Test Cards\n\n**Display in frontend for testing:**\n\n```\nSuccess:\n  • 4242 4242 4242 4242 - Visa (approved)\n  • 5555 5555 5555 4444 - Mastercard (approved)\n\nDecline:\n  • 4000 0000 0000 9995 - Insufficient funds\n  • 4000 0000 0000 0002 - Card declined\n  • 4000 0000 0000 9987 - Lost card\n  • 4000 0000 0000 9979 - Stolen card\n\nExpiry: Any future date (e.g., 12/2025)\nCVV: Any 3 digits (e.g., 123)\n```\n\n### Viewing Results in Stripe Dashboard\n\n**After successful payment:**\n\n1. Go to [https://dashboard.stripe.com/test/payments](https://dashboard.stripe.com/test/payments)\n1. Find charge by `processor_auth_id` (e.g., `ch_3N...`)\n1. View:\n\n- Amount charged\n- Card details (last 4 digits)\n- Metadata (order\\_id, etc.)\n- Timeline (authorized, captured, etc.)\n\n**Frontend should display Stripe Dashboard link:**\n\n```javascript\nfunction getStripeDashboardUrl(processorAuthId) {\n  // Extract charge ID from processor_auth_id\n  if (processorAuthId.startsWith('ch_')) {\n    return `https://dashboard.stripe.com/test/payments/${processorAuthId}`;\n  }\n  return null;\n}\n```\n\n## Future Placeholders\n\n### Menu API Service (Not Implemented)\n\n**Placeholder in code:**\n\n```javascript\n// TODO: Replace with Menu API Service\n// GET /api/v1/restaurants/{restaurant_id}/menu\n// Response:\n// {\n//   \"menu_version\": \"v2\",\n//   \"categories\": [...],\n//   \"items\": [...],\n//   \"updated_at\": \"2025-11-13T14:00:00Z\"\n// }\n\nasync function fetchMenu(restaurantId) {\n  // For now, return mock data\n  return MOCK_MENU_ITEMS;\n  \n  // Future implementation:\n  // const response = await fetch(`/api/v1/restaurants/${restaurantId}/menu`);\n  // return await response.json();\n}\n```\n\n### Order Management Service (Not Implemented)\n\n**Placeholder in code:**\n\n```javascript\n// TODO: Replace with Order Management Service\n// POST /api/v1/orders (create order draft)\n// PATCH /api/v1/orders/{order_id}/items (update cart)\n// POST /api/v1/orders/{order_id}/submit (finalize order)\n\nclass CartManager {\n  constructor() {\n    // For now, use localStorage\n    this.storage = window.localStorage;\n  }\n  \n  async saveCart(cart) {\n    this.storage.setItem('demo_cart', JSON.stringify(cart));\n    \n    // Future implementation:\n    // await fetch(`/api/v1/orders/${this.orderId}`, {\n    //   method: 'PATCH',\n    //   body: JSON.stringify({ items: cart.items })\n    // });\n  }\n}\n```\n\n### Real-Time Order Updates (Not Implemented)\n\n**Placeholder in code:**\n\n```javascript\n// TODO: Replace with WebSocket or Server-Sent Events\n// For real-time order status updates (preparing, ready, etc.)\n\nasync function subscribeToOrderUpdates(orderId) {\n  // Future implementation:\n  // const ws = new WebSocket(`wss://api.example.com/orders/${orderId}/stream`);\n  // ws.onmessage = (event) => updateOrderStatus(JSON.parse(event.data));\n  \n  // For now, just poll payment status\n  return pollPaymentStatus(authRequestId);\n}\n```\n\n## Testing Guide\n\n### Manual Testing Scenarios\n\n#### Scenario 1: Happy Path\n\n1. Start all services: `make start-all`\n1. Open [http://localhost:3000](http://localhost:3000)\n1. Add items to cart:\n\n- 2x Margherita Pizza ($28.00)\n- 1x Garlic Bread ($6.00)\n- 1x Coca-Cola ($3.00)\n\n1. Verify cart total: $37.00 + $3.33 tax = $40.33\n1. Click \"Checkout\"\n1. Enter card: 4242 4242 4242 4242, 12/2025, 123\n1. Click \"Place Order & Pay\"\n1. Verify:\n\n- Redirected to status page\n- Shows \"Processing...\" spinner\n- Within 5-10 seconds shows \"✅ Payment Successful\"\n- Displays authorization code and processor ID\n\n1. Click \"View on Stripe Dashboard\"\n1. Verify charge appears in Stripe dashboard with correct amount\n\n#### Scenario 2: Card Decline\n\n1. Repeat steps 1-5 from Scenario 1\n1. Enter card: 4000 0000 0000 9995 (insufficient funds)\n1. Click \"Place Order & Pay\"\n1. Verify:\n\n- Shows \"❌ Payment Declined\"\n- Displays decline reason: \"Insufficient funds\"\n- Shows \"Try Again\" button\n\n1. Click \"Try Again\" → redirected to checkout\n1. Use successful card → verify payment succeeds\n\n#### Scenario 3: Service Failure\n\n1. Start all services\n1. Stop Payment Token Service: `docker-compose stop payment-token`\n1. Try to place order\n1. Verify:\n\n- Shows error message: \"Unable to process payment\"\n- Provides option to retry\n\n1. Restart service: `docker-compose start payment-token`\n1. Retry payment → verify success\n\n#### Scenario 4: Concurrent Orders\n\n1. Open frontend in 3 different browser tabs\n1. Place different orders simultaneously\n1. Verify all succeed with unique auth\\_request\\_ids\n\n### Automated E2E Tests (Optional Enhancement)\n\n**Could add Playwright/Cypress tests:**\n\n```javascript\n// tests/frontend-e2e/happy-path.spec.js\ntest('complete order flow', async ({ page }) => {\n  await page.goto('http://localhost:3000');\n  \n  // Add items\n  await page.click('[data-item-id=\"item-001\"] button'); // Add pizza\n  await page.click('[data-item-id=\"item-001\"] button'); // Add 2nd pizza\n  \n  // Checkout\n  await page.click('text=Checkout');\n  \n  // Fill payment form\n  await page.fill('[name=\"card_number\"]', '4242424242424242');\n  await page.fill('[name=\"exp_month\"]', '12');\n  await page.fill('[name=\"exp_year\"]', '2025');\n  await page.fill('[name=\"cvv\"]', '123');\n  \n  // Submit\n  await page.click('text=Place Order & Pay');\n  \n  // Wait for success\n  await page.waitForSelector('text=Payment Successful');\n  \n  // Verify details\n  expect(await page.textContent('[data-processor-id]')).toMatch(/ch_/);\n});\n```\n\n## Behaviors\n\n### B1: Menu Display\n\n**Given** frontend loads **When** menu is rendered **Then** display all menu items grouped by category **And** show prices in dollars ($14.00 format) **And** show \"Add to Cart\" button for each item\n\n### B2: Cart Management\n\n**Given** user adds items to cart **When** cart updates **Then** persist cart to localStorage **And** calculate subtotal = sum(item.price \\* quantity) **And** calculate tax = subtotal \\* TAX\\_RATE **And** calculate total = subtotal + tax **And** update cart badge with item count\n\n### B3: Empty Cart Validation\n\n**Given** cart is empty **When** user tries to checkout **Then** disable \"Checkout\" button **And** show message \"Add items to cart first\"\n\n### B4: Payment Token Creation\n\n**Given** user submits payment form **When** creating payment token **Then** encrypt card data with API partner encryption key **And** include `key_id` in encryption metadata **And** send to Payment Token Service **And** handle errors (invalid card, service unavailable) **And** show loading spinner during request\n\n### B5: Authorization Request\n\n**Given** payment token created successfully **When** submitting authorization **Then** send request to Authorization API **And** include cart metadata (items, amounts) **And** redirect to status page immediately **And** pass auth\\_request\\_id in URL\n\n### B6: Status Polling - Fast Path\n\n**Given** authorization request submitted **When** worker completes within 5 seconds **Then** first status check returns AUTHORIZED **And** show success UI immediately **And** display authorization details\n\n### B7: Status Polling - Slow Path\n\n**Given** authorization request submitted **When** worker takes > 5 seconds **Then** show \"Processing...\" spinner **And** poll every 1 second for up to 30 seconds **And** update UI when status changes\n\n### B8: Stripe Dashboard Link\n\n**Given** payment authorized successfully **When** processor is Stripe **Then** display link to Stripe Dashboard **And** link should open charge detail page **And** include processor\\_auth\\_id in URL\n\n### B9: Error Handling - Network Failure\n\n**Given** any API call fails (timeout, 500 error) **When** error occurs **Then** show user-friendly error message **And** provide \"Retry\" button **And** log error details to console\n\n### B10: Error Handling - Card Decline\n\n**Given** card is declined **When** status polling returns DENIED **Then** show decline reason **And** show decline code **And** provide \"Try Again\" button **And** do NOT charge the card\n\n### B11: Cart Persistence\n\n**Given** user adds items to cart **When** user refreshes page **Then** cart items should persist **And** cart totals should be recalculated\n\n### B12: Idempotency - Duplicate Submit\n\n**Given** user submits payment **When** user clicks \"Place Order\" again before completion **Then** use same idempotency key **And** return same auth\\_request\\_id **And** do NOT create duplicate authorization\n\n### B13: Encryption Key Identification\n\n**Given** frontend encrypts card data **When** creating payment token **Then** include `encryption_metadata.key_id` in request **And** backend uses `key_id` to look up correct decryption key **And** support for multiple active keys (future key rotation)\n\n## Configuration\n\n### Environment Variables\n\n**Frontend configuration (**`config.js`**):**\n\n```javascript\nconst CONFIG = {\n  // From environment or hardcoded\n  RESTAURANT_ID: process.env.RESTAURANT_ID || '12345678-1234-5678-1234-567812345678',\n  \n  PAYMENT_TOKEN_SERVICE_URL: process.env.PAYMENT_TOKEN_SERVICE_URL || 'http://localhost:8001',\n  AUTHORIZATION_API_URL: process.env.AUTHORIZATION_API_URL || 'http://localhost:8002',\n  \n  API_PARTNER_KEY_ID: process.env.API_PARTNER_KEY_ID || 'demo-primary-key-001',\n  \n  TAX_RATE: parseFloat(process.env.TAX_RATE || '0.09'),\n  \n  STATUS_POLL_INTERVAL_MS: parseInt(process.env.STATUS_POLL_INTERVAL_MS || '1000'),\n  STATUS_POLL_TIMEOUT_MS: parseInt(process.env.STATUS_POLL_TIMEOUT_MS || '30000'),\n  \n  // Feature flags\n  ENABLE_STRIPE_DASHBOARD_LINKS: process.env.ENABLE_STRIPE_DASHBOARD_LINKS !== 'false',\n  ENABLE_DEBUG_MODE: process.env.ENABLE_DEBUG_MODE === 'true'\n};\n```\n\n### Docker Compose\n\n**Add to root** `docker-compose.yml`**:**\n\n```yaml\nservices:\n  frontend:\n    build: ./frontend\n    ports:\n      - \"3000:80\"\n    environment:\n      - RESTAURANT_ID=12345678-1234-5678-1234-567812345678\n      - PAYMENT_TOKEN_SERVICE_URL=http://payment-token:8000\n      - AUTHORIZATION_API_URL=http://authorization-api:8000\n      - TAX_RATE=0.09\n    depends_on:\n      - payment-token\n      - authorization-api\n    networks:\n      - payments-network\n```\n\n## Success Criteria\n\n### Functional Requirements\n\n- ✅ User can browse menu items\n- ✅ User can add/remove items from cart\n- ✅ Cart calculates totals correctly (subtotal + tax)\n- ✅ User can enter card details and submit payment\n- ✅ Payment is processed through full infrastructure\n- ✅ User sees real-time payment status\n- ✅ Successful payments appear in Stripe Dashboard\n- ✅ Declined cards show appropriate error messages\n- ✅ Encryption includes key identification for future multi-key support\n\n### Non-Functional Requirements\n\n- ✅ Frontend loads in < 2 seconds\n- ✅ Payment flow completes in < 10 seconds (happy path)\n- ✅ Works on desktop and mobile browsers\n- ✅ Clear error messages for all failure scenarios\n- ✅ Easy to start with single `make start-all` command\n\n### Documentation Requirements\n\n- ✅ README with setup instructions\n- ✅ Test card numbers prominently displayed\n- ✅ Links to Stripe Dashboard in UI\n- ✅ Code comments indicating future placeholders\n- ✅ Makefile with clear command descriptions\n\n## Future Enhancements\n\n### Phase 2: Real Menu API\n\n- Replace mock data with Menu API Service\n- Support dynamic menu updates\n- Add menu item availability tracking\n- Support modifiers/customizations\n\n### Phase 3: Multi-Restaurant Support\n\n- Remove hardcoded restaurant ID\n- Add restaurant selection UI\n- Support different tax rates per location\n- Multi-currency support\n\n### Phase 4: Order Management\n\n- Replace cart localStorage with Order API\n- Order history and tracking\n- Order status updates (preparing, ready, delivered)\n- Customer notifications (email, SMS)\n\n### Phase 5: Production Hardening\n\n- Real authentication (customer accounts)\n- PCI compliance review\n- Security audit\n- Rate limiting\n- CSRF protection\n- Content Security Policy (CSP)\n\n### Phase 6: API Partner Key Management\n\n- Implement Key Generation API\n- Support multiple active keys per partner\n- Automatic key rotation\n- Key deprecation workflow\n- Audit logging for key usage\n\n## References\n\n- **Payment Flow**: See `tests/e2e/test_full_e2e.py` for reference implementation\n- **Authorization API**: [[s-9jeq]]\n- **Payment Token Service**: [[s-7ujm]]\n- **Event Sourcing Architecture**: [[s-94si]]\n- **Stripe Documentation**: [https://stripe.com/docs/api](https://stripe.com/docs/api)","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-14 02:46:39","updated_at":"2025-11-14 04:19:31","parent_id":null,"parent_uuid":null,"relationships":[{"from":"s-63fi","from_type":"spec","to":"s-9jeq","to_type":"spec","type":"depends-on"},{"from":"s-63fi","from_type":"spec","to":"s-94si","to_type":"spec","type":"references"},{"from":"s-63fi","from_type":"spec","to":"s-7ujm","to_type":"spec","type":"depends-on"}],"tags":["demo","frontend","ordering","payment-flow","stripe"]}
